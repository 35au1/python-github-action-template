[
    {
        "title": "Image shows UFO taken down by US jet in Canada following Chinese spy craft incident: Report",
        "link": "https://timesofindia.indiatimes.com/world/us/image-shows-ufo-taken-down-by-us-jet-in-canada-following-chinese-spy-craft-incident-report/articleshow/113688682.cms",
        "description": "A photograph of a UFO shot down by a US fighter jet over Canadian airspace in February 2023 has been made public. The image ...",
        "image_url": "https://www.bing.com/th?id=OVFT.0qd8UVxi997FeB0NFWQPZC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "2h",
        "source": "Indiatimes",
        "article_content": "Pic of UFO downed by US fighter jet (Pic credit: MJ Schwab's X account)\n\nA photograph of an unidentified flying object ( UFO ) that was shot down by a US fighter jet over Canadian airspace in February 2023 has been made public. The image, which appears to be a photocopy of an email printout, shows a blurry cylindrical object hovering in the air before it was brought down in Canada 's Yukon Territory, near the Alaskan border, as reported by CTVNews, who obtained the image through an information request from Canada's department of national defence.The North American Aerospace Defense Command initially detected the \"high-altitude airborne object\" flying at approximately 40,000 feet over Alaska and dispatched jets to observe it, according to a report of Fox News. The object drifted from Alaska into Canadian airspace before being shot down on February 11, 2023. This incident occurred shortly after the downing of a Chinese surveillance balloon and was one of three aerial objects brought down that month.\"Yesterday afternoon, I also spoke with President Biden and confirmed together that we will continue to do everything necessary to protect the sovereignty of our shared North American airspace but also to do everything necessary to keep our citizens safe,\" said Canadian Prime Minister Justin Trudeau at the time.The object was shot down by a US F-22 Raptor using an AIM 9X missile and was believed to be a \"small metallic balloon with a tethered payload.\"President Biden later clarified that the three objects were not connected to the Chinese spycraft incident. The Canadian government initially declassified the UFO image but later authorized the public release.However, the acting assistant deputy minister for public affairs questioned whether the public should be allowed to view it, saying in an internal email, \"Should the image be released, it would be via the [Canadian armed forces] social media accounts. Given the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\" The release of the image was subsequently held back pending \"US engagement.\""
    },
    {
        "title": "Image shows UFO downed by US fighter jet in Canadian airspace days after Chinese spy craft incident",
        "link": "https://www.foxnews.com/us/image-shows-ufo-downed-us-fighter-jet-canadian-airspace-days-after-chinese-spy-craft-incident",
        "description": "A newly released image shows a UFO that was brought down last year by a U.S. military fighter jet in Canadian airspace.",
        "image_url": "https://www.bing.com/th?id=OVFT.cdR3vtc8uaCgSaW7qmfZty&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "10h",
        "source": "Fox News",
        "article_content": "An image of a UFO that was shot down by a U.S. fighter jet over Canada last year was released Wednesday.\n\nThe blurry photo, which appears to be a photocopy of an email printout, of the unidentified cylindrical object was captured as it hovered in the air in February 2023, days before it was shot down over Canada's Yukon Territory, which borders Alaska, according to CTVNews.\n\nThe news outlet obtained the image through an information request from Canada\u2019s Department of National Defence.\n\nThe object initially drifted from Alaska into Canadian airspace. The North American Aerospace Defense Command first detected the \"high-altitude airborne object\" flying at about 40,000 feet over Alaska and scrambled jets to monitor it.\n\nUFOs SOAR FROM TABOO TO PRESIDENTIAL: \u2018TIME HAS COME TO INJECT UAPs INTO THE \u2026 ELECTIONS,\u2019 INSTITUTE SAYS\n\nIt was shot down on Feb. 11, 2023, and was one of three aerial objects brought down that month after the downing of a Chinese surveillance balloon days earlier.\n\nAll three objects were smaller than the Chinese spy balloon that drifted from Alaska across the U.S. before it was shot down off the coast of South Carolina on Feb. 4, 2023.\n\n\"Yesterday afternoon, I also spoke with President Biden and confirmed together that we will continue to do everything necessary to protect the sovereignty of our shared North American airspace but also to do everything necessary to keep our citizens safe,\" Canadian Prime Minister Justin Trudeau said at the time.\n\nCONGRESSMAN GIVES 270 DAYS TO DISCLOSE ALL UFO DOCS: \u2018IF YOU GOT NOTHING TO HIDE, RELEASE THE FILES\u2019\n\nA U.S. F-22 Raptor fired an AIM 9X missile to down the object. It was believed to be a \"small metallic balloon with a tethered payload.\"\n\nBiden later said the three objects were not related to the Chinese spy craft incident.\n\nThe image of the UFO was initially declassified in Canada and approved for public release before the acting assistant deputy minister for public affairs questioned whether the public should be allowed to view it, according to the news outlet.\n\n\"Should the image be released, it would be via the [Canadian armed forces] social media accounts,\" the official wrote in an internal email. \"Given the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\"\n\nCLICK TO GET THE FOX NEWS APP\n\nOfficials held back the release pending \"U.S. engagement.\" Fox News Digital has reached out to the Canadian Department of National Defence."
    },
    {
        "title": "New photo shows UFO hovering over Canada before it was shot down by US fighter jet",
        "link": "https://nypost.com/2024/09/25/us-news/ufo-flying-over-canada-shot-down-by-us-in-feb-2023-seen-in-new-picture/",
        "description": "A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.",
        "image_url": "https://www.bing.com/th?id=OVFT.7gqJISWouleXztzizdk58y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "21h",
        "source": "New York Post",
        "article_content": "A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon.\n\nThe grainy, blurry image captured the \u201ccylindrical\u201d \u201csuspected balloon\u201d 40,000 feet above the Great White North in February 2023 days before it was taken out, according to CTVNews, which obtained the image through an information request with Canada\u2019s Department of National Defence.\n\nA US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.\n\n4 A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon. Department of National Defence / CTV News\n\nOfficials in the US and Canada began tracking the UFO again when it crossed into Canadian airspace, and Prime Minister Justin Trudeau gave the order to shoot it down just after 4:50 p.m.\n\nAn American pilot struck the object with an AIM 9x missile.\n\nThe airborne object previously described as a \u201csmall, metallic balloon with a tethered payload\u201d was spotted amid three other cases in which North America dealt with unidentified objects in the sky.\n\nBetween Feb. 10 and Feb 12, three objects were spotted floating over North America before they were downed over Alaska, the Yukon and Lake Huron, respectively.\n\nThey were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023.\n\n4 The Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off. Department of National Defence / CTV News\n\n4 A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023. REUTERS\n\nChina used American technology in its spy balloon that snooped on US military bases earlier this year, a federal investigation analyzing the object\u2019s debris has found.\n\nThe Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off.\n\n\u201cAttached is an image approved to be released,\u201d Canadian military leaders wrote in a Feb. 15, 2023, email, according to the outlet. \u201cWe are looking at getting a better one to send to you.\u201d\n\nThe Department of National Defence was going forward with the release of the image before the acting assistant deputy minister for public affairs questioned whether the public should see it.\n\nStart and end your day informed with our newsletters Morning Report and Evening Update: Your source for today's top stories Thanks for signing up! Enter your email address Please provide a valid email address. By clicking above you agree to the Terms of Use and Privacy Policy. Never miss a story. Check out more newsletters\n\n\u201cShould the image be released, it would be via the [Canadian armed forces] social media accounts,\u201d the official wrote. \u201cGiven the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\u201d\n\nIt was later recommended the Canadian department should wait on the release \u201cpending US engagement,\u201d leading to the photo never seeing the light of day for over a year and a half.\n\nPresident Biden confirmed the three objects were shot down but said there were no \u201csuggestions they were related to China\u2019s spy balloon program, or that they were surveillance vehicles from any other country.\u201d\n\n4 They were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023. REUTERS\n\nSearches for the debris from all three objects were conducted, but both the Canadian Mounties and the US called off the efforts days later.\n\nPoor weather conditions and slim chances of finding the debris fields were cited as reasons for not continuing the searches."
    },
    {
        "title": "New UFO Doc \u2018The Program\u2019 Set From \u2018The Phenomenon\u2019 Director James Fox (Exclusive)",
        "link": "https://www.hollywoodreporter.com/movies/movie-news/ufo-doc-the-program-james-fox-1236011733/",
        "description": "The feature, which will be screened for buyers, will focus on the bipartisan Congressional effort to uncover government ...",
        "image_url": "https://www.bing.com/th?id=OVFT.rbvs0gPJdEgDk7xnICLs_y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "6h",
        "source": "The Hollywood Reporter",
        "article_content": "As the conversation around UFOs/UAPs continues to heat up on Capitol Hill, documentarian James Fox has set his next feature on the subject.\n\nFox directs The Program, which is described as exploring \u201cthe unprecedented bipartisan congressional effort to uncover what intelligence agencies really know about UFOs, now referred to as UAP.\u201d In July 2023, three former Pentagon officials testified about their experience with or sightings of UFOs/ UAPs, and the U.S. Senate introduced the bipartisan UAP Disclosure Act. Earlier this month, it was reported that the Senate Armed Services Committee is looking to hold a UFO hearing after the elections in November.\n\nThe doc, narrated by Peter Coyote, will include extensive interviews with insiders, experts and politicians. Christopher Mellon, the former deputy assistant secretary of defense for intelligence, and Stanford University\u2019s Dr. Gary Nolan, will be among those who appear in the doc. Also set are Jason Sands, a master sergeant in the United States Air Force; Craig Lindsay, formerly of Scotland\u2019s Royal Air Force Office; and Nick Pope, formerly of the U.K.\u2019s Ministry of Defense. Among others, Andre Carson, Sen. Harry Reid and Rep. Tim Burchett are interviewed, along with Kirk McConnell, who previously held a position in Senate Armed Services Committee.\n\nFox and Lance Mungia produced the doc, with Jim Martin and Henry Marx of Lab 9 Films executive producing. Verve Ventures is handling sales, with the doc set to screen for buyers.\n\n\u201cI\u2019ve been making films on the topic of UFOs (now referred to as UAP) since the early 1990s. I never thought I\u2019d live to see the day when high level military officials would testify under oath to a bipartisan group of lawmakers that the United States government has been hiding definitive proof that we are not alone. The program lays out a very compelling case that disclosure is upon us,\u201d said Fox, who was behind previous docs The Phenomenon and Moment of Contact.\n\nAdded Martin and Marx: \u201cWe are thrilled to bring James Fox\u2019s most powerful work, The Program, to the widest possible audience. This film is banging on the door of UFO disclosure, demanding the attention and conversation it deserves.\u201d\n\nThe conversation about UFOs/UAPs is heating up as top officials continue to share their stories. Recently, Jay Stratton, the former director of the U.S. government\u2019s secretive Unidentified Aerial Phenomena Task Force, struck a memoir deal with HarperCollins. Last month, Luis Elizondo \u2014 the former head of the Pentagon\u2019s program investigating UFOs/ UAPs \u2014 released the book Imminent: Inside the Pentagon\u2019s Hunt for UFOs, which became a New York Times best-seller."
    },
    {
        "title": "Presidents CANNOT UFO Information On Their Own because of the Atomic Energy Act.",
        "link": "https://www.msn.com/en-us/news/politics/presidents-cannot-ufo-information-on-their-own-because-of-the-atomic-energy-act/vi-AA1rbWPe?ocid=BingNewsVerp",
        "description": "A reddit thread stated today and listed that Presidents cannot discose UFO information on their own accord due to the Atomic ...",
        "image_url": "https://www.bing.com/th?id=OVF.2KaSM50YMmcBFfJvb040fg&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "Down To Earth With Kristian Harloff on MSN17h",
        "source": "Down To Earth With Kristian Harloff on MSN",
        "article_content": ""
    },
    {
        "title": "Beyond The Cloud: AI Opens The Door For The Next Wave Of B2B Applications",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/beyond-the-cloud-ai-opens-the-door-for-the-next-wave-of-b2b-applications/",
        "description": "Daniel Saks is the CEO of Landbase, an intelligent go-to-market automation company, and co-founder of unicorn AppDirect.",
        "image_url": "https://www.bing.com/th?id=OVFT.dtNvi50CcMCQN6_lFGfmji&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "20h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Meta AI\u2019s GenAI \u2018Imagine\u2019 features expand across Facebook, Instagram, and Messenger",
        "link": "https://techcrunch.com/2024/09/25/meta-ais-genai-imagine-features-expand-across-facebook-instagram-and-messenger/",
        "description": "With the update, users will be able to use prompts to generate AI photos directly in their feed, Stories, and for their ...",
        "image_url": "https://www.bing.com/th?id=OVFT.4_PluQCf1JXeVhYsJknNKi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "14h",
        "source": "TechCrunch",
        "article_content": "Meta AI\u2019s Imagine features, which use generative AI to turn text prompts into images, are now being expanded across Facebook and Instagram, the company announced at Meta Connect 2024 on Wednesday. With the update, users will be able to use prompts to generate AI photos directly in their feed, Stories, and for their Facebook profile pictures.\n\nThe new capabilities could help users and creators call more attention to their posts and shares by allowing them to generate fanciful and eye-catching images to accompany their text. Once the images are shared, friends and followers can see them and react to them or even mimic them, Meta says.\n\nImage Credits: Meta\n\nImage Credits: Meta\n\nFacebook users already upload photos of characters, animals, or something else besides their own photo as their profile picture to better protect their privacy. Now they won\u2019t have to seek out such a photo: They can simply generate one.\n\nThe AI can also suggest captions for Stories on Facebook and Instagram, as a part of this update.\n\nThe image generation capabilities will come to Messenger, too, to create personalized chat themes. This is accessed by tapping on \u201cThemes\u201d in the chat. Before, users could change the background of their chats as well as the color of the text bubbles, but Meta AI offers far more options in terms of the types of images that can be used.\n\nImage Credits: Meta\n\nMeta says it\u2019s also testing new AI-generated content in Facebook and Instagram feeds where it will display AI images created for users based on interests and trends.\n\nImage Credits: Meta\n\nThis is largely designed to push people to try Meta AI by tapping on a suggested prompt to reimagine the photo or by swiping to generate content in real time using Meta Imagine AI.\n\nMeta CEO Mark Zuckerberg remarked during the event that Meta AI differentiates itself not only by offering \u201cstate-of-the-art AI models but also unlimited access to those models for free, integrated easily into our different products and apps,\u201d he said.\n\n\u201cSo Meta AI is on track to being the most used AI assistant in the world by the end of this year. In fact, it\u2019s probably already there. \u2026 We\u2019re almost at 500 million monthly actives, and we haven\u2019t even launched in some of the bigger countries yet,\u201d Zuckerberg added."
    },
    {
        "title": "Meta AI can now understand and edit your photos",
        "link": "https://techcrunch.com/2024/09/25/meta-ai-can-now-understand-and-edit-your-photos/",
        "description": "Meta announced that Meta AI will now be able to help you edit photos using AI technology as well as answer questions about ...",
        "image_url": "https://www.bing.com/th?id=OVFT.mT7uK9pq4shLPt66eQIS_y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "12h",
        "source": "TechCrunch",
        "article_content": "Meta AI is starting to catch up with Google when it comes to AI-powered photo editing. On Wednesday, at the Meta Connect 2024 conference, the tech giant announced that Meta AI will now be able to help you edit photos using AI technology and answer questions about the photos you share.\n\nThe additional features are made possible because Meta AI is gaining multimodal capabilities, powered by its Llama 3.2 models. This means you can now share photos in your chats, not just text, similar to Google Gemini and OpenAI\u2019s ChatGPT.\n\nWhen sharing a photo, Meta AI can understand what the image contains and answer questions about the image. For example, Meta suggests you could share a photo of a flower and then ask the AI what type of flower it is. Or you could share a photo of a delicious dish and ask Meta AI how to make it. Of course, how accurately Meta AI responds to these and other questions still needs to be tested and reviewed.\n\nImage Credits: Meta\n\nAnother key feature with the added photo support is the ability to edit images using AI.\n\nAfter sending Meta AI the photo, you can ask it to make some sort of change \u2014 like adding or removing an object in the foreground, changing your outfit, or updating the background of the photo in some way, like adding a rainbow to the sky, for instance.\n\nImage Credits: Meta\n\nImage Credits: Meta\n\nMeta AI can also be used on Instagram when you reshare a photo from your feed to your Instagram Stories. Here, the AI technology can look at the photo, understand the images, then generate an accompanying background for your Story.\n\nImage Credits: Meta\n\nBeyond photo edits, Meta is also testing translation tools for Facebook and Instagram Reels that include automatic dubbing and lip-syncing. These tests will initially be run in small groups in the U.S. and Latin America in both English and Spanish.\n\nOther Meta AI photo features include the expansion of Meta AI\u2019s generative AI features and the rollout of tests of Meta AI images shared to your Facebook and Instagram feeds, to prompt users to try the feature.\n\nFine text during Meta\u2019s demo noted the editing features were coming to the U.S. in English first.\n\nNoted Meta CEO Mark Zuckerberg during the event, \u201cMeta AI differentiates itself in this category by not just offering state-of-the-art AI models, but also unlimited access to those models for free, integrated easily into our different products and apps,\u201d he said. \u201cSo Meta AI is on track to being the most used AI assistant in the world by the end of this year. In fact, it\u2019s probably already there. \u2026 We\u2019re almost at 500 million monthly actives, and we haven\u2019t even launched in some of the bigger countries yet,\u201d Zuckerberg added."
    },
    {
        "title": "Nothing Teases OS 3.0 With an AI App Drawer",
        "link": "https://www.techopedia.com/news/nothing-teases-os-3-0-with-an-ai-app-drawer",
        "description": "Nothing\u2019s upcoming OS 3.0 builds upon its distinct appearance with more custom widgets, lock screen options, an AI-powered ...",
        "image_url": "https://www.bing.com/th?id=OVF.v7wMpALGJ3afud69M0d8YA&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "Techopedia23h",
        "source": "Techopedia",
        "article_content": "Content not available"
    },
    {
        "title": "How Will AI Affect Low-Code/No-Code Development?",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/how-will-ai-affect-low-codeno-code-development/",
        "description": "When implementing AI into low-code/no-code development, it is important to consider the risks and how to mitigate them.",
        "image_url": "https://www.bing.com/th?id=OVFT.3hoTdJIxRV-Fjg_OSCaXhy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "22h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Exclusive: Seen any paranormal activity on your Ring device? You could win $100,000",
        "link": "https://www.msn.com/en-us/news/technology/exclusive-seen-any-paranormal-activity-on-your-ring-device-you-could-win-100-000/ar-AA1r74hR?ocid=BingNewsVerp",
        "description": "Ring\u2019s 'Great Ghost Search' will award $100,000 for whoever submits compelling paranormal or ghostly activity captured by a ...",
        "image_url": "https://www.bing.com/th?id=OVFT.lLSzBH7Q7ZqkMApvpW742S&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "18hon MSN",
        "source": "USA TODAY on MSN",
        "article_content": ""
    },
    {
        "title": "Got ghosts? Ring asks users for videos of paranormal activity in exchange for $100K",
        "link": "https://www.michigansthumb.com/news/article/ring-camera-great-ghost-search-2024-how-to-enter-19791924.php",
        "description": "Ring announced on Sept. 24, 2024, that users can submit videos of paranormal activity captured on their Ring doorbell or ...",
        "image_url": "https://www.bing.com/th?id=OVFT.jZlSkBiaLj3OBYpdNsQJcC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Huron Daily Tribune15h",
        "source": "Huron Daily Tribune",
        "article_content": "Content not available"
    },
    {
        "title": "How The Scariest Movie of 2009 Launched an Unstoppable Hollywood Studio",
        "link": "https://www.inverse.com/entertainment/paranormal-activity-anniversary-15-years",
        "description": "Blumhouse had already existed for a few years, but 'Paranormal Activity' cracked the code and turned it into a powerhouse.",
        "image_url": "https://www.bing.com/th?id=OVFT.Nr5VFjObBu8WsvnkzNRaXy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Inverse20h",
        "source": "Inverse",
        "article_content": "You kind of had to be there.\n\nParanormal Activity, like The Blair Witch Project before it, is a movie best experienced in a large dark room with 100 screaming strangers. Maybe that\u2019s true of most movies, but found-footage thrillers attempt to hijack your brain into thinking they\u2019re real in a way that just doesn\u2019t work when you\u2019re watching it at home when the lights are on and phone notifications are vying for your attention.\n\nBut even if you can\u2019t re-experience the original sensation of seeing Paranormal Activity in theaters when it was released back on September 25, 2009, it\u2019s still worth reflecting on how this micro-budget horror movie managed to become a worldwide phenomenon, and how it changed the entire industry in the process.\n\nThe plot is simple. A young couple, Katie and Micah, move in together. Katie then tells Micah that she\u2019s been haunted by an evil spirit ever since she was a kid, so Micah sets up a camera and records everything in the house, including their bedroom, while they sleep. The haunting starts small (a door moves on its own, there are some light noises), but things escalate within a few weeks, leading to a terrifying finale where Katie becomes possessed by a demon and murders Micah.\n\nParanormal Activity was made with just $15,000 and filmed in one week in first-time director Oren Peli\u2019s own home. Peli cast two unknown actors, shot the movie on a home video camera, and never bothered writing a script; like with The Blair Witch Project, actors were told to improvise based on a loose outline.\n\nKatie Featherston as Katie. Blumhouse\n\nIn a 2009 interview with Shock Till You Drop, Peli explained his lo-fi, found-footage approach.\n\n\u201cI wanted to make it look as real and natural as possible,\u201d he said. \u201cI\u2019ve always been drawn to this storytelling style. It breaks the mental barrier when audiences see a regular film and become aware of the camera movements, they know a crew is there and there are stars. When you strip all of this away, the audience thinks they are seeing something with a higher degree of plausibility. The suspending of disbelief becomes all the easier. You have an audience that's more invested in the story and the characters.\u201d\n\nParanormal Activity made almost $200 million at the box office and spawned a seven-movie franchise, but its legacy is even bigger than that. Peli\u2019s thriller also gave rise to one of the biggest names in horror today: Jason Blum.\n\nJason Blum attends the Film Independent's Spirit Awards in 2010. Angela Weiss/WireImage/Getty Images\n\nAfter debuting at Screamfest in 2007, Paranormal Activity earned some Hollywood buzz. It landed on the desk of Blumhouse CEO Jason Blum, then an executive at Miramax, who worked with Peli to edit the movie and submit it to Sundance. They were rejected, but didn\u2019t give up, and eventually, an early copy of Paranormal Activity found its way to Steven Spielberg.\n\nSpielberg made a deal with Peli and Blum to release the movie through Paramount. The plan was to completely reshoot it with a bigger budget while releasing the original cut as a DVD extra, but after a test screening scared audiences so much that some people walked out, the team realized they had a potential hit on their hands. The rest is history.\n\nSinister followed a similar formula, giving director Scott Derrickson the freedom to experiment. Blumhouse\n\nSpeaking to The LA Times just days before Paranormal Activity finally hit theaters, Jason Blum broke down exactly what makes the movie so special. \u201cOnce every five years, a guy makes a movie for a nickel that can cross over to a broad audience,\" he said.\n\nYou could practically hear the gears turning in Blum\u2019s head. While his studio, Blumhouse, had already existed for a few years, it was Paranormal Activity that cracked the code. Movies like Insidious and Sinister would soon follow, giving ambitious directors little money but lots of freedom to make bold horror movies that could rake in millions and launch new franchises.\n\nIn that sense, we have Paranormal Activity to thank for our current glut of horror movies. Blumhouse is still pumping them out 15 years later, and so is everyone else, from indie studios like A24 to Hollywood titans like Paramount. Even Disney is cashing in on horror thanks to its Fox acquisition and the IP, like Alien, that came with it.\n\nBut while Paranormal Activity\u2019s legacy may be mighty, the movie itself hasn\u2019t exactly held up, at least not in the context that most people experience movies these days.\n\n\u201cYou watch it in your bedroom, it can look like your kid made it,\u201d Blum said back in 2009. \u201cYou watch it with an audience, it's an entirely different experience.\u201d\n\nSo if you want to watch Paranormal Activity the way it was meant to be seen, just get 100 of your closest friends and family together in a dark room. If that\u2019s not viable, you can explore the entire genre it spawned instead."
    },
    {
        "title": "Catch a ghost on your Ring camera? You can get $100K for the video",
        "link": "https://www.yahoo.com/entertainment/catch-ghost-ring-camera-100k-162202746.html",
        "description": "Catch a \"ghost\" on your Ring camera this fall? Ring wants to see it \u2014 and they may be willing to pay you for it.",
        "image_url": "https://www.bing.com/th?id=OVFT.hsx_wkS-4DNxYdIozQuXxy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "16h",
        "source": "Yahoo",
        "article_content": "Catch a ghost on your Ring camera? You can get $100K for the video\n\n(KTLA) \u2014 Your Ring camera may catch video of packages being dropped off, friends visiting, and cute animal activities, but the home surveillance company is hoping you\u2019ll catch some different, paranormal activity this Halloween season.\n\nRing is inviting users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize.\n\nAny form of paranormal activity \u2014 ghosts, ghouls, and anywhere in between \u2014 is welcome, according to Ring.\n\nRing offering $1M for proof of \u2018extraterrestrial life\u2019 caught on camera\n\n\u201cFrom supernatural sightings of floating orbs and unexplained shadows to family and friends wearing silly costumes. Funny, frightening, fashionable, all of it. If you find a ghost, we want to see it,\u201d the contest website said.\n\nThe company is inviting its users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize. (Ring)\n\n\u201cFinn Wolfhard, star of \u2018Ghostbusters\u2019 and Netflix\u2019s \u2018Stranger Things,\u2019 and Paranormal Investigator Katrina Weidman will serve as part of the judging team for Ring\u2019s Great Ghost Search, helping to select the winning entry,\u201d a news release said.\n\nOnly the first 5,000 entries received through Nov. 1 will be considered for the grand prize. According to Ring, only the first 30 seconds of each video will be considered. Videos will be awarded points, with a maximum of 100 points available.\n\nPoints will be awarded based on the visibility or clarity of the \u201cghost\u201d or ghostly presence; whether the video surprises the judges with uniqueness; whether the judges were \u201cglued to the footage\u201d and how entertaining it was; and how unique the ghost\u2019s engagement with the Ring device was.\n\nRing users can enter the contest and find more details here.\n\nCopyright 2024 Nexstar Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.\n\nFor the latest news, weather, sports, and streaming video, head to PIX11."
    },
    {
        "title": "Childhood Ghost Stories | Paranormal Storytime Collab with Jessii Vee",
        "link": "https://www.msn.com/en-us/money/other/childhood-ghost-stories-paranormal-storytime-collab-with-jessii-vee/vi-AA1r9Fyr?ocid=BingNewsVerp",
        "description": "OPEN ME FOR ALL OF THE THINGS!Make sure to check out Jessii Vee's paranormal story time video here: <a href=\" am I ...",
        "image_url": "https://www.bing.com/th?id=OVFT.2N8ZMtpqG75lYL484Y1PYy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Binge Bytes on MSN20h",
        "source": "Binge Bytes on MSN",
        "article_content": ""
    },
    {
        "title": "Unexpected deep-sea discovery shines light on life in the twilight zone",
        "link": "https://phys.org/news/2024-09-unexpected-deep-sea-discovery-life.html",
        "description": "The ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to ...",
        "image_url": "https://www.bing.com/th?id=OVFT.fERzBQQCwkWUdJWljKZQWC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "17h",
        "source": "Phys.org",
        "article_content": "This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:\n\nA conductivity, temperature and depth (CTD) rosette used to sample water from the ocean's twilight zone during a GEOTRACES expedition in the Pacific Ocean. Credit: Alex Fox\n\nThe ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to 1,000 meters below the sea surface, where levels of iron, a key micronutrient, are so low that the growth of bacteria is restricted. To compensate, these bacteria produce molecules called siderophores, which help the bacteria scavenge trace amounts of iron from the surrounding seawater.\n\nA Nature paper detailing these unexpected findings from the Pacific Ocean could change the way scientists view microbial processes in the deep ocean and offer new insight into the ocean's capacity to absorb carbon.\n\n\"Understanding the organisms that facilitate carbon uptake in the ocean is important for understanding the impacts of climate change,\" said Tim Conway, associate professor of chemical oceanography at the USF College of Marine Science, who co-authored the recent study.\n\n\"When organic matter from the surface ocean descends to the deep ocean, it acts as a biological pump that removes carbon from the atmosphere and stores it in seawater and sediments. Measuring the rates and processes that influence this pump gives us insight into how and where the ocean stores carbon.\"\n\nCo-chief Scientist Phoebe Lam of the University of California, Santa Cruz and others removed the pump's damaged section of cable from the winch. Credit: Alex Fox\n\nTo conduct the study, researchers collected water samples from the upper 1,000 meters of the water column during an expedition through the eastern Pacific Ocean from Alaska to Tahiti. What they found in the samples surprised them.\n\nNot only were concentrations of siderophores high in surface waters where iron is expected to be deficient, but they were also elevated in waters between 200 and 400 meters deep, where nutrient and iron concentrations were thought to have little impact on the growth of bacteria.\n\n\"Unlike in surface waters, we did not expect to find siderophores in the ocean's twilight zone,\" said Conway.\n\n\"Our study shows that iron-deficiency is high for bacteria living in this region throughout much of the east Pacific Ocean, and that the bacteria use siderophores to increase their uptake of iron. This has a knock-on effect on the biological carbon pump, because these bacteria are responsible for the breakdown of organic matter as it sinks through the twilight zone.\"\n\nThe recent discovery was part of GEOTRACES, an international effort to provide high-quality data for the study of climate-driven changes in ocean biogeochemistry.\n\nLeft to right: CTD technician Kyle McQuiggan, Research Technician Keith Shadle and multi-talented Data Analyst Joseph Gum work together to repair the trace metal CTD rosette's connection to the ship. Credit: Alex Fox\n\nTubes awaiting samples in the hydro-lab of the Roger Revelle. Scripps ODF Chemistry Technician Erin Hunt monitors her samples in the background. Credit: Alex Fox\n\nOne of the pumps comes back on board the R/V Roger Revelle at sunset. Credit: Alex Fox\n\nInside the main lab's bubble, some of GP15's scientists found it necessary to create reminders that time was indeed passing. Credit: Alex Fox\n\nThe study of siderophores is still in the early stages. Researchers involved in GEOTRACES only recently developed reliable methods to measure these molecules in water samples, and they're still working to understand where and when microbes use siderophores to acquire iron.\n\nAlthough the research into siderophores is new, this study demonstrates their clear impact on the movement of nutrients in the ocean's twilight zone.\n\n\"For a full picture of how nutrients shape marine biogeochemical cycles, future studies will need to take these findings into account,\" said Daniel Repeta, senior scientist at Woods Hole Oceanographic Institution and co-author of the article.\n\n\"In other words, experiments near the surface must expand to include the twilight zone.\"\n\nMore information: Daniel Repeta et al, Microbial iron limitation in the ocean's twilight zone, Nature (2024). DOI: 10.1038/s41586-024-07905-z. www.nature.com/articles/s41586-024-07905-z Journal information: Nature"
    },
    {
        "title": "Deep-sea discovery shines light on life in the twilight zone",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925123650.htm",
        "description": "A new study could change the way scientists view microbial processes in the deep ocean. The unexpected findings expand our understanding of the impacts of climate change, including how and where the ...",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily8h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "AI Develops Proteins to Boost Drug and Science Discovery",
        "link": "https://www.miragenews.com/ai-develops-proteins-to-boost-drug-and-science-1324688/",
        "description": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more ...",
        "image_url": "https://www.bing.com/th?id=OVFT.t6A53DVVgUHq3_08BDTgeS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Armed robbery in Revesby10h",
        "source": "Armed robbery in Revesby",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature's evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\"Nature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\" said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \"EvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\"\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\"Engineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\" Klivans said. \"It also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\"\n\nUnlike Google DeepMind's AlphaFold, which applies AI to predict the shape and structure of proteins based on each one's sequence of amino acids, the Deep Proteins group's AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan's lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\"The models have come up with substitutions we never would have thought of,\" McLellan said. \"They work, but they aren't things we would have predicted, so they're actually finding some new space for stabilizing.\"\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company's new drug are only about 1 in 10. What's more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development-and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank-as well as the related UT-created framework on which it builds, Stability Oracle-are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster.\n\nUsing existing databases of naturally occurring protein sequences, the researchers who created EvoRank essentially lined up different versions of the same protein that appear in different organisms-from starfish to oak trees to humans-and compared them. At any given position in the protein, there might be one of several different amino acids that evolution has found to be useful, with nature selecting, say, 36% of the time the amino acid tyrosine, 29% of the time histidine, 14% of the time lysine-and even more importantly never leucine. Using this gold mine of existing data reveals an underlying logic in protein evolution. Researchers can knock out options that, evolution suggests, would result in killing the protein's functionality. The team uses all of this to train the new machine learning algorithm. Based on continuous feedback, the model learns which amino acid nature opted for during the past when evolving proteins, and it bases its understanding on what's plausible in nature and what is not.\n\nDiaz next plans to develop a \"multicolumn\" version of EvoRank that can evaluate how multiple mutations at the same time affect a protein's structure and stability. He also wants to build new tools for predicting how a protein's structure relates to its function.\n\nBesides Klivans and Diaz, computer science graduate student Chengyue Gong and UT alumnus James M. Loy co-authored both works. Tianlong Chen and Qiang Liu also contributed to EvoRank; Jeffrey Ouyang-Zhang, David Yang, Andrew D. Ellington and Alex G. Dimakis additionally contributed to Stability Oracle. The research was funded by the NSF, the Defense Threat Reduction Agency and The Welch Foundation."
    },
    {
        "title": "AI Trained on Evolution\u2019s Playbook Develops Proteins that Spur Drug and Scientific Discovery",
        "link": "https://cns.utexas.edu/news/research/ai-trained-evolutions-playbook-develops-proteins-spur-drug-and-scientific-discovery",
        "description": "EvoRank offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology ...",
        "image_url": "https://www.bing.com/th?id=OVFT.v_0f8vasR7xpb6PffHlZwS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Journalism in the Americas11h",
        "source": "Journalism in the Americas",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature\u2019s evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\u201cNature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\u201d said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \u201cEvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\u201d\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\u201cEngineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\u201d Klivans said. \u201cIt also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\u201d\n\nUnlike Google DeepMind\u2019s AlphaFold, which applies AI to predict the shape and structure of proteins based on each one\u2019s sequence of amino acids, the Deep Proteins group\u2019s AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan\u2019s lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\u201cThe models have come up with substitutions we never would have thought of,\u201d McLellan said. \u201cThey work, but they aren\u2019t things we would have predicted, so they\u2019re actually finding some new space for stabilizing.\u201d\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company\u2019s new drug are only about 1 in 10. What\u2019s more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development\u2014and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank\u2014as well as the related UT-created framework on which it builds, Stability Oracle\u2014are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster."
    },
    {
        "title": "Scientists discover a single-electron bond in a carbon-based compound",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925122902.htm",
        "description": "The discovery of a stable single-electron covalent bond between two carbon atoms validates a century-old theory.",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily12h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "How Will AI Affect Low-Code/No-Code Development?",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/how-will-ai-affect-low-codeno-code-development/",
        "description": "When implementing AI into low-code/no-code development, it is important to consider the risks and how to mitigate them.",
        "image_url": "https://www.bing.com/th?id=OVFT.3hoTdJIxRV-Fjg_OSCaXhy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "22h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Inside AI: No-Code Computer Vision and Edge Computing",
        "link": "https://insideunmannedsystems.com/inside-ai-no-code-computer-vision-and-edge-computing/",
        "description": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end ...",
        "image_url": "https://www.bing.com/th?id=OVFT.p3zLnocXw31jrXbR5a8NGy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "The Future of Autonomy16h",
        "source": "The Future of Autonomy",
        "article_content": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end no-code platform and edge computing capabilities.\n\nThey partner with businesses across industries to implement AI-powered computer vision technology. With the Visionplatform.ai software, users can train AI vision algorithms and integrate computer vision into their workflows. The solution enables users to detect, interpret and analyze objects, people and events in real-time, drawing insights and optimizing operations.\n\nVisionplatform.ai integrates edge computing capabilities and the use of high fps video streams instead of static images. The platform allows users to leverage the power of AI and computer vision at the edge, minimizing latency, improving responsiveness and ensuring data privacy.\n\nPLATFORM DESIGN AND DEVELOPMENT\n\nIUS: Can you explain the core design principles behind Visionplatform.ai?\n\nA: Our core design principles are simplicity, and ease of use. Our goal is to democratize computer vision to empower our users to make their own innovative solutions for real world problems.\n\nIUS: What were the biggest technical challenges you faced in developing a no-code AI vision platform, and how did you overcome them?\n\nA: Democratizing AI is a very difficult task. A field like ML and specifically computer vision has long been the playground of experts and professionals. It\u2019s a fact that the field of AI is not standardized. For experts this does not matter, but for the average user the barrier of entry into the field is very high. From a technical standpoint, our biggest challenge has been to abstract away this complexity, for example various dataset formats, various model formats, effect of hyper parameters during training and integrations with other systems. This makes a product with a user experience (UX) that is easy to use.\n\nOur strategy to overcome them is putting ourselves in the shoes of an average user when designing our app, but also actively involve people who satisfy our ideal user profile in early-stage testing of our releases. We also have a long history of working with people who satisfy that profile, which means we already possess a deeper understanding of their needs. We have also introduced a chatbot that possesses all of our gathered knowledge over the years, available to any customer that uses our solution, which aims to provide easy and clear explanation to the most common user inquiries, and trust us, when it comes to ML and computer vision, there\u2019s not many of those. Finally, we offer comprehensive help dialogs in the app, which explain the most important concepts depending on which page the user is on, via text and videos. All of the this enables our users not only to be able to use the platform, but also learn some important basics as they go.\n\nApplications such as security are advanced considerably utilizing AI together with UAS platforms. Image: Visionplatform.ai.\n\nTECHNOLOGICAL INTEGRATION\n\nIUS: How does VisionPlatform.ai integrate with edge computing devices like NVIDIA Jetson, and what advantages does this bring to your users?\n\nA: Visionplatform was born from a company named supplai, which was a project-based AI vision company which primarily focused in the logistics industry. From our previous customer experiences, we found most customers are interested in making their own applications. So, this was where the idea of\n\nvisionplatform was conceived. We aim to be a low code AI platform which democratizes Computer Vision and AI and is easily deployable on the NVIDIA Jetson edge devices. Our past experience has given us a lot of expertise in Jetson and the ability to maximize their performance. Jetsons are by far the most advanced edge IOT devices capable of running relatively large AI models in real time. With the deep stream framework, which brings together hardware accelerated encoding and machine optimized AI runtimes, these devices are still the market leader in terms of edge AI computing with very low power consumption, another big advantage. We know how to make the best use of them and have proven that time and time again. Our users can rest assured that the edge solution that visionplatform provides is not only at an end-end cost effective solution but also it maximizes the capability of these highly efficient hardware.\n\nIUS: Can you discuss the decision-making process behind supporting both edge and cloud computing for AI vision tasks?\n\nA: While edge computing is attractive to a lot of our customers especially in the domains where data privacy and low latency are a key, such as logistics, manufacturing and surveillance, we have also seen a market need to support cloud-based solutions. AI in the cloud has advantages of running significantly higher workloads at the cost of latency. Auto-labeling, for example, makes sense if it is hosted in the cloud as the datasets are large and the models generally for this task need to be large. For this task the user is generally not too concerned about the time it takes to process their media, so such a feature is provided within a cloud framework.\n\nA commercial drone outfitted with the NVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nINDUSTRY APPLICATIONS\n\nIUS: Can you provide examples of how Visionplatform.ai can be used in the drone industry to enhance capabilities such as autonomous navigation and real-time data analysis?\n\nA: We have integrations with the DJI drones. There are two types of integrations we have done with drones. The first is getting a [high-res video] stream directly from the drone. The second is stream a real time messaging protocol (RTMP) stream into the Jetson. In the first case we will have a Jetson mounted on a drone and then run our AI algorithms from the stream directly. This has little latency but the extra weight of the jetson needs to be considered. This solution is perfect for larger drones. The second solution is for lighter drones which have good network connectivity. Though there is some latency introduced, there is no extra weight on the drone itself. These two approaches aim to cover a wide range of drone applications.\n\nSome interesting use cases from customers include drones for security and situational awareness. Having something like an anomaly detection model which identifies anomalous behavior can help spot threats from the sky without human risk. Also, there are useful applications for coast guards like detecting people who are far into the sea.\n\nDrones are also used quite a lot for inspections. Having a segmentation algorithm coupled with object detection will help the drone in inspecting bridges, windmills and give real time localization of defects. Currently, these inspections require a 3D reconstruction from pictures and an expert to classify these defects. This process can take days to weeks. A real time detection solution on the drone can, however, reduce this time to hours.\n\nIUS: How about adjacent industries like robotics and security?\n\nA: With visionplatform we can make any camera into a security camera without replacing it. Applications in security like detecting people with guns or detecting people in unauthorized places and people going to dangerous areas can be made easily with visionplatform with little cost or change in the current infrastructure. For enhancing robots with vision capabilities, especially with vision models, the user can write text prompts to guide the robot. This is a cutting-edge application that opens up many possibilities. Also, our integration with the Milestone VMS already is a huge step in the field of intelligent video analytics for security applications.\n\nVisionplatform.ai\u2019s drone based and AI-enhanced imaging technology. Image: Visionplatform.ai.\n\nMODEL TRAINING AND DEPLOYMENT\n\nIUS: How does your platform handle the training and deployment of AI models to ensure they are robust and reliable across different applications?\n\nA: Our experience in ML over the last few years has led us to finding and developing strategies that make a model robust. From augmentations, smart data splitting and concepts like freezing layers of the model, which can be understood easily by the average person, we have more than enough strategies to make a robust model. Another cool feature about visionplatform is that our LLM chatbot is itself a domain expert in AI and can help guide the user to realize complex tasks. Making sure the training metrics are good we can be sure of the reliability, and we plan to include out-of-distribution detection soon so the model in fact knows when something it sees is out of its understanding. Our Jetsons also run 24/7 with several fallbacks when an application fails so the user knows the application is always running and if it crashes the user is notified.\n\nIUS: What strategies do you employ to continuously improve model accuracy and performance based on user feedback and data?\n\nA: One of the biggest aspects of machine learning is continuous training and improvement of the model. We have a video acquisition pipeline to capture live streams from a video and store it as a part of the user\u2019s dataset. The user also has an event browser where they can pick video events where the model made a false detection and use them into the next round of training. Additionally, we plan to incorporate more data visibility features like displaying the number of classes in a dataset as well as other statistics in order to guide the user into making a good dataset that best trains the model.\n\nNVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nFUTURE DIRECTIONS\n\nIUS: What upcoming features or improvements can users expect from Visionplatform.ai?\n\nA: Newer models, more LLM focused work flows where the user can talk to a chatbot, and it can create an application for them so there are little to no clicks involved in an application. More dataset understanding and visibility and a place to manage all your deployed Jetsons are our immediate features we have planned. But as the ML field brings up new models and ideas, we plan to incorporate them also as long as they are in line with our core vision.\n\nIUS: How do you see the role of AI vision evolving in industries like logistics and public safety over the next five years?\n\nA: AI vision is going to have a large impact in the logistics and security industries in the next 5 years. These industry segments have been generally a bit slow to adapt to AI vision traditionally, but things are changing as AI is becoming easier to integrate and more reliable. Over the next five years, AI vision will revolutionize logistics and public safety by enhancing automation, real-time monitoring and operational efficiency. In logistics, AI vision will improve sorting, picking and inventory tracking while enabling the widespread use of autonomous vehicles and predictive maintenance. Supply chains will benefit from dynamic routing and automated quality control powered by vision algorithms. In public safety, AI vision will enhance surveillance, facial recognition, and emergency response, providing rapid assessments and automated alerts. Traffic management will see smarter control systems and real-time accident detection. Visionplatform\u2019s ability to make any existing IP camera to an AI camera is key for this transformation."
    },
    {
        "title": "Oracle Investment in Chipmaker Ampere Gives It Option to Own",
        "link": "https://www.bloomberg.com/news/articles/2024-09-26/oracle-s-investment-in-chipmaker-ampere-gives-it-option-to-own",
        "description": "Oracle Corp. said it owns 29% of startup Ampere Computing LLC and can exercise future investments options that would give it ...",
        "image_url": "https://www.bing.com/th?id=OVFT.WvhFXS0pdXLfCFhr_zdDdy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "8h",
        "source": "Bloomberg L.P.",
        "article_content": "Why did this happen?\n\nPlease make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy."
    },
    {
        "title": "How the Seattle Freeze and \u2018celebration of pessimism\u2019 hurts the city\u2019s startup scene",
        "link": "https://www.geekwire.com/2024/how-the-seattle-freeze-and-celebration-of-pessimism-hurts-the-citys-startup-scene/",
        "description": "Dave Cotter of D3 Advisors; Yifan Zhang of Ai2 Incubator; Jenny Rojanasthien of NCW Tech Alliance, Skye Henderson of Cowles ...",
        "image_url": "https://www.bing.com/th?id=OVFT.APCA942yERwc4xkQHRFPti&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "13h",
        "source": "GeekWire",
        "article_content": "Content not available"
    },
    {
        "title": "Behind the Scenes of Unity Software's Latest Options Trends",
        "link": "https://www.benzinga.com/insights/options/24/09/41030386/behind-the-scenes-of-unity-softwares-latest-options-trends",
        "description": "Based on the trading activity, it appears that the significant investors are aiming for a price territory stretching from $20 ...",
        "image_url": "https://www.bing.com/th?id=OVFT.0XU4Uq7DqNYbqjOeUcenoi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "15h",
        "source": "Benzinga.com",
        "article_content": "Financial giants have made a conspicuous bullish move on Unity Software. Our analysis of options history for Unity Software U revealed 24 unusual trades.\n\nDelving into the details, we found 50% of traders were bullish, while 33% showed bearish tendencies. Out of all the trades we spotted, 2 were puts, with a value of $73,625, and 22 were calls, valued at $2,431,788.\n\nPredicted Price Range\n\nBased on the trading activity, it appears that the significant investors are aiming for a price territory stretching from $20.0 to $60.0 for Unity Software over the recent three months.\n\nVolume & Open Interest Development\n\nExamining the volume and open interest provides crucial insights into stock research. This information is key in gauging liquidity and interest levels for Unity Software's options at certain strike prices. Below, we present a snapshot of the trends in volume and open interest for calls and puts across Unity Software's significant trades, within a strike price range of $20.0 to $60.0, over the past month.\n\nUnity Software Call and Put Volume: 30-Day Overview\n\nBiggest Options Spotted:\n\nSymbol PUT/CALL Trade Type Sentiment Exp. Date Ask Bid Price Strike Price Total Trade Price Open Interest Volume U CALL TRADE NEUTRAL 10/18/24 $3.55 $3.2 $3.4 $20.00 $1.7M 13.5K 5.2K U CALL SWEEP BEARISH 12/20/24 $3.15 $3.1 $3.1 $23.00 $55.8K 3.5K 254 U CALL TRADE BEARISH 01/17/25 $5.3 $5.25 $5.25 $20.00 $54.6K 20.0K 5.5K U CALL SWEEP BULLISH 11/15/24 $2.88 $2.79 $2.88 $23.00 $53.2K 5.2K 900 U CALL SWEEP NEUTRAL 11/15/24 $2.66 $2.56 $2.61 $23.00 $48.2K 5.2K 1.2K\n\nAbout Unity Software\n\nUnity Software Inc provides a software platform for creating and operating interactive, real-time 3D content. The platform can be used to create, run, and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices. The business is spread across the United States, Greater China, EMEA, APAC, and Other Americas, of which key revenue is derived from the EMEA region. The products are used in the gaming industry, architecture and construction sector, animation industry, and designing sector.\n\nIn light of the recent options history for Unity Software, it's now appropriate to focus on the company itself. We aim to explore its current performance.\n\nUnity Software's Current Market Status\n\nWith a trading volume of 9,822,277, the price of U is down by -2.7%, reaching $22.57.\n\nCurrent RSI values indicate that the stock is may be overbought.\n\nNext earnings report is scheduled for 43 days from now.\n\nTurn $1000 into $1270 in just 20 days?\n\n20-year pro options trader reveals his one-line chart technique that shows when to buy and sell. Copy his trades, which have had averaged a 27% profit every 20 days. Click here for access.\n\nTrading options involves greater risks but also offers the potential for higher profits. Savvy traders mitigate these risks through ongoing education, strategic trade adjustments, utilizing various indicators, and staying attuned to market dynamics. Keep up with the latest options trades for Unity Software with Benzinga Pro for real-time alerts."
    },
    {
        "title": "Life Insurance Software Market Is Booming So Rapidly with Adobe, Vertafore, Salesforce, EIS Group",
        "link": "https://insurancenewsnet.com/oarticle/life-insurance-software-market-is-booming-so-rapidly-with-adobe-vertafore-salesforce-eis-group",
        "description": "Some of the key players profiled in the study are Salesforce, Microsoft, SAP, Vertafore, IBM, Applied Systems Inc., Oracle, ...",
        "image_url": "https://www.bing.com/th?id=OVFT.fYkzyHxnHAYKThxH56Zh_C&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "Insurancenewsnet.com18h",
        "source": "Insurancenewsnet.com",
        "article_content": "EIN Presswire\n\nLife Insurance Software Market\n\nGlobal Life Insurance Software Market is expected to grow from 4.5 billion USD in 2023 to 12 billion USD by 2030, with a CAGR of 10% from 2024 to 2030\n\nHTF Market Intelligence Consulting is uniquely positioned to empower and inspire with research and consulting services to empower businesses with growth strategies, by offering services.\" -- Nidhi Bhawsar\n\nPUNE , MAHARASHTRA, INDIA , September 24, 2024 /EINPresswire.com/ -- Global Life Insurance Software Market by Player, Region, Type, Application and Sales Channel (2024-2032) is the latest research study released by HTF MI evaluating the market risk side analysis, highlighting opportunities, and leveraging strategic and tactical decision-making support. The report provides information on market trends and development, growth drivers, technologies, and the changing investment structure of the Global Life Insurance Software Market. Some of the key players profiled in the study are Salesforce, Microsoft, SAP, Vertafore , IBM , Applied Systems Inc. , Oracle, Sapiens International Corporation , Adobe, Vertafore , IBM , ACI, Sinosoft, Hyland Software , Aptitude Software , EIS Group & HawkSoft .\n\nDownload Sample Pages PDF (Including Full TOC, Table & Figures) @ https://www.htfmarketreport.com/sample-report/3356619-2021-2030-report-on-global-life-insurance-software-market?utm_source=Ganesh_EINnews&utm_id=Ganesh\n\nAccording to HTF Market Intelligence, the Global Life Insurance Software Market is expected to grow from 4.5 billion USD in 2023 to 12 billion USD by 2030, with a CAGR of 10% from 2024 to 2030.\n\nLife Insurance Software Market Overview:\n\nThe study provides a detailed outlook vital to keep market knowledge up to date segmented by Term Life, Annuity, Whole Life, Group Life & Unit-linked, , On-premises & Cloud-based, and 18+ countries across the globe along with insights on emerging & major players. If you want to analyze different companies involved in the Life Insurance Software industry according to your targeted objective or geography we offer customization according to your requirements.\n\nLife Insurance Software Market: Demand Analysis & Opportunity Outlook 2032\n\nLife Insurance Software research study defines the market size of various segments & countries by historical years and forecasts the values for the next 6 years. The report is assembled to comprise qualitative and quantitative elements of Life Insurance Software industry including market share, market size (value and volume 2019-2024, and forecast to 2032) that admires each country concerned in the competitive marketplace. Further, the study also caters to and provides in-depth statistics about the crucial elements of Life Insurance Software which includes drivers & restraining factors that help estimate the future growth outlook of the market.\n\nThe segments and sub-section of Life Insurance Software market is shown below:\n\nThe Study is segmented by the following Product/Service Type: On-premises & Cloud-based\n\nMajor applications/end-users industry are as follows: Term Life, Annuity, Whole Life, Group Life & Unit-linked\n\nSome of the key players involved in the Market are: Salesforce, Microsoft, SAP, Vertafore , IBM , Applied Systems Inc. , Oracle, Sapiens International Corporation , Adobe, Vertafore , IBM , ACI, Sinosoft, Hyland Software , Aptitude Software , EIS Group & HawkSoft\n\nImportant years considered in the Life Insurance Software study:\n\nHistorical year \u2013 2019-2023; Base year \u2013 2023; Forecast period** \u2013 2024 to 2032 [** unless otherwise stated]\n\nBuy Life Insurance Software research report @ https://www.htfmarketreport.com/buy-now?format=1&report=3356619\n\nIf opting for the Global version of Life Insurance Software Market; then the below country analysis would be included:\n\n\u2022 North America (the USA , Canada , and Mexico )\n\n\u2022 Europe ( Germany , France , the United Kingdom , Netherlands , Italy , Nordic Nations, Spain , Switzerland , and the Rest of Europe )\n\n\u2022 Asia-Pacific ( China , Japan , Australia , New Zealand , South Korea , India , Southeast Asia , and the Rest of APAC)\n\n\u2022 South America ( Brazil , Argentina , Chile , Colombia , the Rest of the countries, etc.)\n\n\u2022 the Middle East and Africa ( Saudi Arabia , United Arab Emirates , Israel , Egypt , Turkey , Nigeria , South Africa , Rest of MEA)\n\nKey Questions Answered with this Study\n\n1) What makes Life Insurance Software Market feasible for long-term investment?\n\n2) Know value chain areas where players can create value.\n\n3) Teritorry that may see a steep rise in CAGR & Y-O-Y growth?\n\n4) What geographic region would have better demand for products/services?\n\n5) What opportunity emerging territory would offer to established and new entrants in Life Insurance Software market?\n\n6) Risk side analysis connected with service providers?\n\n7) How influencing are factors driving the demand of Life Insurance Software in the next few years?\n\n8) What is the impact analysis of various factors in the Global Life Insurance Software market growth?\n\n9) What strategies of big players help them acquire a share in a mature market?\n\n10) How Technology and Customer-Centric Innovation is bringing big Change in Life Insurance Software Market?\n\nThere are 15 Chapters to display the Global Life Insurance Software Market\n\nChapter 1, Overview to describe Definition, Specifications, and Classification of Global Life Insurance Software market, Applications [Term Life, Annuity, Whole Life, Group Life & Unit-linked], Market Segment by Types , On-premises & Cloud-based;\n\nChapter 2, the objective of the study.\n\nChapter 3, Research methodology, measures, assumptions, and analytical tools\n\nChapters 4 and 5, Global Life Insurance Software Market Trend Analysis, Drivers, Challenges by Consumer Behavior, Marketing Channels, Value Chain Analysis\n\nChapters 6 and 7, show the Life Insurance Software Market Analysis, segmentation analysis, characteristics;\n\nChapters 8 and 9, show Five forces (bargaining power of buyers/suppliers), Threats to new entrants, and market conditions;\n\nChapters 10 and 11, show analysis by regional segmentation [ North America , Europe , Asia-Pacific etc], comparison, leading countries, and opportunities; Customer Behaviour\n\nChapter 12, identifies the major decision framework accumulated through Industry experts and strategic decision-makers;\n\nChapters 13 and 14, are about the competitive landscape (classification and Market Ranking)\n\nChapter 15, deals with Global Life Insurance Software Market sales channel, research findings, conclusion, appendix, and data source.\n\nGet Details about the Scope; Before Procuring Global Life Insurance Software Market Research Study @ https://www.htfmarketreport.com/enquiry-before-buy/3356619-2021-2030-report-on-global-life-insurance-software-market?utm_source=Ganesh_EINnews&utm_id=Ganesh\n\nThanks for showing interest in Life Insurance Software Industry Research Publication; you can also get individual chapter-wise sections or region-wise report versions like North America , LATAM, United States , GCC, Southeast Asia , Europe , APAC, Japan , United Kingdom , India or China , etc\n\nLegal Disclaimer:\n\nEIN Presswire provides this news content \"as is\" without warranty of any kind. We do not accept any responsibility or liability\n\nfor the accuracy, content, images, videos, licenses, completeness, legality, or reliability of the information contained in this\n\narticle. If you have any complaints or copyright issues related to this article, kindly contact the author above."
    }
]