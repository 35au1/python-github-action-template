[
    {
        "title": "Image shows UFO downed by US fighter jet in Canadian airspace days after Chinese spy craft incident",
        "link": "https://www.foxnews.com/us/image-shows-ufo-downed-us-fighter-jet-canadian-airspace-days-after-chinese-spy-craft-incident",
        "description": "A newly released image shows a UFO that was brought down last year by a U.S. military fighter jet in Canadian airspace.",
        "image_url": "https://www.bing.com/th?id=OVFT.cdR3vtc8uaCgSaW7qmfZty&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "6h",
        "source": "Fox News",
        "article_content": "An image of a UFO that was shot down by a U.S. fighter jet over Canada last year was released Wednesday.\n\nThe blurry photo, which appears to be a photocopy of an email printout, of the unidentified cylindrical object was captured as it hovered in the air in February 2023, days before it was shot down over Canada's Yukon Territory, which borders Alaska, according to CTVNews.\n\nThe news outlet obtained the image through an information request from Canada\u2019s Department of National Defence.\n\nThe object initially drifted from Alaska into Canadian airspace. The North American Aerospace Defense Command first detected the \"high-altitude airborne object\" flying at about 40,000 feet over Alaska and scrambled jets to monitor it.\n\nUFOs SOAR FROM TABOO TO PRESIDENTIAL: \u2018TIME HAS COME TO INJECT UAPs INTO THE \u2026 ELECTIONS,\u2019 INSTITUTE SAYS\n\nIt was shot down on Feb. 11, 2023, and was one of three aerial objects brought down that month after the downing of a Chinese surveillance balloon days earlier.\n\nAll three objects were smaller than the Chinese spy balloon that drifted from Alaska across the U.S. before it was shot down off the coast of South Carolina on Feb. 4, 2023.\n\n\"Yesterday afternoon, I also spoke with President Biden and confirmed together that we will continue to do everything necessary to protect the sovereignty of our shared North American airspace but also to do everything necessary to keep our citizens safe,\" Canadian Prime Minister Justin Trudeau said at the time.\n\nCONGRESSMAN GIVES 270 DAYS TO DISCLOSE ALL UFO DOCS: \u2018IF YOU GOT NOTHING TO HIDE, RELEASE THE FILES\u2019\n\nA U.S. F-22 Raptor fired an AIM 9X missile to down the object. It was believed to be a \"small metallic balloon with a tethered payload.\"\n\nBiden later said the three objects were not related to the Chinese spy craft incident.\n\nThe image of the UFO was initially declassified in Canada and approved for public release before the acting assistant deputy minister for public affairs questioned whether the public should be allowed to view it, according to the news outlet.\n\n\"Should the image be released, it would be via the [Canadian armed forces] social media accounts,\" the official wrote in an internal email. \"Given the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\"\n\nCLICK TO GET THE FOX NEWS APP\n\nOfficials held back the release pending \"U.S. engagement.\" Fox News Digital has reached out to the Canadian Department of National Defence."
    },
    {
        "title": "New UFO Doc \u2018The Program\u2019 Set From \u2018The Phenomenon\u2019 Director James Fox (Exclusive)",
        "link": "https://www.hollywoodreporter.com/movies/movie-news/ufo-doc-the-program-james-fox-1236011733/",
        "description": "The feature, which will be screened for buyers, will focus on the bipartisan Congressional effort to uncover government ...",
        "image_url": "https://www.bing.com/th?id=OVFT.rbvs0gPJdEgDk7xnICLs_y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "2h",
        "source": "The Hollywood Reporter",
        "article_content": "As the conversation around UFOs/UAPs continues to heat up on Capitol Hill, documentarian James Fox has set his next feature on the subject.\n\nFox directs The Program, which is described as exploring \u201cthe unprecedented bipartisan congressional effort to uncover what intelligence agencies really know about UFOs, now referred to as UAP.\u201d In July 2023, three former Pentagon officials testified about their experience with or sightings of UFOs/ UAPs, and the U.S. Senate introduced the bipartisan UAP Disclosure Act. Earlier this month, it was reported that the Senate Armed Services Committee is looking to hold a UFO hearing after the elections in November.\n\nThe doc, narrated by Peter Coyote, will include extensive interviews with insiders, experts and politicians. Christopher Mellon, the former deputy assistant secretary of defense for intelligence, and Stanford University\u2019s Dr. Gary Nolan, will be among those who appear in the doc. Also set are Jason Sands, a master sergeant in the United States Air Force; Craig Lindsay, formerly of Scotland\u2019s Royal Air Force Office; and Nick Pope, formerly of the U.K.\u2019s Ministry of Defense. Among others, Andre Carson, Sen. Harry Reid and Rep. Tim Burchett are interviewed, along with Kirk McConnell, who previously held a position in Senate Armed Services Committee.\n\nFox and Lance Mungia produced the doc, with Jim Martin and Henry Marx of Lab 9 Films executive producing. Verve Ventures is handling sales, with the doc set to screen for buyers.\n\n\u201cI\u2019ve been making films on the topic of UFOs (now referred to as UAP) since the early 1990s. I never thought I\u2019d live to see the day when high level military officials would testify under oath to a bipartisan group of lawmakers that the United States government has been hiding definitive proof that we are not alone. The program lays out a very compelling case that disclosure is upon us,\u201d said Fox, who was behind previous docs The Phenomenon and Moment of Contact.\n\nAdded Martin and Marx: \u201cWe are thrilled to bring James Fox\u2019s most powerful work, The Program, to the widest possible audience. This film is banging on the door of UFO disclosure, demanding the attention and conversation it deserves.\u201d\n\nThe conversation about UFOs/UAPs is heating up as top officials continue to share their stories. Recently, Jay Stratton, the former director of the U.S. government\u2019s secretive Unidentified Aerial Phenomena Task Force, struck a memoir deal with HarperCollins. Last month, Luis Elizondo \u2014 the former head of the Pentagon\u2019s program investigating UFOs/ UAPs \u2014 released the book Imminent: Inside the Pentagon\u2019s Hunt for UFOs, which became a New York Times best-seller."
    },
    {
        "title": "New photo shows UFO hovering over Canada before it was shot down by US fighter jet",
        "link": "https://nypost.com/2024/09/25/us-news/ufo-flying-over-canada-shot-down-by-us-in-feb-2023-seen-in-new-picture/",
        "description": "A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.",
        "image_url": "https://www.bing.com/th?id=OVFT.7gqJISWouleXztzizdk58y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "17h",
        "source": "New York Post",
        "article_content": "A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon.\n\nThe grainy, blurry image captured the \u201ccylindrical\u201d \u201csuspected balloon\u201d 40,000 feet above the Great White North in February 2023 days before it was taken out, according to CTVNews, which obtained the image through an information request with Canada\u2019s Department of National Defence.\n\nA US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.\n\n4 A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon. Department of National Defence / CTV News\n\nOfficials in the US and Canada began tracking the UFO again when it crossed into Canadian airspace, and Prime Minister Justin Trudeau gave the order to shoot it down just after 4:50 p.m.\n\nAn American pilot struck the object with an AIM 9x missile.\n\nThe airborne object previously described as a \u201csmall, metallic balloon with a tethered payload\u201d was spotted amid three other cases in which North America dealt with unidentified objects in the sky.\n\nBetween Feb. 10 and Feb 12, three objects were spotted floating over North America before they were downed over Alaska, the Yukon and Lake Huron, respectively.\n\nThey were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023.\n\n4 The Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off. Department of National Defence / CTV News\n\n4 A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023. REUTERS\n\nChina used American technology in its spy balloon that snooped on US military bases earlier this year, a federal investigation analyzing the object\u2019s debris has found.\n\nThe Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off.\n\n\u201cAttached is an image approved to be released,\u201d Canadian military leaders wrote in a Feb. 15, 2023, email, according to the outlet. \u201cWe are looking at getting a better one to send to you.\u201d\n\nThe Department of National Defence was going forward with the release of the image before the acting assistant deputy minister for public affairs questioned whether the public should see it.\n\nStart and end your day informed with our newsletters Morning Report and Evening Update: Your source for today's top stories Thanks for signing up! Enter your email address Please provide a valid email address. By clicking above you agree to the Terms of Use and Privacy Policy. Never miss a story. Check out more newsletters\n\n\u201cShould the image be released, it would be via the [Canadian armed forces] social media accounts,\u201d the official wrote. \u201cGiven the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\u201d\n\nIt was later recommended the Canadian department should wait on the release \u201cpending US engagement,\u201d leading to the photo never seeing the light of day for over a year and a half.\n\nPresident Biden confirmed the three objects were shot down but said there were no \u201csuggestions they were related to China\u2019s spy balloon program, or that they were surveillance vehicles from any other country.\u201d\n\n4 They were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023. REUTERS\n\nSearches for the debris from all three objects were conducted, but both the Canadian Mounties and the US called off the efforts days later.\n\nPoor weather conditions and slim chances of finding the debris fields were cited as reasons for not continuing the searches."
    },
    {
        "title": "Presidents CANNOT UFO Information On Their Own because of the Atomic Energy Act.",
        "link": "https://www.msn.com/en-us/news/politics/presidents-cannot-ufo-information-on-their-own-because-of-the-atomic-energy-act/vi-AA1rbWPe?ocid=BingNewsVerp",
        "description": "A reddit thread stated today and listed that Presidents cannot discose UFO information on their own accord due to the Atomic ...",
        "image_url": "https://www.bing.com/th?id=OVF.2KaSM50YMmcBFfJvb040fg&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "Down To Earth With Kristian Harloff on MSN13h",
        "source": "Down To Earth With Kristian Harloff on MSN",
        "article_content": ""
    },
    {
        "title": "Eerie declassified photo shows \u2018cylinder\u2019 UFO shot down by US fighter jets over Canada in highly secretive intercept",
        "link": "https://www.thesun.ie/tech/13882327/eerie-declassified-photo-ufo-us-fighter-jet/",
        "description": "AN EERIE picture declassified by the Canadian government has revealed a bizarre 'cylinder' UFO that was shot down by a US ...",
        "image_url": "https://www.bing.com/th?id=OVFT.smbMgZqtnT7jJpPf4KSl4y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "12h",
        "source": "Irish Sun",
        "article_content": "An email from a Canadian Brigadier-General reveals the description of the mystery object\n\nSKY SECRETS Eerie declassified photo shows \u2018cylinder\u2019 UFO shot down by US fighter jets over Canada in highly secretive intercept\n\nAN EERIE picture declassified by the Canadian government has revealed a bizarre \"cylinder\" UFO that was shot down by a US fighter jet in a secret operation.\n\nThe grainy image, understood to be a copy of an email printout, shows a white, doughnut-shaped object that flew over Alaska in 2023.\n\n5 The doughnut-shaped object appears to have a white body with a metallic top Credit: CTVNEWS\n\n5 The grainy image is understood to be a copy of an email printout obtained through an FOI request Credit: CTVNEWS\n\n5 A US Air Force F-22 fighter jet shot down the mystery object in a highly secretive operation Credit: Alamy\n\nIt was one of the three \"unidentified aerial objects\" that were shot down by a US Air Force F-22 fighter jet during a highly secretive joint mission with the Canadian armed forces.\n\nThe downing followed the spotting of a gigantic Chinese spy balloon the size of three buses which was seen lurking over the US.\n\nThe circular UFO along with the other two mystery objects were initially thought to be \"suspected spy balloons\", but were reportedly much smaller than the towering Chinese inflatable object that sparked chaos in America.\n\nAnd its picture was released as part of a Freedom of Information request filed by an anonymous Canadian citizen, and obtained by a reporter at CTVNews.ca.\n\nmore on UFOs MAN IN BLACK I was Pentagon UFO chief - I know \u2018non-human\u2019 bodies have been found on Earth\n\nOne email from Eric Laforest, a Canadian Brigadier-General, revealed the description of the mystery object.\n\nThe email described it as a \"cylindrical object\" that appeared to have a white body and a metallic with a metallic top.\n\nHe added: \" 20-foot wire hanging below with a package of some sort suspended from it.\"\n\nA top memo from the Pentagon office revealed that the object appeared to be a \"small, metallic balloon with a tethered payload below it.\"\n\nThe image appears to have been taken from an aircraft below it, although that has not been confirmed.\n\nDark portions seen at the top of the UFO in the picture may depict the metallic top of the object, as reported by the US and Canadian authorities.\n\nThe image of the object was distributed internally just after the incident.\n\nIt was declassified for public release, but the decision as help back shortly.\n\nAn official working with Canada's Department of National Defence (DND) reportedly warned that releasing this unclassified UFO image \"may create more confusion\".\n\nBut the released picture is now raising more concerns abut the mysteries behind UFO sightings across the skies in the US.\n\nJust a few days ago, Donald Trump vowed to reveal exclusive UFO footage if he is elected back to the office in the November elections.\n\nThe Republican presidential candidate said he would push the Pentagon to declassify the alleged UFO sighting videos in a sensational interview.\n\nTrump, who is hoping to beat Democratic rival Kamla Harris in the upcoming presidential elections, is known to have a decade-long fascination with aliens and unexplainable sightings.\n\nHe told popular American podcaster Lex Fridman that he would \"surely\" make secret footage of alleged UFO sightings public.\n\nWhile most sightings have been deemed balloons, other reports lead the office to investigate UFOs that they say are anomalous.\n\nTrump has previously suggested he would reveal more information from a wide range of classified files to the American people.\n\nThe real threat of UFOs and aliens FOR decades, UFOs and aliens were considered to be make belief things created by people in tinfoil hats but they are now considered a threat to national security. Long gone are those who claim conspiracy theories are all false as many are now discussed at the highest levels of government with US officials even admitting their existence. As more and more credible witnesses continue to come forward to tell their extraordinary stories publicly. The 2010s saw decades of stigmas around extraterrestrial life start to break down as politicians made UFO sightings a matter of national security. Across the world, governments have also unveiled some spooky truths with some even showcasing \"dead alien corpses\" on display for Congress. Researchers recently verified the legitimacy of a set of three-fingered mummies as potential evidence of \"non-human\" life forms. A line-up of doctors confirmed at Mexico's Congress on Tuesday that the bodies, purportedly not of this Earth, were in fact real, once-living organisms. The Pentagon also released a blockbuster 1,574 pages of real-life X-Files in 2022, related to its secretive UFO programme. The haul includes reports into research on the biological effects of UFO sightings on humans, sets out categorisations for paranormal experiences, and studies into sci-fi-style tech. Top UFO chief Sean Kirkpatrick told the world last year that he is set to step down from his job following his stern warning of concerning activity \"in our backyard.\" The Pentagon's UFO analysis office launched a UFO reporting service to the public after admitting to uncovering \"some things\" and calling the high number of suspicious activity either a foreign power or aliens. Navy jet footage has revealed the intriguing images of a government-confirmed UFO baffling the internet. The United States Government launched the All-domain Anomaly Resolution Office (AARO) in 2022 to investigate reports of unidentified flying objects (UFOs).\n\nIn 2021, Trump signed a bill calling on intelligence agencies to find out the truth behind UFO military base sightings.\n\nTrump also said he had heard some \"interesting things\" about aliens as he hinted he may declassify files on the infamous Roswell UFO.\n\nRoswell is regarded as one of the most notorious UFO incidents.\n\nIt happened when a rancher discovered a mysterious crash site on his pasture in New Mexico in 1947.\n\nThe US Air Force said it was a crashed weather balloon, and later admitted it was part of a secret nuclear test.\n\nTheories still rage about the crash, however, with the most outlandish claiming it was a flying saucer filled with alien bodies that were recovered and taken to Area 51.\n\n5 Speaking on Lex Fridman's podcast, Trump claimed he had faced pressure to declassify previous records of alien encounters Credit: YouTube/Lex Fridman"
    },
    {
        "title": "Beyond The Cloud: AI Opens The Door For The Next Wave Of B2B Applications",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/beyond-the-cloud-ai-opens-the-door-for-the-next-wave-of-b2b-applications/",
        "description": "Daniel Saks is the CEO of Landbase, an intelligent go-to-market automation company, and co-founder of unicorn AppDirect.",
        "image_url": "https://www.bing.com/th?id=OVFT.dtNvi50CcMCQN6_lFGfmji&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "16h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "If Generative AI Is The New Operating System, Agents Are The New Apps",
        "link": "https://www.forbes.com/sites/janakirammsv/2024/09/25/if-generative-ai-is-the-new-operating-system-agents-are-the-new-apps/",
        "description": "AI agents are likely to become as ubiquitous as traditional applications. Businesses that effectively leverage them will gain ...",
        "image_url": "https://www.bing.com/th?id=OVFT.XvOCnHcu2w_5CX2KSMZFJS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "20h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Kobiton Announces New AI Capabilities for Mobile App Developers",
        "link": "https://finance.yahoo.com/news/kobiton-announces-ai-capabilities-mobile-120000273.html",
        "description": "The mobile app testing company will offer an AI issue aggregation engine, which would allow developers to group related ...",
        "image_url": "https://www.bing.com/th?id=OVFT.Wr2hNRu0hBSQ13oJOxa5PC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "16h",
        "source": "YAHOO!Finance",
        "article_content": "Kobiton\n\nThe mobile app testing company will offer an AI issue aggregation engine, which would allow developers to group related errors and identify shared commonalities across testing sessions\n\nATLANTA, Sept. 25, 2024 (GLOBE NEWSWIRE) -- Kobiton , a leader in mobile app testing, announces its plans to provide mobile app developers with new AI-enabled testing tools.\n\n\n\nKobiton\u2019s current use of AI begins when it captures device \u201cexhaust\u201d during each test session. This exhaust includes critical data such as test steps, screenshots, full video capture at 30 frames per second, device logs, system metrics, XML for each test step, network payloads and device health statistics. This data is collected in real-time while the application is under test, and is then fed into Kobiton\u2019s AI gateway.\n\nKobiton\u2019s AI gateway is more than just a proprietary system. It allows customers and an ecosystem of third-party AI providers to integrate their own AI algorithms to analyze the mobile device exhaust. Already, Kobiton has established key partnerships with AI-centric industry leaders such as Grafana k6, Applitools and Appdome. When these AI-powered tools detect app issues, the results are ingested into Kobiton\u2019s Session Explorer, an intuitive i-Movie-like interface that provides an in-depth view of test evidence and output. Users can inspect exactly when and where an issue occurred along a timeline, offering users greater visibility into the testing process.\n\nEarly next year, Kobiton will roll out an AI issue aggregation engine that allows users to group related errors and identify shared commonalities across test sessions. For example, issues that appear distinct, such as button occlusion across different devices, can be identified as stemming from the same cause, such as a shared screen resolution. Kobiton\u2019s AI issue aggregation engine can consolidate these errors into a single bug, eliminating manual steps and streamlining the debugging process for developers.\n\n\u201cBy enabling our customers to tap into a variety of powerful AI engines, visualize their data in a graphical interface and identify commonalities across errors, we are setting a new standard for efficiency and accuracy in mobile app testing,\u201d said Frank Moyer, CTO of Kobiton. \u201cWe are excited to be at the forefront of this initiative.\u201d\n\nKobiton\u2019s new AI features, including the issue aggregation engine, will be available in the first half of 2025. To learn more about Kobiton\u2019s AI-augmented testing workflows and see a demo, visit Kobiton in the Expo at StarWest , the largest event held exclusively for QA professionals.\n\nStory continues\n\nAbout Kobiton\n\nKobiton empowers enterprises to accelerate mobile app delivery through manual, automated, and no-code testing on real devices. Kobiton's AI-augmented mobile testing platform uniquely delivers one-hour continuous testing and integration. Founded in 2016, Kobiton is venture-backed and headquartered in Atlanta. More info at www.kobiton.com .\n\nContact:\n\nKevin Wolf\n\nkevin@tgprllc.com\n\n\n\n"
    },
    {
        "title": "Micron shares surge after upbeat first-quarter forecast due to AI demand for memory chips",
        "link": "https://www.reuters.com/technology/micron-forecasts-first-quarter-revenue-above-estimates-2024-09-25/?os=TMB&ref=app",
        "description": "Micron Technology shares surged roughly 14% in after-hours trading after the memory maker forecast higher than expected first ...",
        "image_url": "https://www.bing.com/th?id=OVFT.4t0Aal5ikGDwyE-v3My9HC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "5h",
        "source": "Reuters",
        "article_content": "Content not available"
    },
    {
        "title": "Nothing Teases OS 3.0 With an AI App Drawer",
        "link": "https://www.techopedia.com/news/nothing-teases-os-3-0-with-an-ai-app-drawer",
        "description": "Nothing\u2019s upcoming OS 3.0 builds upon its distinct appearance with more custom widgets, lock screen options, an AI-powered ...",
        "image_url": "https://www.bing.com/th?id=OVF.v7wMpALGJ3afud69M0d8YA&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "Techopedia19h",
        "source": "Techopedia",
        "article_content": "Content not available"
    },
    {
        "title": "Exclusive: Seen any paranormal activity on your Ring device? You could win $100,000",
        "link": "https://www.msn.com/en-us/news/technology/exclusive-seen-any-paranormal-activity-on-your-ring-device-you-could-win-100-000/ar-AA1r74hR?ocid=BingNewsVerp",
        "description": "Ring\u2019s 'Great Ghost Search' will award $100,000 for whoever submits compelling paranormal or ghostly activity captured by a ...",
        "image_url": "https://www.bing.com/th?id=OVFT.lLSzBH7Q7ZqkMApvpW742S&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "14hon MSN",
        "source": "USA TODAY on MSN",
        "article_content": ""
    },
    {
        "title": "How The Scariest Movie of 2009 Launched an Unstoppable Hollywood Studio",
        "link": "https://www.inverse.com/entertainment/paranormal-activity-anniversary-15-years",
        "description": "Blumhouse had already existed for a few years, but 'Paranormal Activity' cracked the code and turned it into a powerhouse.",
        "image_url": "https://www.bing.com/th?id=OVFT.Nr5VFjObBu8WsvnkzNRaXy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Inverse16h",
        "source": "Inverse",
        "article_content": "You kind of had to be there.\n\nParanormal Activity, like The Blair Witch Project before it, is a movie best experienced in a large dark room with 100 screaming strangers. Maybe that\u2019s true of most movies, but found-footage thrillers attempt to hijack your brain into thinking they\u2019re real in a way that just doesn\u2019t work when you\u2019re watching it at home when the lights are on and phone notifications are vying for your attention.\n\nBut even if you can\u2019t re-experience the original sensation of seeing Paranormal Activity in theaters when it was released back on September 25, 2009, it\u2019s still worth reflecting on how this micro-budget horror movie managed to become a worldwide phenomenon, and how it changed the entire industry in the process.\n\nThe plot is simple. A young couple, Katie and Micah, move in together. Katie then tells Micah that she\u2019s been haunted by an evil spirit ever since she was a kid, so Micah sets up a camera and records everything in the house, including their bedroom, while they sleep. The haunting starts small (a door moves on its own, there are some light noises), but things escalate within a few weeks, leading to a terrifying finale where Katie becomes possessed by a demon and murders Micah.\n\nParanormal Activity was made with just $15,000 and filmed in one week in first-time director Oren Peli\u2019s own home. Peli cast two unknown actors, shot the movie on a home video camera, and never bothered writing a script; like with The Blair Witch Project, actors were told to improvise based on a loose outline.\n\nKatie Featherston as Katie. Blumhouse\n\nIn a 2009 interview with Shock Till You Drop, Peli explained his lo-fi, found-footage approach.\n\n\u201cI wanted to make it look as real and natural as possible,\u201d he said. \u201cI\u2019ve always been drawn to this storytelling style. It breaks the mental barrier when audiences see a regular film and become aware of the camera movements, they know a crew is there and there are stars. When you strip all of this away, the audience thinks they are seeing something with a higher degree of plausibility. The suspending of disbelief becomes all the easier. You have an audience that's more invested in the story and the characters.\u201d\n\nParanormal Activity made almost $200 million at the box office and spawned a seven-movie franchise, but its legacy is even bigger than that. Peli\u2019s thriller also gave rise to one of the biggest names in horror today: Jason Blum.\n\nJason Blum attends the Film Independent's Spirit Awards in 2010. Angela Weiss/WireImage/Getty Images\n\nAfter debuting at Screamfest in 2007, Paranormal Activity earned some Hollywood buzz. It landed on the desk of Blumhouse CEO Jason Blum, then an executive at Miramax, who worked with Peli to edit the movie and submit it to Sundance. They were rejected, but didn\u2019t give up, and eventually, an early copy of Paranormal Activity found its way to Steven Spielberg.\n\nSpielberg made a deal with Peli and Blum to release the movie through Paramount. The plan was to completely reshoot it with a bigger budget while releasing the original cut as a DVD extra, but after a test screening scared audiences so much that some people walked out, the team realized they had a potential hit on their hands. The rest is history.\n\nSinister followed a similar formula, giving director Scott Derrickson the freedom to experiment. Blumhouse\n\nSpeaking to The LA Times just days before Paranormal Activity finally hit theaters, Jason Blum broke down exactly what makes the movie so special. \u201cOnce every five years, a guy makes a movie for a nickel that can cross over to a broad audience,\" he said.\n\nYou could practically hear the gears turning in Blum\u2019s head. While his studio, Blumhouse, had already existed for a few years, it was Paranormal Activity that cracked the code. Movies like Insidious and Sinister would soon follow, giving ambitious directors little money but lots of freedom to make bold horror movies that could rake in millions and launch new franchises.\n\nIn that sense, we have Paranormal Activity to thank for our current glut of horror movies. Blumhouse is still pumping them out 15 years later, and so is everyone else, from indie studios like A24 to Hollywood titans like Paramount. Even Disney is cashing in on horror thanks to its Fox acquisition and the IP, like Alien, that came with it.\n\nBut while Paranormal Activity\u2019s legacy may be mighty, the movie itself hasn\u2019t exactly held up, at least not in the context that most people experience movies these days.\n\n\u201cYou watch it in your bedroom, it can look like your kid made it,\u201d Blum said back in 2009. \u201cYou watch it with an audience, it's an entirely different experience.\u201d\n\nSo if you want to watch Paranormal Activity the way it was meant to be seen, just get 100 of your closest friends and family together in a dark room. If that\u2019s not viable, you can explore the entire genre it spawned instead."
    },
    {
        "title": "Catch a ghost on your Ring camera? You can get $100K for the video",
        "link": "https://www.yahoo.com/entertainment/catch-ghost-ring-camera-100k-162202746.html",
        "description": "Catch a \"ghost\" on your Ring camera this fall? Ring wants to see it \u2014 and they may be willing to pay you for it.",
        "image_url": "https://www.bing.com/th?id=OVFT.hsx_wkS-4DNxYdIozQuXxy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "12h",
        "source": "Yahoo",
        "article_content": "Catch a ghost on your Ring camera? You can get $100K for the video\n\n(KTLA) \u2014 Your Ring camera may catch video of packages being dropped off, friends visiting, and cute animal activities, but the home surveillance company is hoping you\u2019ll catch some different, paranormal activity this Halloween season.\n\nRing is inviting users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize.\n\nAny form of paranormal activity \u2014 ghosts, ghouls, and anywhere in between \u2014 is welcome, according to Ring.\n\nRing offering $1M for proof of \u2018extraterrestrial life\u2019 caught on camera\n\n\u201cFrom supernatural sightings of floating orbs and unexplained shadows to family and friends wearing silly costumes. Funny, frightening, fashionable, all of it. If you find a ghost, we want to see it,\u201d the contest website said.\n\nThe company is inviting its users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize. (Ring)\n\n\u201cFinn Wolfhard, star of \u2018Ghostbusters\u2019 and Netflix\u2019s \u2018Stranger Things,\u2019 and Paranormal Investigator Katrina Weidman will serve as part of the judging team for Ring\u2019s Great Ghost Search, helping to select the winning entry,\u201d a news release said.\n\nOnly the first 5,000 entries received through Nov. 1 will be considered for the grand prize. According to Ring, only the first 30 seconds of each video will be considered. Videos will be awarded points, with a maximum of 100 points available.\n\nPoints will be awarded based on the visibility or clarity of the \u201cghost\u201d or ghostly presence; whether the video surprises the judges with uniqueness; whether the judges were \u201cglued to the footage\u201d and how entertaining it was; and how unique the ghost\u2019s engagement with the Ring device was.\n\nRing users can enter the contest and find more details here.\n\nCopyright 2024 Nexstar Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.\n\nFor the latest news, weather, sports, and streaming video, head to PIX11."
    },
    {
        "title": "Your Ring Doorbell Could Earn You $100,000 This Halloween\u2014Here\u2019s How To Enter the Spooky Contest",
        "link": "https://www.yahoo.com/tech/ring-doorbell-could-earn-100-125401047.html",
        "description": "Ring Doorbell users, it\u2019s time to go ghost-hunting. The popular home security company announced that it will host a video ...",
        "image_url": "https://www.bing.com/th?id=OVF.HJ%2fO%2b8DmrUL3L0YMvGe1BA&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "15h",
        "source": "Yahoo",
        "article_content": "Ring Doorbell users, it\u2019s time to go ghost-hunting. The popular home security company announced that it will host a video competition with submissions centered around paranormal activity caught on a Ring camera. Keep reading to learn more about the Ring Doorbell Halloween challenge and how to enter for a chance to win $100,000!\n\nWhat to know about the Ring Doorbell Halloween challenge\n\nThe Ring Doorbell Halloween challenge began on September 24 and runs until November 1 or until 5,000 submissions are received. It will have winner, to whom the company will award $100,000 for a \"not-so-haunted house, ghost-free getaway, or any other earthly expense,\u201d according to a press release obtained by First for Women.\n\n\"Every day, we hear from our customers about surprising or unexpected footage captured by their Ring cameras. They love the ability to stay connected to what's happening \u2014 although paranormal sightings are understandably not the most welcome,\u201d Ring\u2019s Chief Commercial Officer, Mimi Swain, said in the same press release. \"Now, during Halloween, the busiest doorbell season of the year, we're calling on customers to keep an eye out for any ghostly activity. If they do capture a ghost on camera, we're going to help them escape their haunted situation. After all, what's Halloween without a few surprises?\"\n\nRing Doorbell\u2019s Halloween contest features a star-studded judging panel, including actor Finn Wolfhard of Stranger Things and paranormal investigator Katrina Weidman.\n\n\"Ring is known to catch all kinds of activity\u2014but I know if I saw a ghost on my Ring camera, I'd want to move out as fast as possible,\" said in the press release. \"This Halloween season, I'm relying on my Ring camera to alert me of any activity happening in and around my house\u2014even if it's the spooky or paranormal.\"\n\nWolfhard also posted a funny video, highlighting the competition on his Instagram. You can watch it below.\n\nHow to enter the Ring Doorbell Halloween challenge\n\nIf you think your video is spooky enough for the Ring Doorbell Halloween competition, all you have to do is submit it to ring.com/ghostsearch. You can also share your creepiest footage on social media by tagging @Ring and using the hashtag #RingGhostSearch to boost your chances of being featured.\n\nRing and the judges say they are looking for something \u201cseriously silly or totally unexplainable\u201d\u2014just like the sample video shared on their Instagram.\n\nThe doorbell company also shared another example of a video on their Instagram with the caption quoting the user who shared it: \u201cI noticed that the passenger door was wide open, so I walked around [and] closed it. As soon as I closed the door, the car attempted to start by itself. It was really creepy. I thought maybe my son was in there messing with me. I walked back over to the driver\u2019s side and leaned in, and when I checked the keys, they were in the off position and every hair on [my] body stood straight up.\u201d\n\nYou can watch that video below!\n\nGood luck! May the spooky odds be ever in your favor.\n\nFor more Halloween content, keep scrolling!\n\n\u2018Beetlejuice\u2019 Halloween Costumes and Decorations: Ideas from TikTok to Try\n\n14 DIY Fall Nail Designs That Pretty Up Fingertips\n\nStarbucks Fall Menu 2024: Get the Scoop on New and Returning Favorites"
    },
    {
        "title": "Got ghosts? Ring asks users for videos of paranormal activity in exchange for $100K",
        "link": "https://www.michigansthumb.com/news/article/ring-camera-great-ghost-search-2024-how-to-enter-19791924.php",
        "description": "Ring announced on Sept. 24, 2024, that users can submit videos of paranormal activity captured on their Ring doorbell or ...",
        "image_url": "https://www.bing.com/th?id=OVFT.jZlSkBiaLj3OBYpdNsQJcC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Huron Daily Tribune11h",
        "source": "Huron Daily Tribune",
        "article_content": "Content not available"
    },
    {
        "title": "Unexpected deep-sea discovery shines light on life in the twilight zone",
        "link": "https://phys.org/news/2024-09-unexpected-deep-sea-discovery-life.html",
        "description": "The ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to ...",
        "image_url": "https://www.bing.com/th?id=OVFT.fERzBQQCwkWUdJWljKZQWC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "13h",
        "source": "Phys.org",
        "article_content": "This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:\n\nA conductivity, temperature and depth (CTD) rosette used to sample water from the ocean's twilight zone during a GEOTRACES expedition in the Pacific Ocean. Credit: Alex Fox\n\nThe ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to 1,000 meters below the sea surface, where levels of iron, a key micronutrient, are so low that the growth of bacteria is restricted. To compensate, these bacteria produce molecules called siderophores, which help the bacteria scavenge trace amounts of iron from the surrounding seawater.\n\nA Nature paper detailing these unexpected findings from the Pacific Ocean could change the way scientists view microbial processes in the deep ocean and offer new insight into the ocean's capacity to absorb carbon.\n\n\"Understanding the organisms that facilitate carbon uptake in the ocean is important for understanding the impacts of climate change,\" said Tim Conway, associate professor of chemical oceanography at the USF College of Marine Science, who co-authored the recent study.\n\n\"When organic matter from the surface ocean descends to the deep ocean, it acts as a biological pump that removes carbon from the atmosphere and stores it in seawater and sediments. Measuring the rates and processes that influence this pump gives us insight into how and where the ocean stores carbon.\"\n\nCo-chief Scientist Phoebe Lam of the University of California, Santa Cruz and others removed the pump's damaged section of cable from the winch. Credit: Alex Fox\n\nTo conduct the study, researchers collected water samples from the upper 1,000 meters of the water column during an expedition through the eastern Pacific Ocean from Alaska to Tahiti. What they found in the samples surprised them.\n\nNot only were concentrations of siderophores high in surface waters where iron is expected to be deficient, but they were also elevated in waters between 200 and 400 meters deep, where nutrient and iron concentrations were thought to have little impact on the growth of bacteria.\n\n\"Unlike in surface waters, we did not expect to find siderophores in the ocean's twilight zone,\" said Conway.\n\n\"Our study shows that iron-deficiency is high for bacteria living in this region throughout much of the east Pacific Ocean, and that the bacteria use siderophores to increase their uptake of iron. This has a knock-on effect on the biological carbon pump, because these bacteria are responsible for the breakdown of organic matter as it sinks through the twilight zone.\"\n\nThe recent discovery was part of GEOTRACES, an international effort to provide high-quality data for the study of climate-driven changes in ocean biogeochemistry.\n\nLeft to right: CTD technician Kyle McQuiggan, Research Technician Keith Shadle and multi-talented Data Analyst Joseph Gum work together to repair the trace metal CTD rosette's connection to the ship. Credit: Alex Fox\n\nTubes awaiting samples in the hydro-lab of the Roger Revelle. Scripps ODF Chemistry Technician Erin Hunt monitors her samples in the background. Credit: Alex Fox\n\nOne of the pumps comes back on board the R/V Roger Revelle at sunset. Credit: Alex Fox\n\nInside the main lab's bubble, some of GP15's scientists found it necessary to create reminders that time was indeed passing. Credit: Alex Fox\n\nThe study of siderophores is still in the early stages. Researchers involved in GEOTRACES only recently developed reliable methods to measure these molecules in water samples, and they're still working to understand where and when microbes use siderophores to acquire iron.\n\nAlthough the research into siderophores is new, this study demonstrates their clear impact on the movement of nutrients in the ocean's twilight zone.\n\n\"For a full picture of how nutrients shape marine biogeochemical cycles, future studies will need to take these findings into account,\" said Daniel Repeta, senior scientist at Woods Hole Oceanographic Institution and co-author of the article.\n\n\"In other words, experiments near the surface must expand to include the twilight zone.\"\n\nMore information: Daniel Repeta et al, Microbial iron limitation in the ocean's twilight zone, Nature (2024). DOI: 10.1038/s41586-024-07905-z. www.nature.com/articles/s41586-024-07905-z Journal information: Nature"
    },
    {
        "title": "Deep-sea discovery shines light on life in the twilight zone",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925123650.htm",
        "description": "A new study could change the way scientists view microbial processes in the deep ocean. The unexpected findings expand our understanding of the impacts of climate change, including how and where the ...",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily4h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "AI Develops Proteins to Boost Drug and Science Discovery",
        "link": "https://www.miragenews.com/ai-develops-proteins-to-boost-drug-and-science-1324688/",
        "description": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more ...",
        "image_url": "https://www.bing.com/th?id=OVFT.t6A53DVVgUHq3_08BDTgeS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Armed robbery in Revesby6h",
        "source": "Armed robbery in Revesby",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature's evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\"Nature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\" said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \"EvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\"\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\"Engineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\" Klivans said. \"It also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\"\n\nUnlike Google DeepMind's AlphaFold, which applies AI to predict the shape and structure of proteins based on each one's sequence of amino acids, the Deep Proteins group's AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan's lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\"The models have come up with substitutions we never would have thought of,\" McLellan said. \"They work, but they aren't things we would have predicted, so they're actually finding some new space for stabilizing.\"\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company's new drug are only about 1 in 10. What's more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development-and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank-as well as the related UT-created framework on which it builds, Stability Oracle-are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster.\n\nUsing existing databases of naturally occurring protein sequences, the researchers who created EvoRank essentially lined up different versions of the same protein that appear in different organisms-from starfish to oak trees to humans-and compared them. At any given position in the protein, there might be one of several different amino acids that evolution has found to be useful, with nature selecting, say, 36% of the time the amino acid tyrosine, 29% of the time histidine, 14% of the time lysine-and even more importantly never leucine. Using this gold mine of existing data reveals an underlying logic in protein evolution. Researchers can knock out options that, evolution suggests, would result in killing the protein's functionality. The team uses all of this to train the new machine learning algorithm. Based on continuous feedback, the model learns which amino acid nature opted for during the past when evolving proteins, and it bases its understanding on what's plausible in nature and what is not.\n\nDiaz next plans to develop a \"multicolumn\" version of EvoRank that can evaluate how multiple mutations at the same time affect a protein's structure and stability. He also wants to build new tools for predicting how a protein's structure relates to its function.\n\nBesides Klivans and Diaz, computer science graduate student Chengyue Gong and UT alumnus James M. Loy co-authored both works. Tianlong Chen and Qiang Liu also contributed to EvoRank; Jeffrey Ouyang-Zhang, David Yang, Andrew D. Ellington and Alex G. Dimakis additionally contributed to Stability Oracle. The research was funded by the NSF, the Defense Threat Reduction Agency and The Welch Foundation."
    },
    {
        "title": "AI Trained on Evolution\u2019s Playbook Develops Proteins that Spur Drug and Scientific Discovery",
        "link": "https://cns.utexas.edu/news/research/ai-trained-evolutions-playbook-develops-proteins-spur-drug-and-scientific-discovery",
        "description": "EvoRank offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology ...",
        "image_url": "https://www.bing.com/th?id=OVFT.v_0f8vasR7xpb6PffHlZwS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Journalism in the Americas7h",
        "source": "Journalism in the Americas",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature\u2019s evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\u201cNature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\u201d said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \u201cEvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\u201d\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\u201cEngineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\u201d Klivans said. \u201cIt also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\u201d\n\nUnlike Google DeepMind\u2019s AlphaFold, which applies AI to predict the shape and structure of proteins based on each one\u2019s sequence of amino acids, the Deep Proteins group\u2019s AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan\u2019s lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\u201cThe models have come up with substitutions we never would have thought of,\u201d McLellan said. \u201cThey work, but they aren\u2019t things we would have predicted, so they\u2019re actually finding some new space for stabilizing.\u201d\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company\u2019s new drug are only about 1 in 10. What\u2019s more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development\u2014and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank\u2014as well as the related UT-created framework on which it builds, Stability Oracle\u2014are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster."
    },
    {
        "title": "Scientists discover a single-electron bond in a carbon-based compound",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925122902.htm",
        "description": "The discovery of a stable single-electron covalent bond between two carbon atoms validates a century-old theory.",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily8h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "How Will AI Affect Low-Code/No-Code Development?",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/how-will-ai-affect-low-codeno-code-development/",
        "description": "When implementing AI into low-code/no-code development, it is important to consider the risks and how to mitigate them.",
        "image_url": "https://www.bing.com/th?id=OVFT.3hoTdJIxRV-Fjg_OSCaXhy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "18h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Inside AI: No-Code Computer Vision and Edge Computing",
        "link": "https://insideunmannedsystems.com/inside-ai-no-code-computer-vision-and-edge-computing/",
        "description": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end ...",
        "image_url": "https://www.bing.com/th?id=OVFT.p3zLnocXw31jrXbR5a8NGy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "The Future of Autonomy12h",
        "source": "The Future of Autonomy",
        "article_content": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end no-code platform and edge computing capabilities.\n\nThey partner with businesses across industries to implement AI-powered computer vision technology. With the Visionplatform.ai software, users can train AI vision algorithms and integrate computer vision into their workflows. The solution enables users to detect, interpret and analyze objects, people and events in real-time, drawing insights and optimizing operations.\n\nVisionplatform.ai integrates edge computing capabilities and the use of high fps video streams instead of static images. The platform allows users to leverage the power of AI and computer vision at the edge, minimizing latency, improving responsiveness and ensuring data privacy.\n\nPLATFORM DESIGN AND DEVELOPMENT\n\nIUS: Can you explain the core design principles behind Visionplatform.ai?\n\nA: Our core design principles are simplicity, and ease of use. Our goal is to democratize computer vision to empower our users to make their own innovative solutions for real world problems.\n\nIUS: What were the biggest technical challenges you faced in developing a no-code AI vision platform, and how did you overcome them?\n\nA: Democratizing AI is a very difficult task. A field like ML and specifically computer vision has long been the playground of experts and professionals. It\u2019s a fact that the field of AI is not standardized. For experts this does not matter, but for the average user the barrier of entry into the field is very high. From a technical standpoint, our biggest challenge has been to abstract away this complexity, for example various dataset formats, various model formats, effect of hyper parameters during training and integrations with other systems. This makes a product with a user experience (UX) that is easy to use.\n\nOur strategy to overcome them is putting ourselves in the shoes of an average user when designing our app, but also actively involve people who satisfy our ideal user profile in early-stage testing of our releases. We also have a long history of working with people who satisfy that profile, which means we already possess a deeper understanding of their needs. We have also introduced a chatbot that possesses all of our gathered knowledge over the years, available to any customer that uses our solution, which aims to provide easy and clear explanation to the most common user inquiries, and trust us, when it comes to ML and computer vision, there\u2019s not many of those. Finally, we offer comprehensive help dialogs in the app, which explain the most important concepts depending on which page the user is on, via text and videos. All of the this enables our users not only to be able to use the platform, but also learn some important basics as they go.\n\nApplications such as security are advanced considerably utilizing AI together with UAS platforms. Image: Visionplatform.ai.\n\nTECHNOLOGICAL INTEGRATION\n\nIUS: How does VisionPlatform.ai integrate with edge computing devices like NVIDIA Jetson, and what advantages does this bring to your users?\n\nA: Visionplatform was born from a company named supplai, which was a project-based AI vision company which primarily focused in the logistics industry. From our previous customer experiences, we found most customers are interested in making their own applications. So, this was where the idea of\n\nvisionplatform was conceived. We aim to be a low code AI platform which democratizes Computer Vision and AI and is easily deployable on the NVIDIA Jetson edge devices. Our past experience has given us a lot of expertise in Jetson and the ability to maximize their performance. Jetsons are by far the most advanced edge IOT devices capable of running relatively large AI models in real time. With the deep stream framework, which brings together hardware accelerated encoding and machine optimized AI runtimes, these devices are still the market leader in terms of edge AI computing with very low power consumption, another big advantage. We know how to make the best use of them and have proven that time and time again. Our users can rest assured that the edge solution that visionplatform provides is not only at an end-end cost effective solution but also it maximizes the capability of these highly efficient hardware.\n\nIUS: Can you discuss the decision-making process behind supporting both edge and cloud computing for AI vision tasks?\n\nA: While edge computing is attractive to a lot of our customers especially in the domains where data privacy and low latency are a key, such as logistics, manufacturing and surveillance, we have also seen a market need to support cloud-based solutions. AI in the cloud has advantages of running significantly higher workloads at the cost of latency. Auto-labeling, for example, makes sense if it is hosted in the cloud as the datasets are large and the models generally for this task need to be large. For this task the user is generally not too concerned about the time it takes to process their media, so such a feature is provided within a cloud framework.\n\nA commercial drone outfitted with the NVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nINDUSTRY APPLICATIONS\n\nIUS: Can you provide examples of how Visionplatform.ai can be used in the drone industry to enhance capabilities such as autonomous navigation and real-time data analysis?\n\nA: We have integrations with the DJI drones. There are two types of integrations we have done with drones. The first is getting a [high-res video] stream directly from the drone. The second is stream a real time messaging protocol (RTMP) stream into the Jetson. In the first case we will have a Jetson mounted on a drone and then run our AI algorithms from the stream directly. This has little latency but the extra weight of the jetson needs to be considered. This solution is perfect for larger drones. The second solution is for lighter drones which have good network connectivity. Though there is some latency introduced, there is no extra weight on the drone itself. These two approaches aim to cover a wide range of drone applications.\n\nSome interesting use cases from customers include drones for security and situational awareness. Having something like an anomaly detection model which identifies anomalous behavior can help spot threats from the sky without human risk. Also, there are useful applications for coast guards like detecting people who are far into the sea.\n\nDrones are also used quite a lot for inspections. Having a segmentation algorithm coupled with object detection will help the drone in inspecting bridges, windmills and give real time localization of defects. Currently, these inspections require a 3D reconstruction from pictures and an expert to classify these defects. This process can take days to weeks. A real time detection solution on the drone can, however, reduce this time to hours.\n\nIUS: How about adjacent industries like robotics and security?\n\nA: With visionplatform we can make any camera into a security camera without replacing it. Applications in security like detecting people with guns or detecting people in unauthorized places and people going to dangerous areas can be made easily with visionplatform with little cost or change in the current infrastructure. For enhancing robots with vision capabilities, especially with vision models, the user can write text prompts to guide the robot. This is a cutting-edge application that opens up many possibilities. Also, our integration with the Milestone VMS already is a huge step in the field of intelligent video analytics for security applications.\n\nVisionplatform.ai\u2019s drone based and AI-enhanced imaging technology. Image: Visionplatform.ai.\n\nMODEL TRAINING AND DEPLOYMENT\n\nIUS: How does your platform handle the training and deployment of AI models to ensure they are robust and reliable across different applications?\n\nA: Our experience in ML over the last few years has led us to finding and developing strategies that make a model robust. From augmentations, smart data splitting and concepts like freezing layers of the model, which can be understood easily by the average person, we have more than enough strategies to make a robust model. Another cool feature about visionplatform is that our LLM chatbot is itself a domain expert in AI and can help guide the user to realize complex tasks. Making sure the training metrics are good we can be sure of the reliability, and we plan to include out-of-distribution detection soon so the model in fact knows when something it sees is out of its understanding. Our Jetsons also run 24/7 with several fallbacks when an application fails so the user knows the application is always running and if it crashes the user is notified.\n\nIUS: What strategies do you employ to continuously improve model accuracy and performance based on user feedback and data?\n\nA: One of the biggest aspects of machine learning is continuous training and improvement of the model. We have a video acquisition pipeline to capture live streams from a video and store it as a part of the user\u2019s dataset. The user also has an event browser where they can pick video events where the model made a false detection and use them into the next round of training. Additionally, we plan to incorporate more data visibility features like displaying the number of classes in a dataset as well as other statistics in order to guide the user into making a good dataset that best trains the model.\n\nNVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nFUTURE DIRECTIONS\n\nIUS: What upcoming features or improvements can users expect from Visionplatform.ai?\n\nA: Newer models, more LLM focused work flows where the user can talk to a chatbot, and it can create an application for them so there are little to no clicks involved in an application. More dataset understanding and visibility and a place to manage all your deployed Jetsons are our immediate features we have planned. But as the ML field brings up new models and ideas, we plan to incorporate them also as long as they are in line with our core vision.\n\nIUS: How do you see the role of AI vision evolving in industries like logistics and public safety over the next five years?\n\nA: AI vision is going to have a large impact in the logistics and security industries in the next 5 years. These industry segments have been generally a bit slow to adapt to AI vision traditionally, but things are changing as AI is becoming easier to integrate and more reliable. Over the next five years, AI vision will revolutionize logistics and public safety by enhancing automation, real-time monitoring and operational efficiency. In logistics, AI vision will improve sorting, picking and inventory tracking while enabling the widespread use of autonomous vehicles and predictive maintenance. Supply chains will benefit from dynamic routing and automated quality control powered by vision algorithms. In public safety, AI vision will enhance surveillance, facial recognition, and emergency response, providing rapid assessments and automated alerts. Traffic management will see smarter control systems and real-time accident detection. Visionplatform\u2019s ability to make any existing IP camera to an AI camera is key for this transformation."
    },
    {
        "title": "Chiefs' Andy Reid addresses idea Travis Kelce is 'old' and 'distracted' amid Taylor Swift concerns, bad start",
        "link": "https://www.foxnews.com/sports/chiefs-andy-reid-addresses-idea-travis-kelce-old-distracted-amid-taylor-swift",
        "description": "Travis Kelce is off to one of the worst starts of his career, but his head coach defended him Wednesday amid speculation he's ...",
        "image_url": "https://www.bing.com/th?id=OVFT.v7cKqIp1Bm6r5S0036xWDC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "5h",
        "source": "Fox News",
        "article_content": "Travis Kelce's performance during his second NFL season while dating Taylor Swift has raised eyebrows.\n\nKelce, 34, has just 69 receiving yards with no touchdowns through the first three games of the season. It's one of the slowest starts of his career. And Kelce's poor start this year has come with a much larger dose of scrutiny than most veteran tight ends with lower early-season production.\n\nHis relationship with Swift, the Chiefs' ambition to become the first NFL team in history to win three straight Super Bowls and a more intrusive political climate have somehow made Kelce a topic of negative discussion this week.\n\nESPN \"First Take\" host Stephen A. Smith used a segment on his show Wednesday to call out Kelce for his slow start, claiming his team won't accomplish its historic mission unless the tight end \"gets it going.\"\n\nCLICK HERE FOR MORE SPORTS COVERAGE ON FOXNEWS.COM\n\nWhoopi Goldberg also called out Chiefs fans who were blaming Swift for Kelce's poor performance during an episode of \"The View\" Tuesday. Goldberg appeared to be referencing recent social media conversation by fans blaming Kelce's relationship with Swift for his early-season struggles.\n\nSwift, who endorsed Kamala Harris Sept. 10, did not appear at the Chiefs' most recent game in Atlanta against the Falcons Sunday. It was the first game of the season she missed. She attended the first two games but sat separately from Brittany Mahomes, the wife of Kelce's teammate Patrick Mahomes, after their history of sitting together in suites last season.\n\nBrittany has been linked to support for Donald Trump on social media over the last month, raising questions about political differences between the celebrities.\n\nBefore the start of the season, both Patrick Mahomes and Kelce said Swift was also attempting to \"draw up plays\" for the Chiefs. These plays would focus on getting the ball to Kelce, which the tight end explained in an interview on the \"Rich Eisen Show\" Sept. 3.\n\nNow, after a start that indicates decline or distractions for the perennial Pro Bowler, his head coach has weighed in. Chiefs head coach Andy Reid addressed the negative comments about Kelce in a press conference Wednesday.\n\n\"I know people are saying that he's old or that he has distractions, but defenses don't think that,\" the Chiefs head coach told reporters. \"Trav is fine. He just keeps being Trav. He works his tail off. He hasn't lost a step. He's not distracted.\"\n\nTAYLOR SWIFT FANS WORRY FOR TRAVIS KELCE AS HE LOOKS DOWNCAST DURING GAME\n\nMahomes, who is having the worst statistical start to a season of his career, has also defended Kelce, saying Kelce's not getting the ball because opposing defenses are committing too many players to covering Kelce.\n\n\"We\u2019re calling a lot of plays for Travis, and it\u2019s like two or three people are going to him. He understands. That\u2019s the great thing about him is he wants to make an impact on the game, but he wants to win at the end of the day. I\u2019m gonna try to do my best to keep feeding him the ball whenever he\u2019s there, whenever he\u2019s open.\" Mahomes said.\n\n\"People are really emphasizing trying to take him away, and that\u2019s getting other guys open.\"\n\nCLICK HERE TO GET THE FOX NEWS APP\n\nDuring the Chiefs' win Sunday against the Falcons, the NBC broadcast showed Kelce looking downcast on the bench as he reviewed some film with 59 seconds to go before halftime. At that point, the Chiefs were on their way to a win and a perfect 3-0 start.\n\nThe footage of Kelce sparked a wave of online reactions. Fans wondered if his mood was related to Swift. However, Kelce said his mood at that moment was related to his level of play in this week's episode of \"New Heights.\"\n\nThat hasn't stopped others from theorizing Kelce is the victim of the \"NFL Wag Curse,\" a celebrity superstition about a pattern of misfortune for players who date high-profile celebrity women. Other examples include former Cowboys' quarterback Tony Romo, who dated Jessica Simpson from 2007-09; former Chicago Bears quarterback Jay Cutler, who dated reality star Kristin Cavallari; and Romo again when he dated Carrie Underwood.\n\nKelce was thought to have avoided the curse last year, when he helped lead the Chiefs to their third Super Bowl title of the Reid-Mahomes era.\n\nFollow Fox News Digital\u2019s sports coverage on X, and subscribe to the Fox News Sports Huddle newsletter."
    },
    {
        "title": "How the Seattle Freeze and \u2018celebration of pessimism\u2019 hurts the city\u2019s startup scene",
        "link": "https://www.geekwire.com/2024/how-the-seattle-freeze-and-celebration-of-pessimism-hurts-the-citys-startup-scene/",
        "description": "Dave Cotter of D3 Advisors; Yifan Zhang of Ai2 Incubator; Jenny Rojanasthien of NCW Tech Alliance, Skye Henderson of Cowles ...",
        "image_url": "https://www.bing.com/th?id=OVFT.APCA942yERwc4xkQHRFPti&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "9h",
        "source": "GeekWire",
        "article_content": "Content not available"
    },
    {
        "title": "Apple iPhone 16 vs. iPhone 15: Time for an upgrade?",
        "link": "https://www.digitaltrends.com/mobile/apple-iphone-16-vs-apple-iphone-15/",
        "description": "The iPhone 16 breathes new life into Apple's standard iPhone lineup, but is it a worthy upgrade over the iPhone 15? We walk ...",
        "image_url": "https://www.bing.com/th?id=OVF.A80HctMBidwXWf7nlrKwYw&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "8h",
        "source": "Digital Trends",
        "article_content": "For the past two years, Apple\u2019s standard iPhones have felt like awkward compromises, doing little more than bringing over features from their pro-level predecessors without adding anything significantly new to the mix. This year, everything changes.\n\nWith the release of the Apple iPhone 16, Apple\u2019s 2024 iPhone lineup is back in unity for the first time since at least 2021. Unlike the Dynamic Island and Action button in previous years, Apple isn\u2019t artificially limiting features like the new Camera Control to the iPhone 16 Pro. The balance between the standard and pro lineups has been restored, with the higher-end models differentiated only by truly Pro-level features and not mere design and user interface aspects. Mix in some unique new design changes, and the iPhone 16 feels like an iPhone that can stand on its own rather than being an also-ran.\n\nRecommended Videos\n\nWith so many fun improvements in this year\u2019s model, you may wonder where that leaves the iPhone 15. Last year\u2019s model lacked an Action button and has a processor that\u2019s now two generations behind, so is it still a good choice in today\u2019s iPhone landscape? Perhaps more significantly, is the iPhone 16 worth the upgrade if you\u2019re holding an iPhone 15 in your hand right now? Let\u2019s dive in and find out.\n\niPhone 16 vs. iPhone 15: specs\n\nApple iPhone 16\n\nApple iPhone 15\n\nSize 147.6 x 71.6 x 7.8 mm (5.81 x 2.82 x 0.31 inches) 147.6 x 71.6 x 7.8 mm (5.81 x 2.82 x 0.31 inches) Weight 170 grams (6 ounces) 171 grams (6.03 ounces) Screen size 6.1-inch Super Retina XDR OLED (60Hz) 6.1-inch Super Retina XDR OLED (60Hz) Screen resolution 2556 x 1179 resolution at 461 pixels per inch 2556 x 1179 resolution at 461 pixels per inch Operating system iOS 18 iOS 17 (upgradable to iOS 18) Storage 128GB, 256GB, 512GB 128GB, 256GB, 512GB MicroSD card slot No No Tap-to-pay services Apple Pay Apple Pay Processor Apple A18 Apple A16 Bionic RAM 8GB 6GB Cameras Rear: 48-megapixel primary, 12MP ultrawide Front: 12MP Rear: 48MP primary, 12MP ultrawide Front: 12MP Video Rear: Up to 4K at 60 frames-per-second (fps), FHD at 60 fps, and 240 fps for slow motion Front: Up to 4K at 60 fps Rear: Up to 4K at 60 fps, FHD at 120 fps, and 960 fps for slow motion Front: Up to 4K at 60 fps Bluetooth Yes, Bluetooth 5.3 Yes, Bluetooth 5.3 Ports USB-C USB-C Biometrics Face ID facial recognition Face ID facial recognition Water resistance IP68 IP68 Battery Size to be confirmed 27W fast charging 25W MagSafe charging 15W fast wireless charging 4.5W reverse wireless charging 3,349mAh 27W fast charging 15W MagSafe charging 15W fast wireless charging 4.5W reverse wireless charging\n\nApp marketplace Apple App Store Apple App Store Network support 5G 5G Colors Black, white, pink, teal, ultramarine Black, blue, green, yellow, pink Price From $799 From $799 Available from All major offline and online retailers All major offline and online retailers\n\niPhone 16 vs. iPhone 15: design\n\nIt shouldn\u2019t come as a big surprise that the iPhone 16 retains most of the same design elements of the past few generations as Apple has seemingly settled on the flat-edged style that began with the 2020 iPhone 12. Nevertheless, the iPhone 16 changes things up in at least one interesting way.\n\nSpecifically, while the dimensions of the iPhone 16 are identical to those of the iPhone 15 down to the millimeter, and the weight is essentially the same, the camera layout is a whole new ballgame \u2014 although perhaps it\u2019s more accurate to say it\u2019s a return to an older one. The cameras moved back to a tandem vertical arrangement from the iPhone 12 era, but the camera bump is an even bigger throwback that\u2019s more reminiscent of what we saw on the iPhone XS. A pill-shaped cutout encloses the two cameras, while the LED flash sits off to one side.\n\nIt\u2019s a classier and more elegant look compared to the big square camera bump that always seemed to take up more space than needed to hold the dual-camera array on Apple\u2019s non-Pro models. It also gives those standard models a look that sets them apart as unique devices in their own right rather than being second-class citizens to their iPhone Pro counterparts.\n\nThe other welcome change to this year\u2019s iPhone 16 is a selection of more saturated and vibrant colors. Apple introduced a new color-infused glass to last year\u2019s iPhone 15 models, but only in mostly weak pastel shades. Several reports earlier this year suggested Apple has improved the process, and the result appears to be deeper and richer colors. While it\u2019s a matter of taste, if you want a blue that actually looks blue instead of borderline white, the ultramarine iPhone 16 won\u2019t disappoint, and the new teal and pink options are similarly fun.\n\nThe sides of the iPhone 16 also show two key differences compared to previous models, with last year\u2019s iPhone 15 Pro Action button replacing the venerable ring/silent switch on all this year\u2019s models. There\u2019s also Apple\u2019s new Camera Control on the lower right side. We\u2019ll talk more about those later.\n\nThe durability of the iPhone 16 also improves slightly over the iPhone 15 thanks to the newer Ceramic Shield glass on the front. However, the iP68 rating remains the same, meaning the phone is rated for immersion in 6 meters of water for up to 30 minutes.\n\niPhone 16 vs. iPhone 15: display\n\nIf you were hoping for massive display improvements in this year\u2019s iPhone 16, we have bad news. It has what is essentially the same Super Retina XDR display as last year\u2019s iPhone 15, which hasn\u2019t been meaningfully improved since the iPhone 12 switched to OLED in the first place.\n\nThat\u2019s not to say it isn\u2019t a great screen, but some folks will be understandably disappointed by Apple\u2019s choice to stick with a 60Hz refresh rate on its standard models. Nevertheless, it still offers crisp text with a 460 pixel-per-inch (psi) density and HDR support with vibrant colors.\n\nThe iPhone 16 retains the 2,000-nit peak outdoor brightness introduced on last year\u2019s iPhone 15. The most significant change is its ability to drop brightness as low as a single nit so it won\u2019t overpower your eyes in a dark room. Other than that, it\u2019s the same display.\n\niPhone 16 vs. iPhone 15: performance and battery\n\nIf there\u2019s one groundbreaking improvement in this year\u2019s iPhone 16, it comes from Apple\u2019s decision to shake off its recent trend of using year-old chips in its standard iPhone models.\n\nBefore the iPhone 14, every year\u2019s iPhone model mostly shared the same A-series chips; the iPhone 13 version of the A15 had one less GPU core than its iPhone 13 Pro counterpart, but even that was an aberration. However, when the iPhone 14 came along, Apple split the deck, using the prior year\u2019s iPhone 13 Pro chip in that standard model and reserving its new A16 Bionic for the iPhone 14 Pro. That repeated last year with the iPhone 15 getting the A16, while the iPhone 15 Pro moved on to the much higher-performance A17 Pro.\n\nThankfully, that ends with this year\u2019s A18 chips, and it also means that the iPhone 16 gets a massive leap in performance over its predecessor since it\u2019s skipping two generations ahead. Apple is still using slightly different chips for its standard and pro models \u2014 an A18 and an A18 Pro \u2014 but they\u2019re the same class of silicon, with the primary difference being an extra GPU core in the A18 Pro, similar to the A15 chips of the iPhone 13 era.\n\nApple touts the new chips as ready for its Apple Intelligence AI features \u2014 the 16-core Neural Engine is twice as fast at handling machine learning models \u2014 but the A18 also packs in enough power to bring AAA console gaming to the standard iPhone. The hardware-accelerated ray tracing from last year\u2019s A17 Pro is here, offering noticeably faster frame rates, and Apple claims the five-core GPU is 40% faster than that of the iPhone 15 and twice as fast as the iPhone 12\u2019s.\n\nWill you notice that performance if you\u2019re not gaming or using AI? Probably not, but the A18 chip brings one other advantage to the table: efficiency. Combined with a bigger battery and improved power management in iOS 18, Apple promises the iPhone 16 can deliver two hours more video playback time on a single charge. That\u2019s been borne out in our testing, where the iPhone 16 got us through an entire day without needing a midday top-up.\n\nApple has also improved wireless charging speeds to support 25-watt charging, although this comes with the usual asterisk. You\u2019ll need to buy Apple\u2019s newest 25W MagSafe charger to support these faster speeds, which promise to top up your iPhone just as quickly as a wired charger. Considering that every Android handset maker has been doing the same for years, it\u2019s hard to see the need to invest in a proprietary charger as a deal-breaker. Standard Qi2 chargers can only deliver 15W right now, as that\u2019s the maximum supported by the new standard. Older Qi chargers remain limited to the same 7.5W speeds on the iPhone 16 as on every other iPhone model.\n\niPhone 16 vs. iPhone 15: cameras\n\nApple has a new name for its primary camera in this year\u2019s iPhone lineup \u2014 the 48-megapixel Fusion \u2014 but that may be the most significant change to the primary camera hardware over last year\u2019s iPhone 15. While Apple likely has an improved sensor under the hood, the raw specs remain the same: a 48MP sensor with an f/1.6 aperture that can capture 24MP and 48MP photos using computational photography.\n\nThe \u201cFusion\u201d branding is Apple\u2019s way of highlighting how the primary camera can do double-duty as both a 1x and 2x lens thanks to the pixel-cropping technique it debuted with the iPhone 14 Pro two years ago. However, it does get an anti-reflective coating that should help reduce lens flare.\n\nMeanwhile, the ultrawide camera retains its 12MP sensor, but increases the aperture to f/2.2, letting in 2.6x more light and gaining autofocus capabilities.\n\nDon\u2019t let those specs discourage you, as Apple has added some Pro-level features to the iPhone 16. These include the macro photo capabilities introduced on the iPhone 13 Pro, including macro video recording with slo-mo and time-lapse, plus 4K Dolby Vision video recording and Spatial videos and photos. The iPhone 16 also gains a wind noise reduction feature when recording video and a new Audio Mix to help balance out foreground and background noise.\n\nThe other significant computational photography improvement in this year\u2019s iPhone 16 is a whole new generation of Photographic Styles that go deeper into the image pipeline and can better factor in things like skin tone, color, highlights, and shadows in real time when making adjustments. There are now 15 styles to choose from instead of four, and they can be applied during capture. However, what\u2019s especially great is that, unlike the previous Photographic Styles that were baked into the images, these are non-destructive and can also be changed after the fact while editing in the Photos app. We think they\u2019re a really fun new twist that makes a much bigger difference than the core camera improvements.\n\niPhone 16 vs. iPhone 15: software and updates\n\nThe iPhone 15 and iPhone 16 can both run iOS 18; the iPhone 16 ships with it out of the box, while the iPhone 15 can get it as a free update.\n\nFor the most part, iOS 18 will function identically on both devices, putting them on par for software features. The only significant differences are new buttons like the Action button and Camera Control.\n\nHowever, the two iPhones will diverge more when iOS 18.1 ships next month with Apple Intelligence support since the iPhone 16 can handle that, while the iPhone 15 can\u2019t. That\u2019s technically still a hardware difference, although it may not feel like one to the casual user. That gap will increase even more as subsequent iOS 18 point releases add more Apple Intelligence features. Other subtle changes will highlight the presence of Apple Intelligence, such as a different interface that comes up when activating Siri.\n\nThis won\u2019t be a big deal if AI features aren\u2019t your cup of tea. It\u2019s also worth noting that it won\u2019t matter to folks outside the U.S. and other English-speaking countries until sometime next year, as Apple Intelligence is only launching in a few localized English languages over the next few months.\n\nFor software updates, it\u2019s fair to say that the older iPhone 15 will see the end of its update life slightly ahead of the iPhone 16, but that\u2019s likely years away for either model. Considering that iOS 18 still supports the 2018 iPhone XS and iPhone XR, it\u2019s a safe bet both models will make it to at least iOS 23.\n\niPhone 16 vs. iPhone 15: special features\n\nAs odd as it sounds, the marquee feature of this year\u2019s iPhone 16 lineup is a button. All four iPhone 16 models feature a new Camera Control on the lower-right side, below the side button, and while we found it took some time to get used to it, it\u2019s a lot of fun once you do.\n\nAs the name suggests, this button opens the camera app and takes pictures, but there\u2019s more to it than just those basic functions. It also features a capacitive touch surface that can be used to adjust other settings, like a touch-sensitive scroll wheel. In the built-in camera app, these are exposure, depth, zoom, camera field-of-view, Photographic Styles, and tone. However, third-party apps can also use the Camera Control, with developers defining their own functions.\n\nThe Camera Control is also lined up to trigger Visual Intelligence, a new feature that won\u2019t be available for the iPhone 16 until later this year. While a single press of the Camera Control will open your camera app of choice, holding the button down will trigger a new AI feature that will let you use your iPhone 16 camera to look up more information on real-world objects, whether that\u2019s reviews for a restaurant or the breed of a dog walking by.\n\nThe iPhone 16 also gains the Action button that replaced the ring/silent switch on last year\u2019s iPhone 15 Pro. That\u2019s a benefit over the iPhone 15, just like it was on last year\u2019s Pro model. It works just the same, letting you use it to trigger different built-in functions or even launch shortcuts.\n\nOf course, the other unique feature coming to the iPhone 16 is one that Apple won\u2019t stop talking about right now, even though it won\u2019t be available until next month. When Apple Intelligence does arrive, the iPhone 16 will be able to proofread and rewrite text and summarize notifications, messages, and audio recordings (including those made from phone calls, which is a new feature coming to all iPhone models in iOS 18.1). Other Apple Intelligence features will appear over subsequent iOS 18 point releases, including AI image generation, ChatGPT integration, and a more intelligent and personalized Siri.\n\niPhone 16 vs. iPhone 15: price and availability\n\nThe iPhone 16 can be purchased directly from Apple and most other major retailers and carriers \u2014 and the good news is that Apple still hasn\u2019t increased the price. It starts at the same $799 for 128GB of storage as the iPhone 15 did when it launched last year, and you can take it up to 256GB or 512GB storage for $899 and $1,099, respectively.\n\nAs usual, Apple is still selling last year\u2019s iPhone 15 at a lower price, with the base 128GB model selling for $699. Larger storage capacities are still available at the same relative price points \u2014 $799 for 256GB or $999 for 512GB \u2014 which could make it a tough call whether to opt for more storage or the newer iPhone 16.\n\niPhone 16 vs. iPhone 15: Should you upgrade?\n\nIf you\u2019re shopping for a new iPhone this year or upgrading from a much older model, there\u2019s little doubt the iPhone 16 is the one to buy. Apple has perhaps done the iPhone 16 a disservice by focusing too much on the new Apple Intelligence features, as there\u2019s a lot to recommend here even if you don\u2019t care about AI stuff.\n\nThe new design and saturated colors are the best we\u2019ve seen in years. The Camera Control button is useful and a lot of fun, as is the Action button, which was a Pro-exclusive feature last year. There are some meaningful camera improvements, particularly with the new Photographic Styles. The A18 chip is a giant leap forward in performance for a standard iPhone and means you\u2019ll be ready to handle any game the App Store can throw at it.\n\nPerhaps most significantly, this is the first time in at least three years that we\u2019ve had a non-Pro iPhone that hasn\u2019t felt like an afterthought. Not only does it pack in the same class of processor and feature the same physical controls, but the new design makes the standard model feel like it finally stands on its own as a viable and powerful alternative to the iPhone 16 Pro."
    },
    {
        "title": "Progress Software Corporation (PRGS): Short Seller Sentiment Is Bearish On This Affordable Tech Stock",
        "link": "https://www.msn.com/en-us/money/other/progress-software-corporation-prgs-short-seller-sentiment-is-bearish-on-this-affordable-tech-stock/ar-AA1rcRTu?ocid=BingNewsVerp",
        "description": "We recently compiled a list of the 10 Worst Affordable Tech Stocks to Buy According to Short Sellers. In this article, we are ...",
        "image_url": "https://www.bing.com/th?id=OVFT.n5sgqtRVg2_Qj-8WF6Amay&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "8hon MSN",
        "source": "Insider Monkey on MSN",
        "article_content": ""
    }
]