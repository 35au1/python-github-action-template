[
    {
        "title": "Image shows UFO downed by US fighter jet in Canadian airspace days after Chinese spy craft incident",
        "link": "https://www.aol.com/news/image-shows-ufo-downed-us-222320436.html",
        "description": "A newly released image shows a UFO that was brought down last year by a U.S. military fighter jet in Canadian airspace.",
        "image_url": "https://www.bing.com/th?id=OVFT.wgXqecRW3oKxy8khi9FdIi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "19m",
        "source": "AOL",
        "article_content": "An image of a UFO that was shot down by a U.S. fighter jet over Canada last year was released Wednesday.\n\nThe blurry photo, which appears to be a photocopy of an email printout, of the unidentified cylindrical object was captured as it hovered in the air in February 2023, days before it was shot down over Canada's Yukon Territory, which borders Alaska, according to CTVNews.\n\nThe news outlet obtained the image through an information request from Canada\u2019s Department of National Defence.\n\nThe object initially drifted from Alaska into Canadian airspace. The North American Aerospace Defense Command first detected the \"high-altitude airborne object\" flying at about 40,000 feet over Alaska and scrambled jets to monitor it.\n\nUFOs SOAR FROM TABOO TO PRESIDENTIAL: \u2018TIME HAS COME TO INJECT UAPs INTO THE \u2026 ELECTIONS,\u2019 INSTITUTE SAYS\n\nA newly released image shows the UFO that was shot down by a U.S. fighter jet over Canada in 2023.\n\nIt was shot down on Feb. 11, 2023, and was one of three aerial objects brought down that month after the downing of a Chinese surveillance balloon days earlier.\n\nRead On The Fox News App\n\nAll three objects were smaller than the Chinese spy balloon that drifted from Alaska across the U.S. before it was shot down off the coast of South Carolina on Feb. 4, 2023.\n\n\"Yesterday afternoon, I also spoke with President Biden and confirmed together that we will continue to do everything necessary to protect the sovereignty of our shared North American airspace but also to do everything necessary to keep our citizens safe,\" Canadian Prime Minister Justin Trudeau said at the time.\n\nCongressman Gives 270 Days To Disclose All Ufo Docs: \u2018If You Got Nothing To Hide, Release The Files\u2019\n\nA U.S. F-22 Raptor shot down the UFO in Canadian airspace.\n\nA U.S. F-22 Raptor fired an AIM 9X missile to down the object. It was believed to be a \"small metallic balloon with a tethered payload.\"\n\nBiden later said the three objects were not related to the Chinese spy craft incident.\n\nThe image of the UFO was initially declassified in Canada and approved for public release before the acting assistant deputy minister for public affairs questioned whether the public should be allowed to view it, according to the news outlet.\n\n\"Should the image be released, it would be via the [Canadian armed forces] social media accounts,\" the official wrote in an internal email. \"Given the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\"\n\nClick To Get The Fox News App\n\nOfficials held back the release pending \"U.S. engagement.\" Fox News Digital has reached out to the Canadian Department of National Defence.\n\n\n\n\n\nOriginal article source: Image shows UFO downed by US fighter jet in Canadian airspace days after Chinese spy craft incident"
    },
    {
        "title": "New UFO Doc \u2018The Program\u2019 Set from \u2018The Phenomenon\u2019 Director James Fox (Exclusive)",
        "link": "https://www.hollywoodreporter.com/movies/movie-news/ufo-doc-the-program-james-fox-1236011733/",
        "description": "The feature, which will be screened for buyers, will focus on the bipartisan Congressional effort to uncover government ...",
        "image_url": "https://www.bing.com/th?id=OVFT.rbvs0gPJdEgDk7xnICLs_y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "43m",
        "source": "The Hollywood Reporter",
        "article_content": "As the conversation around UFOs/UAPs continues to heat up on Capitol Hill, documentarian James Fox has set his next feature on the subject.\n\nFox directs The Program, which is described as exploring \u201cthe unprecedented bipartisan congressional effort to uncover what intelligence agencies really know about UFOs, now referred to as UAP.\u201d In July 2023, three former Pentagon officials testified about their experience with or sightings of UFOs/ UAPs, and the U.S. Senate introduced the bipartisan UAP Disclosure Act. Earlier this month, it was reported that the Senate Armed Services Committee is looking to hold a UFO hearing after the elections in November.\n\nThe doc, narrated by Peter Coyote, will include extensive interviews with insiders, experts and politicians. Christopher Mellon, the former deputy assistant secretary of defense for intelligence, and Stanford University\u2019s Dr. Gary Nolan, will be among those who appear in the doc. Also set are Jason Sands, a master sergeant in the United States Air Force; Craig Lindsay, formerly of Scotland\u2019s Royal Air Force Office; and Nick Pope, formerly of the U.K.\u2019s Ministry of Defense. Among others, Andre Carson, Sen. Harry Reid and Rep. Tim Burchett are interviewed, along with Kirk McConnell, who previously held a position in Senate Armed Services Committee.\n\nFox and Lance Mungia produced the doc, with Jim Martin and Henry Marx of Lab 9 Films executive producing. Verve Ventures is handling sales, with the doc set to screen for buyers.\n\n\u201cI\u2019ve been making films on the topic of UFOs (now referred to as UAP) since the early 1990s. I never thought I\u2019d live to see the day when high level military officials would testify under oath to a bipartisan group of lawmakers that the United States government has been hiding definitive proof that we are not alone. The program lays out a very compelling case that disclosure is upon us,\u201d said Fox, who was behind previous docs The Phenomenon and Moment of Contact.\n\nAdded Martin and Marx: \u201cWe are thrilled to bring James Fox\u2019s most powerful work, The Program, to the widest possible audience. This film is banging on the door of UFO disclosure, demanding the attention and conversation it deserves.\u201d\n\nThe conversation about UFOs/UAPs is heating up as top officials continue to share their stories. Recently, Jay Stratton, the former director of the U.S. government\u2019s secretive Unidentified Aerial Phenomena Task Force, struck a memoir deal with HarperCollins. Last month, Luis Elizondo \u2014 the former head of the Pentagon\u2019s program investigating UFOs/ UAPs \u2014 released the book Imminent: Inside the Pentagon\u2019s Hunt for UFOs, which became a New York Times best-seller."
    },
    {
        "title": "New photo shows UFO hovering over Canada before it was shot down by US fighter jet",
        "link": "https://nypost.com/2024/09/25/us-news/ufo-flying-over-canada-shot-down-by-us-in-feb-2023-seen-in-new-picture/",
        "description": "A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.",
        "image_url": "https://www.bing.com/th?id=OVFT.7gqJISWouleXztzizdk58y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "15h",
        "source": "New York Post",
        "article_content": "A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon.\n\nThe grainy, blurry image captured the \u201ccylindrical\u201d \u201csuspected balloon\u201d 40,000 feet above the Great White North in February 2023 days before it was taken out, according to CTVNews, which obtained the image through an information request with Canada\u2019s Department of National Defence.\n\nA US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023.\n\n4 A newly released image showing the UFO that was shot down by a US fighter jet over Canada in 2023 has added more questions and uncertainty to the object floating over the Yukon. Department of National Defence / CTV News\n\nOfficials in the US and Canada began tracking the UFO again when it crossed into Canadian airspace, and Prime Minister Justin Trudeau gave the order to shoot it down just after 4:50 p.m.\n\nAn American pilot struck the object with an AIM 9x missile.\n\nThe airborne object previously described as a \u201csmall, metallic balloon with a tethered payload\u201d was spotted amid three other cases in which North America dealt with unidentified objects in the sky.\n\nBetween Feb. 10 and Feb 12, three objects were spotted floating over North America before they were downed over Alaska, the Yukon and Lake Huron, respectively.\n\nThey were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023.\n\n4 The Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off. Department of National Defence / CTV News\n\n4 A US F-22 shot the object, which was first tracked flying over Alaska eight days earlier, out of the sky on Feb. 11, 2023. REUTERS\n\nChina used American technology in its spy balloon that snooped on US military bases earlier this year, a federal investigation analyzing the object\u2019s debris has found.\n\nThe Canadian government was prepared to release the photo of the Yukon UFO, having declassified it and approved it for the public to see before holding off.\n\n\u201cAttached is an image approved to be released,\u201d Canadian military leaders wrote in a Feb. 15, 2023, email, according to the outlet. \u201cWe are looking at getting a better one to send to you.\u201d\n\nThe Department of National Defence was going forward with the release of the image before the acting assistant deputy minister for public affairs questioned whether the public should see it.\n\nStart and end your day informed with our newsletters Morning Report and Evening Update: Your source for today's top stories Thanks for signing up! Enter your email address Please provide a valid email address. By clicking above you agree to the Terms of Use and Privacy Policy. Never miss a story. Check out more newsletters\n\n\u201cShould the image be released, it would be via the [Canadian armed forces] social media accounts,\u201d the official wrote. \u201cGiven the current public environment and statements related to the object being benign, releasing the image may create more questions/confusion, regardless of the text that will accompany the post.\u201d\n\nIt was later recommended the Canadian department should wait on the release \u201cpending US engagement,\u201d leading to the photo never seeing the light of day for over a year and a half.\n\nPresident Biden confirmed the three objects were shot down but said there were no \u201csuggestions they were related to China\u2019s spy balloon program, or that they were surveillance vehicles from any other country.\u201d\n\n4 They were all smaller than the suspected Chinese spy balloon that traveled from Alaska across the United States before it was shot down over South Carolina on Feb. 4, 2023. REUTERS\n\nSearches for the debris from all three objects were conducted, but both the Canadian Mounties and the US called off the efforts days later.\n\nPoor weather conditions and slim chances of finding the debris fields were cited as reasons for not continuing the searches."
    },
    {
        "title": "Presidents CANNOT UFO Information On Their Own because of the Atomic Energy Act.",
        "link": "https://www.msn.com/en-us/news/politics/presidents-cannot-ufo-information-on-their-own-because-of-the-atomic-energy-act/vi-AA1rbWPe?ocid=BingNewsVerp",
        "description": "A reddit thread stated today and listed that Presidents cannot discose UFO information on their own accord due to the Atomic ...",
        "image_url": "https://www.bing.com/th?id=OVF.2KaSM50YMmcBFfJvb040fg&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "Down To Earth With Kristian Harloff on MSN11h",
        "source": "Down To Earth With Kristian Harloff on MSN",
        "article_content": ""
    },
    {
        "title": "Eerie declassified photo shows \u2018cylinder\u2019 UFO shot down by US fighter jets over Canada in highly secretive intercept",
        "link": "https://www.thesun.ie/tech/13882327/eerie-declassified-photo-ufo-us-fighter-jet/",
        "description": "AN EERIE picture declassified by the Canadian government has revealed a bizarre 'cylinder' UFO that was shot down by a US ...",
        "image_url": "https://www.bing.com/th?id=OVFT.smbMgZqtnT7jJpPf4KSl4y&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ufo",
        "date": "9h",
        "source": "Irish Sun",
        "article_content": "An email from a Canadian Brigadier-General reveals the description of the mystery object\n\nSKY SECRETS Eerie declassified photo shows \u2018cylinder\u2019 UFO shot down by US fighter jets over Canada in highly secretive intercept\n\nAN EERIE picture declassified by the Canadian government has revealed a bizarre \"cylinder\" UFO that was shot down by a US fighter jet in a secret operation.\n\nThe grainy image, understood to be a copy of an email printout, shows a white, doughnut-shaped object that flew over Alaska in 2023.\n\n5 The doughnut-shaped object appears to have a white body with a metallic top Credit: CTVNEWS\n\n5 The grainy image is understood to be a copy of an email printout obtained through an FOI request Credit: CTVNEWS\n\n5 A US Air Force F-22 fighter jet shot down the mystery object in a highly secretive operation Credit: Alamy\n\nIt was one of the three \"unidentified aerial objects\" that were shot down by a US Air Force F-22 fighter jet during a highly secretive joint mission with the Canadian armed forces.\n\nThe downing followed the spotting of a gigantic Chinese spy balloon the size of three buses which was seen lurking over the US.\n\nThe circular UFO along with the other two mystery objects were initially thought to be \"suspected spy balloons\", but were reportedly much smaller than the towering Chinese inflatable object that sparked chaos in America.\n\nAnd its picture was released as part of a Freedom of Information request filed by an anonymous Canadian citizen, and obtained by a reporter at CTVNews.ca.\n\nmore on UFOs MAN IN BLACK I was Pentagon UFO chief - I know \u2018non-human\u2019 bodies have been found on Earth\n\nOne email from Eric Laforest, a Canadian Brigadier-General, revealed the description of the mystery object.\n\nThe email described it as a \"cylindrical object\" that appeared to have a white body and a metallic with a metallic top.\n\nHe added: \" 20-foot wire hanging below with a package of some sort suspended from it.\"\n\nA top memo from the Pentagon office revealed that the object appeared to be a \"small, metallic balloon with a tethered payload below it.\"\n\nThe image appears to have been taken from an aircraft below it, although that has not been confirmed.\n\nDark portions seen at the top of the UFO in the picture may depict the metallic top of the object, as reported by the US and Canadian authorities.\n\nThe image of the object was distributed internally just after the incident.\n\nIt was declassified for public release, but the decision as help back shortly.\n\nAn official working with Canada's Department of National Defence (DND) reportedly warned that releasing this unclassified UFO image \"may create more confusion\".\n\nBut the released picture is now raising more concerns abut the mysteries behind UFO sightings across the skies in the US.\n\nJust a few days ago, Donald Trump vowed to reveal exclusive UFO footage if he is elected back to the office in the November elections.\n\nThe Republican presidential candidate said he would push the Pentagon to declassify the alleged UFO sighting videos in a sensational interview.\n\nTrump, who is hoping to beat Democratic rival Kamla Harris in the upcoming presidential elections, is known to have a decade-long fascination with aliens and unexplainable sightings.\n\nHe told popular American podcaster Lex Fridman that he would \"surely\" make secret footage of alleged UFO sightings public.\n\nWhile most sightings have been deemed balloons, other reports lead the office to investigate UFOs that they say are anomalous.\n\nTrump has previously suggested he would reveal more information from a wide range of classified files to the American people.\n\nThe real threat of UFOs and aliens FOR decades, UFOs and aliens were considered to be make belief things created by people in tinfoil hats but they are now considered a threat to national security. Long gone are those who claim conspiracy theories are all false as many are now discussed at the highest levels of government with US officials even admitting their existence. As more and more credible witnesses continue to come forward to tell their extraordinary stories publicly. The 2010s saw decades of stigmas around extraterrestrial life start to break down as politicians made UFO sightings a matter of national security. Across the world, governments have also unveiled some spooky truths with some even showcasing \"dead alien corpses\" on display for Congress. Researchers recently verified the legitimacy of a set of three-fingered mummies as potential evidence of \"non-human\" life forms. A line-up of doctors confirmed at Mexico's Congress on Tuesday that the bodies, purportedly not of this Earth, were in fact real, once-living organisms. The Pentagon also released a blockbuster 1,574 pages of real-life X-Files in 2022, related to its secretive UFO programme. The haul includes reports into research on the biological effects of UFO sightings on humans, sets out categorisations for paranormal experiences, and studies into sci-fi-style tech. Top UFO chief Sean Kirkpatrick told the world last year that he is set to step down from his job following his stern warning of concerning activity \"in our backyard.\" The Pentagon's UFO analysis office launched a UFO reporting service to the public after admitting to uncovering \"some things\" and calling the high number of suspicious activity either a foreign power or aliens. Navy jet footage has revealed the intriguing images of a government-confirmed UFO baffling the internet. The United States Government launched the All-domain Anomaly Resolution Office (AARO) in 2022 to investigate reports of unidentified flying objects (UFOs).\n\nIn 2021, Trump signed a bill calling on intelligence agencies to find out the truth behind UFO military base sightings.\n\nTrump also said he had heard some \"interesting things\" about aliens as he hinted he may declassify files on the infamous Roswell UFO.\n\nRoswell is regarded as one of the most notorious UFO incidents.\n\nIt happened when a rancher discovered a mysterious crash site on his pasture in New Mexico in 1947.\n\nThe US Air Force said it was a crashed weather balloon, and later admitted it was part of a secret nuclear test.\n\nTheories still rage about the crash, however, with the most outlandish claiming it was a flying saucer filled with alien bodies that were recovered and taken to Area 51.\n\n5 Speaking on Lex Fridman's podcast, Trump claimed he had faced pressure to declassify previous records of alien encounters Credit: YouTube/Lex Fridman"
    },
    {
        "title": "Beyond The Cloud: AI Opens The Door For The Next Wave Of B2B Applications",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/beyond-the-cloud-ai-opens-the-door-for-the-next-wave-of-b2b-applications/",
        "description": "Daniel Saks is the CEO of Landbase, an intelligent go-to-market automation company, and co-founder of unicorn AppDirect.",
        "image_url": "https://www.bing.com/th?id=OVFT.dtNvi50CcMCQN6_lFGfmji&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "14h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "If Generative AI Is The New Operating System, Agents Are The New Apps",
        "link": "https://www.forbes.com/sites/janakirammsv/2024/09/25/if-generative-ai-is-the-new-operating-system-agents-are-the-new-apps/",
        "description": "AI agents are likely to become as ubiquitous as traditional applications. Businesses that effectively leverage them will gain ...",
        "image_url": "https://www.bing.com/th?id=OVFT.XvOCnHcu2w_5CX2KSMZFJS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "17h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "F5, NetApp team to streamline AI app deployments",
        "link": "https://www.networkworld.com/article/3539333/f5-netapp-team-to-streamline-ai-app-deployments.html",
        "description": "The vendors are combining their multicloud networking and data management platforms to make it easier for enterprises to ...",
        "image_url": "https://www.bing.com/th?id=OVFT.oCoV0cOlmcSU9S2GxHLoBi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "Network World10h",
        "source": "Network World",
        "article_content": "F5 and NetApp announced plans to combine their technologies to help enterprise customers securely deploy AI applications across multicloud environments.\n\nThe deal will bring together F5\u2019s secure multicloud networking technology and NetApp\u2019s BlueXP suite of data management products to streamline the use of large language models (LLM) across hybrid environments. The combination will make it easier for customers to build LLMs using enterprise data and create AI-based applications that can help monitor, manage and troubleshoot distributed networked systems.\n\nDistributed Cloud Network Connect is F5\u2019s connectivity service that ties together multiple cloud provider networks. NetApp\u2019s BlueXP offers a single integrated pane of glass for monitoring, troubleshooting and managing NetApp storage systems including OnCommand Network Attached Storage Protocol (ONTAP), All flash (AFF), and the Microsoft-NetApp developed Azure NetApp Files (ANF)."
    },
    {
        "title": "Kobiton Announces New AI Capabilities for Mobile App Developers",
        "link": "https://finance.yahoo.com/news/kobiton-announces-ai-capabilities-mobile-120000273.html",
        "description": "The mobile app testing company will offer an AI issue aggregation engine, which would allow developers to group related ...",
        "image_url": "https://www.bing.com/th?id=OVFT.Wr2hNRu0hBSQ13oJOxa5PC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "13h",
        "source": "YAHOO!Finance",
        "article_content": "Kobiton\n\nThe mobile app testing company will offer an AI issue aggregation engine, which would allow developers to group related errors and identify shared commonalities across testing sessions\n\nATLANTA, Sept. 25, 2024 (GLOBE NEWSWIRE) -- Kobiton , a leader in mobile app testing, announces its plans to provide mobile app developers with new AI-enabled testing tools.\n\n\n\nKobiton\u2019s current use of AI begins when it captures device \u201cexhaust\u201d during each test session. This exhaust includes critical data such as test steps, screenshots, full video capture at 30 frames per second, device logs, system metrics, XML for each test step, network payloads and device health statistics. This data is collected in real-time while the application is under test, and is then fed into Kobiton\u2019s AI gateway.\n\nKobiton\u2019s AI gateway is more than just a proprietary system. It allows customers and an ecosystem of third-party AI providers to integrate their own AI algorithms to analyze the mobile device exhaust. Already, Kobiton has established key partnerships with AI-centric industry leaders such as Grafana k6, Applitools and Appdome. When these AI-powered tools detect app issues, the results are ingested into Kobiton\u2019s Session Explorer, an intuitive i-Movie-like interface that provides an in-depth view of test evidence and output. Users can inspect exactly when and where an issue occurred along a timeline, offering users greater visibility into the testing process.\n\nEarly next year, Kobiton will roll out an AI issue aggregation engine that allows users to group related errors and identify shared commonalities across test sessions. For example, issues that appear distinct, such as button occlusion across different devices, can be identified as stemming from the same cause, such as a shared screen resolution. Kobiton\u2019s AI issue aggregation engine can consolidate these errors into a single bug, eliminating manual steps and streamlining the debugging process for developers.\n\n\u201cBy enabling our customers to tap into a variety of powerful AI engines, visualize their data in a graphical interface and identify commonalities across errors, we are setting a new standard for efficiency and accuracy in mobile app testing,\u201d said Frank Moyer, CTO of Kobiton. \u201cWe are excited to be at the forefront of this initiative.\u201d\n\nKobiton\u2019s new AI features, including the issue aggregation engine, will be available in the first half of 2025. To learn more about Kobiton\u2019s AI-augmented testing workflows and see a demo, visit Kobiton in the Expo at StarWest , the largest event held exclusively for QA professionals.\n\nStory continues\n\nAbout Kobiton\n\nKobiton empowers enterprises to accelerate mobile app delivery through manual, automated, and no-code testing on real devices. Kobiton's AI-augmented mobile testing platform uniquely delivers one-hour continuous testing and integration. Founded in 2016, Kobiton is venture-backed and headquartered in Atlanta. More info at www.kobiton.com .\n\nContact:\n\nKevin Wolf\n\nkevin@tgprllc.com\n\n\n\n"
    },
    {
        "title": "Meta AI\u2019s GenAI \u2018Imagine\u2019 features expand across Facebook, Instagram, and Messenger",
        "link": "https://techcrunch.com/2024/09/25/meta-ais-genai-imagine-features-expand-across-facebook-instagram-and-messenger/",
        "description": "With the update, users will be able to use prompts to generate AI photos directly in their feed, Stories, and for their ...",
        "image_url": "https://www.bing.com/th?id=OVFT.4_PluQCf1JXeVhYsJknNKi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "ai+app",
        "date": "8h",
        "source": "TechCrunch",
        "article_content": "Meta AI\u2019s Imagine features, which use generative AI to turn text prompts into images, are now being expanded across Facebook and Instagram, the company announced at Meta Connect 2024 on Wednesday. With the update, users will be able to use prompts to generate AI photos directly in their feed, Stories, and for their Facebook profile pictures.\n\nThe new capabilities could help users and creators call more attention to their posts and shares by allowing them to generate fanciful and eye-catching images to accompany their text. Once the images are shared, friends and followers can see them and react to them or even mimic them, Meta says.\n\nImage Credits: Meta\n\nImage Credits: Meta\n\nFacebook users already upload photos of characters, animals, or something else besides their own photo as their profile picture to better protect their privacy. Now they won\u2019t have to seek out such a photo: They can simply generate one.\n\nThe AI can also suggest captions for Stories on Facebook and Instagram, as a part of this update.\n\nThe image generation capabilities will come to Messenger, too, to create personalized chat themes. This is accessed by tapping on \u201cThemes\u201d in the chat. Before, users could change the background of their chats as well as the color of the text bubbles, but Meta AI offers far more options in terms of the types of images that can be used.\n\nImage Credits: Meta\n\nMeta says it\u2019s also testing new AI-generated content in Facebook and Instagram feeds where it will display AI images created for users based on interests and trends.\n\nImage Credits: Meta\n\nThis is largely designed to push people to try Meta AI by tapping on a suggested prompt to reimagine the photo or by swiping to generate content in real time using Meta Imagine AI.\n\nMeta CEO Mark Zuckerberg remarked during the event that Meta AI differentiates itself not only by offering \u201cstate-of-the-art AI models but also unlimited access to those models for free, integrated easily into our different products and apps,\u201d he said.\n\n\u201cSo Meta AI is on track to being the most used AI assistant in the world by the end of this year. In fact, it\u2019s probably already there. \u2026 We\u2019re almost at 500 million monthly actives, and we haven\u2019t even launched in some of the bigger countries yet,\u201d Zuckerberg added."
    },
    {
        "title": "Exclusive: Seen any paranormal activity on your Ring device? You could win $100,000",
        "link": "https://www.msn.com/en-us/news/us/exclusive-seen-any-paranormal-activity-on-your-ring-device-you-could-win-100000/ar-AA1r74hR?ocid=BingNewsVerp",
        "description": "\"I would encourage folks to really keep an eye on things that are happening in front of their cameras,\" Ring Chief Commercial ...",
        "image_url": "https://www.bing.com/th?id=OVFT.lLSzBH7Q7ZqkMApvpW742S&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "11hon MSN",
        "source": "USA TODAY on MSN",
        "article_content": ""
    },
    {
        "title": "Ghosts\u2014busted?",
        "link": "https://www.udel.edu/udaily/2024/september/paranormal-beliefs-youtube-paul-brewer/",
        "description": "Yes, Brewer was a fan of the 1990s television hit 'The X Files,' and he does admit to watching a Ghostbusters movie or two \u2014 he even has a pint-sized replica of the film\u2019s famous ghost-fighting ...",
        "image_url": "https://www.bing.com/th?id=ODF.SSsIsrIvUPdpCDihE7zimg&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "paranormal",
        "date": "University of Delaware7h",
        "source": "University of Delaware",
        "article_content": "Illustration and animation by Jeffrey C. Chase\n\nSince he was a child, University of Delaware communication professor Paul Brewer has been fascinated by unidentified flying objects (UFOs), ghosts, haunted houses and the like.\n\nYes, Brewer was a fan of the 1990s television hit \u201cThe X Files,\u201d and he does admit to watching a Ghostbusters movie or two \u2014 he even has a pint-sized replica of the film\u2019s famous ghost-fighting ambulance, the Ectomobile, in his office.\n\nBut what Brewer finds most intriguing is how media messages might influence people's belief in paranormal topics, and what we can learn from this in terms of how individuals perceive other messaging that may sit at the fringes of mainstream belief.\n\nAn expanding media landscape\n\nDuring the 1990s, a big wave of research erupted on how media messages might influence people's belief in paranormal topics with popular television shows like \u201cAlien Autopsy\u201d and \u201cCrossing Over with John Edwards.\u201d A second wave of research occurred in the mid-2000s in response to cable television series such as \u201cGhost Hunters\u201d and \u201cFinding Big Foot.\u201d\n\nBrewer\u2019s early research on this topic found that consuming paranormal television media was linked to believing in the paranormal, such as UFOs. His later work demonstrated that specific media messages can boost or reduce belief in paranormal phenomena, depending on the content of the message.\n\nSince then, the media landscape has evolved beyond traditional outlets like print, television and radio to include multimedia, such as YouTube, TikTok and other platforms. In his latest work, published in the journal Cyberpsychology, Behavior and Social Networking, Brewer looked beyond consuming paranormal television to include the use of social media, especially YouTube.\n\n\u201cIf you think about the paranormal, YouTube is a platform that seems like an especially plausible candidate to shape people's beliefs because seeing is believing\u2014and it is a very visual storytelling medium,\u201d said Brewer.\n\nUndergraduate students in Brewer\u2019s Comm 424 Media Message Analysis class participated in the work, along with graduate students Holly Wright and Erin Oittinen, who co-authored the paper with Brewer.\n\n\n\nThe goal was to understand how popular YouTube videos present reported paranormal phenomena, like UFOs and ghosts, and to measure whether more YouTube use is linked to increased belief in these things.\n\nSpoiler alert: Yes, it is.\n\nThe research team used two methodological approaches to tease this apart. A content analysis was used to determine how YouTube videos present information. Then the team used survey research to assess whether consumption of media is linked to belief in things. The research team built in layers of rigor to remove supposition and individual bias, while improving consistency.\n\n\u201cIt\u2019s not just a fun, kooky idea to study. About half the public believes in UFOs and almost half the public believes in ghosts and haunted houses, even though these phenomena aren't recognized by mainstream science. At least that's what they tell survey researchers,\u201d said Brewer.\n\n\u201cBroadly, there is a lot of concern about pseudoscience and misinformation out there in the media, and by understanding the processes by which people turn media messages into beliefs about stuff like UFOs and ghosts, we might also understand how they form beliefs about other things.\u201d\n\nBy way of example, Brewer pointed to a fictional documentary-style show that claimed the National Oceanic and Atmospheric Administration (NOAA) knew about mermaids and was hiding evidence for them, including real video footage. The show included disclaimers, but viewers ignored them, revealing an important detail about the power of belief.\n\n\u201cIt sounds ridiculous but, as one marine scientist pointed out, if you believe that NOAA is hiding evidence for mermaids, then why would you trust NOAA when it talks about climate change or hurricanes?\u201d said Brewer.\n\nBack to the current paper, where they discuss ghosts.\n\nThe researchers looked at 25 videos about UFOs and 25 videos about ghosts and specifically asked whether each video included a paranormal claim, that is, some sort of claim that the phenomenon was real. The researchers found that an overwhelming majority, 94% of the videos, included a paranormal claim. This finding was generally consistent across both UFOs and ghosts.\n\nKeep in mind that a claim is not a fact. It\u2019s just a claim and, in fact, a third of the videos also included skeptical claims.\n\n\u201cThe bottom line here is that if you go looking for YouTube content about UFOs or ghosts, you're likely to find videos that feature claims that paranormal phenomena are real,\u201d said Brewer.\n\nThe research team also considered whether the videos included video footage or audio of paranormal phenomena that the YouTube video presented as evidence for a UFO or a ghost. About 75% of the videos about ghosts included footage. and over half of the posted videos about UFOs had footage. So, roughly two-thirds of the videos included footage that was professed to be real.\n\nAccording to Brewer, this goes to the point that seeing is believing.\n\nFinally, the team studied whether the videos used scientific sources and government sources to lend an air of legitimacy to a claim.\n\nAmong the 25 YouTube videos discussing the presence of ghosts, no scientific sources were cited and very few government sources were cited. The 25 YouTube videos on UFOs included few scientific sources, but a fair amount of government sources. These government sources, however, weren\u2019t necessarily confirming the existence of ghosts or UFOs \u2014 it might just be a federal agency, say the Department of Defense, confirming that the footage shown is actual footage.\n\nThe research team built on the study of YouTube videos by conducting a survey of the public to explore how YouTube use and other forms of media consumption are linked to belief in the paranormal. The survey responses showed that watching YouTube was linked to believing, even after taking into account other media habits and background factors.\n\n\u201cInterestingly enough, when people watch a lot of YouTube, they also tend to believe in these other things more intensely. So, the more someone watches YouTube, the more likely they are to believe in ghosts or UFOs as a real thing,\u201d said Brewer.\n\n\u201cWe're not saying that YouTube is the only thing that is shaping people's beliefs about this. But it is something worth looking at if you care about whether people believe in fringe or pseudoscientific claims,\u201d he continued. \u201cUltimately, if you want to influence what the public is thinking about ideas and popular claims that scientists don't endorse, you might want to pay attention to YouTube.\u201d\n\nAsked if he is a believer, Brewer\u2019s response might surprise you: \u201cI have not seen any evidence that has persuaded me to believe.\u201d\n\nThat said, he is curious about why it is that other people do believe.\n\nIn a sequel study, the research team is exploring the differences between paranormal videos on YouTube, which often originate from mainstream popular media sources viewers consider legitimate, such as \u201c60 Minutes\u201d or the History Channel, versus TikTok, where content is developed and disseminated by individual users most people have never heard of, but who are producing videos that collectively have been viewed tens of millions, maybe hundreds of millions of times."
    },
    {
        "title": "Catch a ghost on your Ring camera? You can get $100K for the video",
        "link": "https://www.yahoo.com/entertainment/catch-ghost-ring-camera-100k-162202746.html",
        "description": "Catch a \"ghost\" on your Ring camera this fall? Ring wants to see it \u2014 and they may be willing to pay you for it.",
        "image_url": "https://www.bing.com/th?id=OVFT.hsx_wkS-4DNxYdIozQuXxy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "9h",
        "source": "Yahoo",
        "article_content": "Catch a ghost on your Ring camera? You can get $100K for the video\n\n(KTLA) \u2014 Your Ring camera may catch video of packages being dropped off, friends visiting, and cute animal activities, but the home surveillance company is hoping you\u2019ll catch some different, paranormal activity this Halloween season.\n\nRing is inviting users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize.\n\nAny form of paranormal activity \u2014 ghosts, ghouls, and anywhere in between \u2014 is welcome, according to Ring.\n\nRing offering $1M for proof of \u2018extraterrestrial life\u2019 caught on camera\n\n\u201cFrom supernatural sightings of floating orbs and unexplained shadows to family and friends wearing silly costumes. Funny, frightening, fashionable, all of it. If you find a ghost, we want to see it,\u201d the contest website said.\n\nThe company is inviting its users to submit videos showcasing paranormal activity for the chance to win a $100,000 prize. (Ring)\n\n\u201cFinn Wolfhard, star of \u2018Ghostbusters\u2019 and Netflix\u2019s \u2018Stranger Things,\u2019 and Paranormal Investigator Katrina Weidman will serve as part of the judging team for Ring\u2019s Great Ghost Search, helping to select the winning entry,\u201d a news release said.\n\nOnly the first 5,000 entries received through Nov. 1 will be considered for the grand prize. According to Ring, only the first 30 seconds of each video will be considered. Videos will be awarded points, with a maximum of 100 points available.\n\nPoints will be awarded based on the visibility or clarity of the \u201cghost\u201d or ghostly presence; whether the video surprises the judges with uniqueness; whether the judges were \u201cglued to the footage\u201d and how entertaining it was; and how unique the ghost\u2019s engagement with the Ring device was.\n\nRing users can enter the contest and find more details here.\n\nCopyright 2024 Nexstar Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.\n\nFor the latest news, weather, sports, and streaming video, head to PIX11."
    },
    {
        "title": "How The Scariest Movie of 2009 Launched an Unstoppable Hollywood Studio",
        "link": "https://www.inverse.com/entertainment/paranormal-activity-anniversary-15-years",
        "description": "Blumhouse had already existed for a few years, but 'Paranormal Activity' cracked the code and turned it into a powerhouse.",
        "image_url": "https://www.bing.com/th?id=OVFT.Nr5VFjObBu8WsvnkzNRaXy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "Inverse14h",
        "source": "Inverse",
        "article_content": "You kind of had to be there.\n\nParanormal Activity, like The Blair Witch Project before it, is a movie best experienced in a large dark room with 100 screaming strangers. Maybe that\u2019s true of most movies, but found-footage thrillers attempt to hijack your brain into thinking they\u2019re real in a way that just doesn\u2019t work when you\u2019re watching it at home when the lights are on and phone notifications are vying for your attention.\n\nBut even if you can\u2019t re-experience the original sensation of seeing Paranormal Activity in theaters when it was released back on September 25, 2009, it\u2019s still worth reflecting on how this micro-budget horror movie managed to become a worldwide phenomenon, and how it changed the entire industry in the process.\n\nThe plot is simple. A young couple, Katie and Micah, move in together. Katie then tells Micah that she\u2019s been haunted by an evil spirit ever since she was a kid, so Micah sets up a camera and records everything in the house, including their bedroom, while they sleep. The haunting starts small (a door moves on its own, there are some light noises), but things escalate within a few weeks, leading to a terrifying finale where Katie becomes possessed by a demon and murders Micah.\n\nParanormal Activity was made with just $15,000 and filmed in one week in first-time director Oren Peli\u2019s own home. Peli cast two unknown actors, shot the movie on a home video camera, and never bothered writing a script; like with The Blair Witch Project, actors were told to improvise based on a loose outline.\n\nKatie Featherston as Katie. Blumhouse\n\nIn a 2009 interview with Shock Till You Drop, Peli explained his lo-fi, found-footage approach.\n\n\u201cI wanted to make it look as real and natural as possible,\u201d he said. \u201cI\u2019ve always been drawn to this storytelling style. It breaks the mental barrier when audiences see a regular film and become aware of the camera movements, they know a crew is there and there are stars. When you strip all of this away, the audience thinks they are seeing something with a higher degree of plausibility. The suspending of disbelief becomes all the easier. You have an audience that's more invested in the story and the characters.\u201d\n\nParanormal Activity made almost $200 million at the box office and spawned a seven-movie franchise, but its legacy is even bigger than that. Peli\u2019s thriller also gave rise to one of the biggest names in horror today: Jason Blum.\n\nJason Blum attends the Film Independent's Spirit Awards in 2010. Angela Weiss/WireImage/Getty Images\n\nAfter debuting at Screamfest in 2007, Paranormal Activity earned some Hollywood buzz. It landed on the desk of Blumhouse CEO Jason Blum, then an executive at Miramax, who worked with Peli to edit the movie and submit it to Sundance. They were rejected, but didn\u2019t give up, and eventually, an early copy of Paranormal Activity found its way to Steven Spielberg.\n\nSpielberg made a deal with Peli and Blum to release the movie through Paramount. The plan was to completely reshoot it with a bigger budget while releasing the original cut as a DVD extra, but after a test screening scared audiences so much that some people walked out, the team realized they had a potential hit on their hands. The rest is history.\n\nSinister followed a similar formula, giving director Scott Derrickson the freedom to experiment. Blumhouse\n\nSpeaking to The LA Times just days before Paranormal Activity finally hit theaters, Jason Blum broke down exactly what makes the movie so special. \u201cOnce every five years, a guy makes a movie for a nickel that can cross over to a broad audience,\" he said.\n\nYou could practically hear the gears turning in Blum\u2019s head. While his studio, Blumhouse, had already existed for a few years, it was Paranormal Activity that cracked the code. Movies like Insidious and Sinister would soon follow, giving ambitious directors little money but lots of freedom to make bold horror movies that could rake in millions and launch new franchises.\n\nIn that sense, we have Paranormal Activity to thank for our current glut of horror movies. Blumhouse is still pumping them out 15 years later, and so is everyone else, from indie studios like A24 to Hollywood titans like Paramount. Even Disney is cashing in on horror thanks to its Fox acquisition and the IP, like Alien, that came with it.\n\nBut while Paranormal Activity\u2019s legacy may be mighty, the movie itself hasn\u2019t exactly held up, at least not in the context that most people experience movies these days.\n\n\u201cYou watch it in your bedroom, it can look like your kid made it,\u201d Blum said back in 2009. \u201cYou watch it with an audience, it's an entirely different experience.\u201d\n\nSo if you want to watch Paranormal Activity the way it was meant to be seen, just get 100 of your closest friends and family together in a dark room. If that\u2019s not viable, you can explore the entire genre it spawned instead."
    },
    {
        "title": "Your Ring Doorbell Could Earn You $100,000 This Halloween\u2014Here\u2019s How To Enter the Spooky Contest",
        "link": "https://www.yahoo.com/tech/ring-doorbell-could-earn-100-125401047.html",
        "description": "Ring Doorbell users, it\u2019s time to go ghost-hunting. The popular home security company announced that it will host a video ...",
        "image_url": "https://www.bing.com/th?id=OVF.HJ%2fO%2b8DmrUL3L0YMvGe1BA&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "paranormal",
        "date": "12h",
        "source": "Yahoo",
        "article_content": "Ring Doorbell users, it\u2019s time to go ghost-hunting. The popular home security company announced that it will host a video competition with submissions centered around paranormal activity caught on a Ring camera. Keep reading to learn more about the Ring Doorbell Halloween challenge and how to enter for a chance to win $100,000!\n\nWhat to know about the Ring Doorbell Halloween challenge\n\nThe Ring Doorbell Halloween challenge began on September 24 and runs until November 1 or until 5,000 submissions are received. It will have winner, to whom the company will award $100,000 for a \"not-so-haunted house, ghost-free getaway, or any other earthly expense,\u201d according to a press release obtained by First for Women.\n\n\"Every day, we hear from our customers about surprising or unexpected footage captured by their Ring cameras. They love the ability to stay connected to what's happening \u2014 although paranormal sightings are understandably not the most welcome,\u201d Ring\u2019s Chief Commercial Officer, Mimi Swain, said in the same press release. \"Now, during Halloween, the busiest doorbell season of the year, we're calling on customers to keep an eye out for any ghostly activity. If they do capture a ghost on camera, we're going to help them escape their haunted situation. After all, what's Halloween without a few surprises?\"\n\nRing Doorbell\u2019s Halloween contest features a star-studded judging panel, including actor Finn Wolfhard of Stranger Things and paranormal investigator Katrina Weidman.\n\n\"Ring is known to catch all kinds of activity\u2014but I know if I saw a ghost on my Ring camera, I'd want to move out as fast as possible,\" said in the press release. \"This Halloween season, I'm relying on my Ring camera to alert me of any activity happening in and around my house\u2014even if it's the spooky or paranormal.\"\n\nWolfhard also posted a funny video, highlighting the competition on his Instagram. You can watch it below.\n\nHow to enter the Ring Doorbell Halloween challenge\n\nIf you think your video is spooky enough for the Ring Doorbell Halloween competition, all you have to do is submit it to ring.com/ghostsearch. You can also share your creepiest footage on social media by tagging @Ring and using the hashtag #RingGhostSearch to boost your chances of being featured.\n\nRing and the judges say they are looking for something \u201cseriously silly or totally unexplainable\u201d\u2014just like the sample video shared on their Instagram.\n\nThe doorbell company also shared another example of a video on their Instagram with the caption quoting the user who shared it: \u201cI noticed that the passenger door was wide open, so I walked around [and] closed it. As soon as I closed the door, the car attempted to start by itself. It was really creepy. I thought maybe my son was in there messing with me. I walked back over to the driver\u2019s side and leaned in, and when I checked the keys, they were in the off position and every hair on [my] body stood straight up.\u201d\n\nYou can watch that video below!\n\nGood luck! May the spooky odds be ever in your favor.\n\nFor more Halloween content, keep scrolling!\n\n\u2018Beetlejuice\u2019 Halloween Costumes and Decorations: Ideas from TikTok to Try\n\n14 DIY Fall Nail Designs That Pretty Up Fingertips\n\nStarbucks Fall Menu 2024: Get the Scoop on New and Returning Favorites"
    },
    {
        "title": "Deep-sea discovery shines light on life in the twilight zone",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925123650.htm",
        "description": "A new study could change the way scientists view microbial processes in the deep ocean. The unexpected findings expand our understanding of the impacts of climate change, including how and where the ...",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily2h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "Unexpected deep-sea discovery shines light on life in the twilight zone",
        "link": "https://phys.org/news/2024-09-unexpected-deep-sea-discovery-life.html",
        "description": "The ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to ...",
        "image_url": "https://www.bing.com/th?id=OVFT.fERzBQQCwkWUdJWljKZQWC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "10h",
        "source": "Phys.org",
        "article_content": "This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:\n\nA conductivity, temperature and depth (CTD) rosette used to sample water from the ocean's twilight zone during a GEOTRACES expedition in the Pacific Ocean. Credit: Alex Fox\n\nThe ocean's twilight zone is deep, dark, and\u2014according to new research\u2014iron deficient. No sunlight reaches this region 200 to 1,000 meters below the sea surface, where levels of iron, a key micronutrient, are so low that the growth of bacteria is restricted. To compensate, these bacteria produce molecules called siderophores, which help the bacteria scavenge trace amounts of iron from the surrounding seawater.\n\nA Nature paper detailing these unexpected findings from the Pacific Ocean could change the way scientists view microbial processes in the deep ocean and offer new insight into the ocean's capacity to absorb carbon.\n\n\"Understanding the organisms that facilitate carbon uptake in the ocean is important for understanding the impacts of climate change,\" said Tim Conway, associate professor of chemical oceanography at the USF College of Marine Science, who co-authored the recent study.\n\n\"When organic matter from the surface ocean descends to the deep ocean, it acts as a biological pump that removes carbon from the atmosphere and stores it in seawater and sediments. Measuring the rates and processes that influence this pump gives us insight into how and where the ocean stores carbon.\"\n\nCo-chief Scientist Phoebe Lam of the University of California, Santa Cruz and others removed the pump's damaged section of cable from the winch. Credit: Alex Fox\n\nTo conduct the study, researchers collected water samples from the upper 1,000 meters of the water column during an expedition through the eastern Pacific Ocean from Alaska to Tahiti. What they found in the samples surprised them.\n\nNot only were concentrations of siderophores high in surface waters where iron is expected to be deficient, but they were also elevated in waters between 200 and 400 meters deep, where nutrient and iron concentrations were thought to have little impact on the growth of bacteria.\n\n\"Unlike in surface waters, we did not expect to find siderophores in the ocean's twilight zone,\" said Conway.\n\n\"Our study shows that iron-deficiency is high for bacteria living in this region throughout much of the east Pacific Ocean, and that the bacteria use siderophores to increase their uptake of iron. This has a knock-on effect on the biological carbon pump, because these bacteria are responsible for the breakdown of organic matter as it sinks through the twilight zone.\"\n\nThe recent discovery was part of GEOTRACES, an international effort to provide high-quality data for the study of climate-driven changes in ocean biogeochemistry.\n\nLeft to right: CTD technician Kyle McQuiggan, Research Technician Keith Shadle and multi-talented Data Analyst Joseph Gum work together to repair the trace metal CTD rosette's connection to the ship. Credit: Alex Fox\n\nTubes awaiting samples in the hydro-lab of the Roger Revelle. Scripps ODF Chemistry Technician Erin Hunt monitors her samples in the background. Credit: Alex Fox\n\nOne of the pumps comes back on board the R/V Roger Revelle at sunset. Credit: Alex Fox\n\nInside the main lab's bubble, some of GP15's scientists found it necessary to create reminders that time was indeed passing. Credit: Alex Fox\n\nThe study of siderophores is still in the early stages. Researchers involved in GEOTRACES only recently developed reliable methods to measure these molecules in water samples, and they're still working to understand where and when microbes use siderophores to acquire iron.\n\nAlthough the research into siderophores is new, this study demonstrates their clear impact on the movement of nutrients in the ocean's twilight zone.\n\n\"For a full picture of how nutrients shape marine biogeochemical cycles, future studies will need to take these findings into account,\" said Daniel Repeta, senior scientist at Woods Hole Oceanographic Institution and co-author of the article.\n\n\"In other words, experiments near the surface must expand to include the twilight zone.\"\n\nMore information: Daniel Repeta et al, Microbial iron limitation in the ocean's twilight zone, Nature (2024). DOI: 10.1038/s41586-024-07905-z. www.nature.com/articles/s41586-024-07905-z Journal information: Nature"
    },
    {
        "title": "AI Develops Proteins to Boost Drug and Science Discovery",
        "link": "https://www.miragenews.com/ai-develops-proteins-to-boost-drug-and-science-1324688/",
        "description": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more ...",
        "image_url": "https://www.bing.com/th?id=OVFT.t6A53DVVgUHq3_08BDTgeS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Armed robbery in Revesby3h",
        "source": "Armed robbery in Revesby",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature's evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\"Nature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\" said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \"EvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\"\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\"Engineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\" Klivans said. \"It also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\"\n\nUnlike Google DeepMind's AlphaFold, which applies AI to predict the shape and structure of proteins based on each one's sequence of amino acids, the Deep Proteins group's AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan's lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\"The models have come up with substitutions we never would have thought of,\" McLellan said. \"They work, but they aren't things we would have predicted, so they're actually finding some new space for stabilizing.\"\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company's new drug are only about 1 in 10. What's more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development-and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank-as well as the related UT-created framework on which it builds, Stability Oracle-are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster.\n\nUsing existing databases of naturally occurring protein sequences, the researchers who created EvoRank essentially lined up different versions of the same protein that appear in different organisms-from starfish to oak trees to humans-and compared them. At any given position in the protein, there might be one of several different amino acids that evolution has found to be useful, with nature selecting, say, 36% of the time the amino acid tyrosine, 29% of the time histidine, 14% of the time lysine-and even more importantly never leucine. Using this gold mine of existing data reveals an underlying logic in protein evolution. Researchers can knock out options that, evolution suggests, would result in killing the protein's functionality. The team uses all of this to train the new machine learning algorithm. Based on continuous feedback, the model learns which amino acid nature opted for during the past when evolving proteins, and it bases its understanding on what's plausible in nature and what is not.\n\nDiaz next plans to develop a \"multicolumn\" version of EvoRank that can evaluate how multiple mutations at the same time affect a protein's structure and stability. He also wants to build new tools for predicting how a protein's structure relates to its function.\n\nBesides Klivans and Diaz, computer science graduate student Chengyue Gong and UT alumnus James M. Loy co-authored both works. Tianlong Chen and Qiang Liu also contributed to EvoRank; Jeffrey Ouyang-Zhang, David Yang, Andrew D. Ellington and Alex G. Dimakis additionally contributed to Stability Oracle. The research was funded by the NSF, the Defense Threat Reduction Agency and The Welch Foundation."
    },
    {
        "title": "Scientists discover a single-electron bond in a carbon-based compound",
        "link": "https://www.sciencedaily.com/releases/2024/09/240925122902.htm",
        "description": "The discovery of a stable single-electron covalent bond between two carbon atoms validates a century-old theory.",
        "image_url": "https://www.bing.com/th?id=ODF.96mwsaHf5w3b01ClmPkvpA&pid=news&w=16&h=16&c=14&rs=2&qlt=90",
        "category": "science+discovery",
        "date": "Science Daily5h",
        "source": "Science Daily",
        "article_content": "Content not available"
    },
    {
        "title": "AI Trained on Evolution\u2019s Playbook Develops Proteins that Spur Drug and Scientific Discovery",
        "link": "https://cns.utexas.edu/news/research/ai-trained-evolutions-playbook-develops-proteins-spur-drug-and-scientific-discovery",
        "description": "EvoRank offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology ...",
        "image_url": "https://www.bing.com/th?id=OVFT.v_0f8vasR7xpb6PffHlZwS&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "science+discovery",
        "date": "Journalism in the Americas4h",
        "source": "Journalism in the Americas",
        "article_content": "A new artificial intelligence model developed by researchers at The University of Texas at Austin paves the way for more effective and less toxic treatments and new preventive strategies in medicine. The AI model informs the design of protein-based therapies and vaccines by leveraging the underlying logic from nature\u2019s evolutionary processes.\n\nThe AI advance, called EvoRank, offers a new and tangible example of how AI may help bring disruptive change to biomedical research and biotechnology more broadly. Scientists described the work at the International Conference on Machine Learning and published a related paper in Nature Communications about leveraging a broader AI framework to identify useful mutations in proteins.\n\nA major obstacle to designing better protein-based biotechnologies is having enough experimental data about proteins to adequately train AI models to understand how specific proteins work and thus how to engineer them for specific purposes. The key insight with EvoRank is to harness the natural variations of millions of proteins generated by evolution over deep time and extract the underlying dynamics needed for workable solutions to biotech challenges.\n\n\u201cNature has been evolving proteins for 3 billion years, mutating or swapping out amino acids and keeping those that benefit living things,\u201d said Daniel Diaz, a research scientist in computer science and co-lead of the Deep Proteins group, an interdisciplinary team of computer science and chemistry experts at UT. \u201cEvoRank learns how to rank the evolution that we observe around us, to essentially distill the principles that determine protein evolution and to use those principles so they can guide the development of new protein-based applications, including for drug development and vaccines, as well as a wide range of biomanufacturing purposes.\u201d\n\nUT is home to one of the leading programs in the country for AI research and houses the National Science Foundation-funded Institute for Foundations of Machine Learning (IFML) led by computer science professor Adam Klivans, who also co-leads Deep Proteins. Today, the Advanced Research Projects Agency for Health announced a grant award involving Deep Proteins and vaccine-maker Jason McLellan, a UT professor of molecular biosciences, in collaboration with the La Jolla Institute for Immunology. The UT team will receive nearly $2.5 million to begin to apply AI in protein engineering research into developing vaccines to fight herpesviruses.\n\n\u201cEngineering proteins with capabilities that natural proteins do not have is a recurring grand challenge in the life sciences,\u201d Klivans said. \u201cIt also happens to be the type of task that generative AI models are made for, as they can synthesize large databases of known biochemistry and then generate new designs.\u201d\n\nUnlike Google DeepMind\u2019s AlphaFold, which applies AI to predict the shape and structure of proteins based on each one\u2019s sequence of amino acids, the Deep Proteins group\u2019s AI systems suggest how best to make alterations in proteins for specific functions, such as improving the ease with which a protein can be developed into new biotechnologies.\n\nMcLellan\u2019s lab is already synthesizing different versions of viral proteins based on AI-generated designs, then testing their stability and other properties.\n\n\u201cThe models have come up with substitutions we never would have thought of,\u201d McLellan said. \u201cThey work, but they aren\u2019t things we would have predicted, so they\u2019re actually finding some new space for stabilizing.\u201d\n\nProtein therapeutics often have fewer side effects and can be safer and more effective than the alternatives, and the estimated $400 billion global industry today is primed to grow more than 50% during the next decade. Still, developing a protein-based drug is slow, costly and risky. An estimated $1 billion or more is needed for the decade-plus journey from drug design to completing clinical trials; even then, the odds of securing approval from the Food and Drug Administration for a company\u2019s new drug are only about 1 in 10. What\u2019s more, to be useful in therapeutics, proteins often need to be genetically engineered, for example, to ensure their stability or to allow them to yield at a level needed for drug development\u2014and cumbersome trial-and-error in labs traditionally has dictated such genetic engineering decisions.\n\nIf EvoRank\u2014as well as the related UT-created framework on which it builds, Stability Oracle\u2014are commercially adapted, industry would have opportunities to shave time and expense from drug development, with a road map to arrive at better designs faster."
    },
    {
        "title": "How Will AI Affect Low-Code/No-Code Development?",
        "link": "https://www.forbes.com/councils/forbestechcouncil/2024/09/25/how-will-ai-affect-low-codeno-code-development/",
        "description": "When implementing AI into low-code/no-code development, it is important to consider the risks and how to mitigate them.",
        "image_url": "https://www.bing.com/th?id=OVFT.3hoTdJIxRV-Fjg_OSCaXhy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "15h",
        "source": "Forbes",
        "article_content": "Content not available"
    },
    {
        "title": "Inside AI: No-Code Computer Vision and Edge Computing",
        "link": "https://insideunmannedsystems.com/inside-ai-no-code-computer-vision-and-edge-computing/",
        "description": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end ...",
        "image_url": "https://www.bing.com/th?id=OVFT.p3zLnocXw31jrXbR5a8NGy&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "nocode",
        "date": "The Future of Autonomy9h",
        "source": "The Future of Autonomy",
        "article_content": "Sharath Rajampeta is Chief AI, at Visionplatfrom.ai, a Dutch firm aiming to revolutionize computer vision with an end-to-end no-code platform and edge computing capabilities.\n\nThey partner with businesses across industries to implement AI-powered computer vision technology. With the Visionplatform.ai software, users can train AI vision algorithms and integrate computer vision into their workflows. The solution enables users to detect, interpret and analyze objects, people and events in real-time, drawing insights and optimizing operations.\n\nVisionplatform.ai integrates edge computing capabilities and the use of high fps video streams instead of static images. The platform allows users to leverage the power of AI and computer vision at the edge, minimizing latency, improving responsiveness and ensuring data privacy.\n\nPLATFORM DESIGN AND DEVELOPMENT\n\nIUS: Can you explain the core design principles behind Visionplatform.ai?\n\nA: Our core design principles are simplicity, and ease of use. Our goal is to democratize computer vision to empower our users to make their own innovative solutions for real world problems.\n\nIUS: What were the biggest technical challenges you faced in developing a no-code AI vision platform, and how did you overcome them?\n\nA: Democratizing AI is a very difficult task. A field like ML and specifically computer vision has long been the playground of experts and professionals. It\u2019s a fact that the field of AI is not standardized. For experts this does not matter, but for the average user the barrier of entry into the field is very high. From a technical standpoint, our biggest challenge has been to abstract away this complexity, for example various dataset formats, various model formats, effect of hyper parameters during training and integrations with other systems. This makes a product with a user experience (UX) that is easy to use.\n\nOur strategy to overcome them is putting ourselves in the shoes of an average user when designing our app, but also actively involve people who satisfy our ideal user profile in early-stage testing of our releases. We also have a long history of working with people who satisfy that profile, which means we already possess a deeper understanding of their needs. We have also introduced a chatbot that possesses all of our gathered knowledge over the years, available to any customer that uses our solution, which aims to provide easy and clear explanation to the most common user inquiries, and trust us, when it comes to ML and computer vision, there\u2019s not many of those. Finally, we offer comprehensive help dialogs in the app, which explain the most important concepts depending on which page the user is on, via text and videos. All of the this enables our users not only to be able to use the platform, but also learn some important basics as they go.\n\nApplications such as security are advanced considerably utilizing AI together with UAS platforms. Image: Visionplatform.ai.\n\nTECHNOLOGICAL INTEGRATION\n\nIUS: How does VisionPlatform.ai integrate with edge computing devices like NVIDIA Jetson, and what advantages does this bring to your users?\n\nA: Visionplatform was born from a company named supplai, which was a project-based AI vision company which primarily focused in the logistics industry. From our previous customer experiences, we found most customers are interested in making their own applications. So, this was where the idea of\n\nvisionplatform was conceived. We aim to be a low code AI platform which democratizes Computer Vision and AI and is easily deployable on the NVIDIA Jetson edge devices. Our past experience has given us a lot of expertise in Jetson and the ability to maximize their performance. Jetsons are by far the most advanced edge IOT devices capable of running relatively large AI models in real time. With the deep stream framework, which brings together hardware accelerated encoding and machine optimized AI runtimes, these devices are still the market leader in terms of edge AI computing with very low power consumption, another big advantage. We know how to make the best use of them and have proven that time and time again. Our users can rest assured that the edge solution that visionplatform provides is not only at an end-end cost effective solution but also it maximizes the capability of these highly efficient hardware.\n\nIUS: Can you discuss the decision-making process behind supporting both edge and cloud computing for AI vision tasks?\n\nA: While edge computing is attractive to a lot of our customers especially in the domains where data privacy and low latency are a key, such as logistics, manufacturing and surveillance, we have also seen a market need to support cloud-based solutions. AI in the cloud has advantages of running significantly higher workloads at the cost of latency. Auto-labeling, for example, makes sense if it is hosted in the cloud as the datasets are large and the models generally for this task need to be large. For this task the user is generally not too concerned about the time it takes to process their media, so such a feature is provided within a cloud framework.\n\nA commercial drone outfitted with the NVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nINDUSTRY APPLICATIONS\n\nIUS: Can you provide examples of how Visionplatform.ai can be used in the drone industry to enhance capabilities such as autonomous navigation and real-time data analysis?\n\nA: We have integrations with the DJI drones. There are two types of integrations we have done with drones. The first is getting a [high-res video] stream directly from the drone. The second is stream a real time messaging protocol (RTMP) stream into the Jetson. In the first case we will have a Jetson mounted on a drone and then run our AI algorithms from the stream directly. This has little latency but the extra weight of the jetson needs to be considered. This solution is perfect for larger drones. The second solution is for lighter drones which have good network connectivity. Though there is some latency introduced, there is no extra weight on the drone itself. These two approaches aim to cover a wide range of drone applications.\n\nSome interesting use cases from customers include drones for security and situational awareness. Having something like an anomaly detection model which identifies anomalous behavior can help spot threats from the sky without human risk. Also, there are useful applications for coast guards like detecting people who are far into the sea.\n\nDrones are also used quite a lot for inspections. Having a segmentation algorithm coupled with object detection will help the drone in inspecting bridges, windmills and give real time localization of defects. Currently, these inspections require a 3D reconstruction from pictures and an expert to classify these defects. This process can take days to weeks. A real time detection solution on the drone can, however, reduce this time to hours.\n\nIUS: How about adjacent industries like robotics and security?\n\nA: With visionplatform we can make any camera into a security camera without replacing it. Applications in security like detecting people with guns or detecting people in unauthorized places and people going to dangerous areas can be made easily with visionplatform with little cost or change in the current infrastructure. For enhancing robots with vision capabilities, especially with vision models, the user can write text prompts to guide the robot. This is a cutting-edge application that opens up many possibilities. Also, our integration with the Milestone VMS already is a huge step in the field of intelligent video analytics for security applications.\n\nVisionplatform.ai\u2019s drone based and AI-enhanced imaging technology. Image: Visionplatform.ai.\n\nMODEL TRAINING AND DEPLOYMENT\n\nIUS: How does your platform handle the training and deployment of AI models to ensure they are robust and reliable across different applications?\n\nA: Our experience in ML over the last few years has led us to finding and developing strategies that make a model robust. From augmentations, smart data splitting and concepts like freezing layers of the model, which can be understood easily by the average person, we have more than enough strategies to make a robust model. Another cool feature about visionplatform is that our LLM chatbot is itself a domain expert in AI and can help guide the user to realize complex tasks. Making sure the training metrics are good we can be sure of the reliability, and we plan to include out-of-distribution detection soon so the model in fact knows when something it sees is out of its understanding. Our Jetsons also run 24/7 with several fallbacks when an application fails so the user knows the application is always running and if it crashes the user is notified.\n\nIUS: What strategies do you employ to continuously improve model accuracy and performance based on user feedback and data?\n\nA: One of the biggest aspects of machine learning is continuous training and improvement of the model. We have a video acquisition pipeline to capture live streams from a video and store it as a part of the user\u2019s dataset. The user also has an event browser where they can pick video events where the model made a false detection and use them into the next round of training. Additionally, we plan to incorporate more data visibility features like displaying the number of classes in a dataset as well as other statistics in order to guide the user into making a good dataset that best trains the model.\n\nNVIDIA Jetson AI computer. Image: Visionplatform.ai.\n\nFUTURE DIRECTIONS\n\nIUS: What upcoming features or improvements can users expect from Visionplatform.ai?\n\nA: Newer models, more LLM focused work flows where the user can talk to a chatbot, and it can create an application for them so there are little to no clicks involved in an application. More dataset understanding and visibility and a place to manage all your deployed Jetsons are our immediate features we have planned. But as the ML field brings up new models and ideas, we plan to incorporate them also as long as they are in line with our core vision.\n\nIUS: How do you see the role of AI vision evolving in industries like logistics and public safety over the next five years?\n\nA: AI vision is going to have a large impact in the logistics and security industries in the next 5 years. These industry segments have been generally a bit slow to adapt to AI vision traditionally, but things are changing as AI is becoming easier to integrate and more reliable. Over the next five years, AI vision will revolutionize logistics and public safety by enhancing automation, real-time monitoring and operational efficiency. In logistics, AI vision will improve sorting, picking and inventory tracking while enabling the widespread use of autonomous vehicles and predictive maintenance. Supply chains will benefit from dynamic routing and automated quality control powered by vision algorithms. In public safety, AI vision will enhance surveillance, facial recognition, and emergency response, providing rapid assessments and automated alerts. Traffic management will see smarter control systems and real-time accident detection. Visionplatform\u2019s ability to make any existing IP camera to an AI camera is key for this transformation."
    },
    {
        "title": "Cowboys\u2019 CeeDee Lamb rebounded from a poor start last season. \u2018I plan on doing it again\u2019",
        "link": "https://www.dallasnews.com/sports/cowboys/2024/09/24/cowboys-ceedee-lamb-rebounded-from-a-poor-start-last-season-i-plan-on-doing-it-again/",
        "description": "The first three weeks of his season have been turbulent, and after a Dak Prescott misfire in Week 3, Lamb sat in the end zone ...",
        "image_url": "https://www.bing.com/th?id=OVFT.qhhCDPiP2NjkUrqKDJhQoC&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "23h",
        "source": "Dallas Morning News",
        "article_content": "FRISCO \u2014 CeeDee Lamb took the blame for everything.\n\nHe owned the end zone tantrum, loud chats with teammates and coaches, and his poor performance.\n\nAfter skipping out on speaking with the media following the Cowboys\u2019 loss to the Ravens on Sunday, Lamb discussed everything two days later.\n\n\u201cHonestly I got to be truthful to myself and I played a part in that loss,\u201d he said. \u201cA big part honestly, and nor did my body language nor attitude, approaching the situation help the situation or the outcome of the game.\u201d\n\nCowboys Be the smartest Cowboys fan. Get the latest news. SIGN UP Or with: Google Facebook By signing up you agree to our Terms of Service and Privacy Policy\n\nLamb added of his actions, \u201cVery detrimental. Detrimental and, yeah, I\u2019ll make up for it.\u201d\n\nAdvertisement\n\nLamb is normally a smooth operator on the field. It\u2019s the reason the Cowboys signed him to one of the richest contracts in NFL history at the receiver position. But the first three weeks of the season have been turbulent.\n\nOut of 24 targets, he has 13 catches and one touchdown. Last season he caught a career-high 74% of passes directed toward him.\n\nThe offensive issues Lamb faced came to a head against the Ravens.\n\nAdvertisement\n\nIn a moment telling of that 28-25 loss, Prescott misfired on a potential touchdown pass to Lamb in the end zone. A pass interference call was negated by an offsetting holding penalty, and Lamb sat in the end zone yelling and slapping both hands to the turf.\n\nAdvertisement\n\nHe later arrived on the sidelines and had a loud discussion with Prescott and anyone else nearby. You could tell he was frustrated. Maybe the contract was getting to him. Maybe the pressures of trying to find a flow within an offense he didn\u2019t work in during training camp because of his contract holdout was rearing its ugly head.\n\nHe finished the game with two drops, a false start and four catches for 67 yards. He also fumbled in the red zone.\n\n\u201cYou got to start with the man in the mirror and I\u2019m a huge believer in that,\u201d Lamb said. \u201cAnd watching that game kind of pissed me off, but I did that. I can\u2019t get mad at nobody else. So with that being said, I\u2019ve learned.\u201d\n\nAdvertisement\n\nThe Cowboys have gone through this with Lamb, most recently last season. After four weeks, Lamb had 23 catches for 309 yards with a touchdown. He caught 76.7% of his passes. Those numbers look so much better than what he\u2019s producing now.\n\nAnd Lamb wasn\u2019t happy about it then. The next week at San Francisco, Lamb caught four passes for 49 yards and no touchdowns in a 42-10 loss. Lamb went off.\n\nAfter the 49ers game, receiver Brandin Cooks became Lamb\u2019s consigliere. Cooks understood then Lamb was playing for a huge contract and poor performances hamper that. The two talked about getting on the same page with Prescott and coach Mike McCarthy, in his first year with this team as the playcaller.\n\nAdvertisement\n\nOver the next eight games, Lamb had 69 catches for 859 yards and seven touchdowns. Lamb\u2019s confidence soared along and everyone forgot about that sorry performance against the 49ers.\n\nOn Thursday night, the Cowboys visit the New York Giants and Lamb has to respond in a similar fashion.\n\n\u201cI plan on doing it again,\u201d he said.\n\nThe problem with doing it again isn\u2019t so much what defenses are doing to Lamb, it\u2019s finding a rhythm with Prescott.\n\nAdvertisement\n\nQB1 wasn\u2019t available to tell his side of the story because team officials elected to have him speak after the Giants game.\n\nMcCarthy has turned Lamb into an elite receiver that takes over games. But it\u2019s something we haven\u2019t seen in the early stages of the season.\n\n\u201cCeeDee is a primary focal point for us game planning and it\u2019ll be a primary focal point for the defense,\u201d McCarthy said. \u201cThat\u2019s why you play the game. We\u2019ll continue to do what we have done with him. There\u2019s always little things you\u2019re looking to build on, certain routes and so forth.\u201d\n\nAdvertisement\n\nThe Cowboys can line Lamb up in the backfield, use him on jet sweeps, line him up in three receiver spots. When he\u2019s on the field and used properly his talent is unmatched.\n\nAfter three weeks, he hasn\u2019t shown it.\n\n\u201cGranted, it was a bad game on my end. I fully take accountability in that,\u201d he said. \u201cI have no shame in that. So with that being said, I will be better in the future and it\u2019s going to be fun.\u201d\n\nX: @calvinwatkins\n\nAdvertisement\n\nFind more Cowboys coverage from The Dallas Morning News here."
    },
    {
        "title": "Zip doubles down as the procurement startup expands into EMEA and debuts new brand design",
        "link": "https://www.aol.com/finance/zip-doubles-down-procurement-startup-120402411.html",
        "description": "Zip will expand into Europe, Middle East, and Africa (EMEA) and unveil a design rebrand, Fortune has exclusively learned.",
        "image_url": "https://www.bing.com/th?id=OVFT.0gYa7X8956fyf1IP1ScG8S&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "it+startup",
        "date": "10h",
        "source": "AOL",
        "article_content": "Rujul Zaparde and Lu Cheng knew they wanted to start a company together\u2014but they had some rules.\n\nThe two, who first met at Airbnb, had left their jobs with comically bad timing in 2020. But Cheng and Zaparde were determined to figure out what might work for them and as a business.\n\nAs the surrounding world reeled from the pandemic, the pair spent months developing a 16-point set of criteria to determine if a business idea was worth pursuing. It\u2019s a colorful set of rules. There\u2019s the \"bomb test,\" a gallows humor screening of a potential business idea\u2019s scalability, sustainability, and enterprise software-ness. Then there\u2019s the hair-on-fire principle, which describes a must-solve problem that cannot, under any circumstances, be ignored.\n\n\"It's a real problem that they have to solve, because it's causing that much pain,\" said Zaparde.\n\nOthers include: \"Why is now the right time to start the company?\" and \"Is this really sticky and super hard to rip out?\" They tried on different ideas and even stumbled on a prospective services business that began generating revenue faster than they\u2019d imagined\u2014but they nixed it. Their startup idea had to fit all the criteria. And that\u2019s how they got into the business of procurement, the labyrinthine corporate process of finding, buying, receiving, and checking goods.\n\nIt's a process that every business undergoes but no one seems to like, which is perhaps putting it mildly. Once, someone cried to Cheng and Zaparde in procurement-induced frustration.\n\n\"We had a notes doc that had about 120 pages, and the word \u2018pain\u2019 shows up 110 times in it,\" said Cheng. \"People had these visceral reactions to the challenges around procurement and how the industry has evolved, how types of spend have evolved, and how technology just hasn\u2019t caught up.\"\n\nAnd there was that key word: Pain. Procurement problems were hair-on-fire problems. In the four years since Cheng and Zaparde founded Zip, the procurement software startup has covered a lot of ground\u2014backed by Y Combinator, CRV, and Tiger Global, it was last valued at $1.5 billion in 2023. Zip\u2019s current customers include OpenAI, Discover, Sephora, and Snowflake.\n\nThis week marks another big milestone for Zip: The company today announced its expansion into Europe, the Middle East, and Africa (EMEA) and revealed a design rebrand. This is all just two days after IDC placed Zip at the top of its newly minted \"spend orchestration category,\" even beating out publicly traded giants like ServiceNow.\n\n\"This is an acknowledgment that they actually have found a legitimate category,\" said Zip investor Ali Rowghani, who\u2019s former managing director of YC\u2019s Continuity Fund, former CFO at Pixar, and former COO at Twitter. \"I think it\u2019s going to be really big. From an investor's point of view, it validates the thesis that there\u2019s a real problem here that not just a small number of companies have, but that a lot of companies have.\"\n\nAnd the problem, more or less, is this: Procurement can cover almost anything, from pens and printers to industry-specific must-haves. It inherently requires many layers of approval\u2014there have been more and more layers added over the years, as companies have gotten bigger and more complex. So, requests get denied and no one knows why. Procurement has become a procedural maze with trap doors, hidden corners, and nonsensical dead-ends. And like a maze, it\u2019s hard to see clearly and (without tech help) impossible to see as a whole. The overall effect: Procurement divisions feel like black boxes, and the people who work in them are usually unseen and underappreciated. Case in point, when was the last time you thanked your procurement specialist?\n\nZip already has international customers, and that\u2019s been true \"from the very beginning,\" according to Cheng. For example, Tel Aviv and New York-based Pagaya since 2022 has been a Zip customer. David Eckstein, Pagaya\u2019s director of procurement, said via email that, though the procurement process in most places is considered \"chaotic,\" that\u2019s something that Zip \"solved for me, for us.\" Other existing international Zip customers include U.K.-based semiconductor company Arm and Germany-based digital bank N26.\n\nSo, the EMEA expansion is a formalization of something that\u2019s been happening for years. Zip is opening a new office in London and will be hiring aggressively there, and will also court talent in Germany and France.\n\n\"We've seen a lot of pull from EMEA naturally,\" Zaparde said. \"We didn't have an EMEA team at all until about a year or so ago, give or take\u2026We had just been receiving all this inbound from prospective customers, because they had this pain around procurement intake and orchestration.\"\n\nZaparde and Cheng, respectively CEO and CTO, are eyeing APAC next. But that\u2019s down the road. Today (and probably today only) Zip is concentrated on San Francisco, where it\u2019s holding its second-ever conference, Zip Forward, and unveiling new products like AI invoice coding. Buses and billboards across the city will feature the company\u2019s brand redesign, taking something that was frankly generic and turning it electric blue.\n\nIt would be a big week for anyone. But it\u2019s especially so for a startup that was founded just four years ago to solve a problem setting hair on fire.\n\nElsewhere\u2026Yesterday, former FTX executive Caroline Ellison was sentenced to two years in federal prison. Here\u2019s more from my colleague Leo Schwartz.\n\nSee you tomorrow,\n\nAllie Garfinkle\n\nTwitter: @agarfinks\n\nEmail: alexandra.garfinkle@fortune.com\n\nSubmit a deal for the Term Sheet newsletter here.\n\nNina Ajemian curated the deals section of today\u2019s newsletter.\n\nThis story was originally featured on Fortune.com"
    },
    {
        "title": "Behind the Scenes of Unity Software's Latest Options Trends",
        "link": "https://www.benzinga.com/insights/options/24/09/41030386/behind-the-scenes-of-unity-softwares-latest-options-trends",
        "description": "Based on the trading activity, it appears that the significant investors are aiming for a price territory stretching from $20 ...",
        "image_url": "https://www.bing.com/th?id=OVFT.0XU4Uq7DqNYbqjOeUcenoi&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "8h",
        "source": "Benzinga.com",
        "article_content": "Financial giants have made a conspicuous bullish move on Unity Software. Our analysis of options history for Unity Software U revealed 24 unusual trades.\n\nDelving into the details, we found 50% of traders were bullish, while 33% showed bearish tendencies. Out of all the trades we spotted, 2 were puts, with a value of $73,625, and 22 were calls, valued at $2,431,788.\n\nPredicted Price Range\n\nBased on the trading activity, it appears that the significant investors are aiming for a price territory stretching from $20.0 to $60.0 for Unity Software over the recent three months.\n\nVolume & Open Interest Development\n\nExamining the volume and open interest provides crucial insights into stock research. This information is key in gauging liquidity and interest levels for Unity Software's options at certain strike prices. Below, we present a snapshot of the trends in volume and open interest for calls and puts across Unity Software's significant trades, within a strike price range of $20.0 to $60.0, over the past month.\n\nUnity Software Call and Put Volume: 30-Day Overview\n\nBiggest Options Spotted:\n\nSymbol PUT/CALL Trade Type Sentiment Exp. Date Ask Bid Price Strike Price Total Trade Price Open Interest Volume U CALL TRADE NEUTRAL 10/18/24 $3.55 $3.2 $3.4 $20.00 $1.7M 13.5K 5.2K U CALL SWEEP BEARISH 12/20/24 $3.15 $3.1 $3.1 $23.00 $55.8K 3.5K 254 U CALL TRADE BEARISH 01/17/25 $5.3 $5.25 $5.25 $20.00 $54.6K 20.0K 5.5K U CALL SWEEP BULLISH 11/15/24 $2.88 $2.79 $2.88 $23.00 $53.2K 5.2K 900 U CALL SWEEP NEUTRAL 11/15/24 $2.66 $2.56 $2.61 $23.00 $48.2K 5.2K 1.2K\n\nAbout Unity Software\n\nUnity Software Inc provides a software platform for creating and operating interactive, real-time 3D content. The platform can be used to create, run, and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices. The business is spread across the United States, Greater China, EMEA, APAC, and Other Americas, of which key revenue is derived from the EMEA region. The products are used in the gaming industry, architecture and construction sector, animation industry, and designing sector.\n\nIn light of the recent options history for Unity Software, it's now appropriate to focus on the company itself. We aim to explore its current performance.\n\nUnity Software's Current Market Status\n\nWith a trading volume of 9,822,277, the price of U is down by -2.7%, reaching $22.57.\n\nCurrent RSI values indicate that the stock is may be overbought.\n\nNext earnings report is scheduled for 43 days from now.\n\nTurn $1000 into $1270 in just 20 days?\n\n20-year pro options trader reveals his one-line chart technique that shows when to buy and sell. Copy his trades, which have had averaged a 27% profit every 20 days. Click here for access.\n\nTrading options involves greater risks but also offers the potential for higher profits. Savvy traders mitigate these risks through ongoing education, strategic trade adjustments, utilizing various indicators, and staying attuned to market dynamics. Keep up with the latest options trades for Unity Software with Benzinga Pro for real-time alerts."
    },
    {
        "title": "Life Insurance Software Market Is Booming So Rapidly with Adobe, Vertafore, Salesforce, EIS Group",
        "link": "https://insurancenewsnet.com/oarticle/life-insurance-software-market-is-booming-so-rapidly-with-adobe-vertafore-salesforce-eis-group",
        "description": "Some of the key players profiled in the study are Salesforce, Microsoft, SAP, Vertafore, IBM, Applied Systems Inc., Oracle, ...",
        "image_url": "https://www.bing.com/th?id=OVFT.fYkzyHxnHAYKThxH56Zh_C&pid=News&w=234&h=132&c=14&rs=2&qlt=30",
        "category": "software+trend",
        "date": "Insurancenewsnet.com12h",
        "source": "Insurancenewsnet.com",
        "article_content": "EIN Presswire\n\nLife Insurance Software Market\n\nGlobal Life Insurance Software Market is expected to grow from 4.5 billion USD in 2023 to 12 billion USD by 2030, with a CAGR of 10% from 2024 to 2030\n\nHTF Market Intelligence Consulting is uniquely positioned to empower and inspire with research and consulting services to empower businesses with growth strategies, by offering services.\" -- Nidhi Bhawsar\n\nPUNE , MAHARASHTRA, INDIA , September 24, 2024 /EINPresswire.com/ -- Global Life Insurance Software Market by Player, Region, Type, Application and Sales Channel (2024-2032) is the latest research study released by HTF MI evaluating the market risk side analysis, highlighting opportunities, and leveraging strategic and tactical decision-making support. The report provides information on market trends and development, growth drivers, technologies, and the changing investment structure of the Global Life Insurance Software Market. Some of the key players profiled in the study are Salesforce, Microsoft, SAP, Vertafore , IBM , Applied Systems Inc. , Oracle, Sapiens International Corporation , Adobe, Vertafore , IBM , ACI, Sinosoft, Hyland Software , Aptitude Software , EIS Group & HawkSoft .\n\nDownload Sample Pages PDF (Including Full TOC, Table & Figures) @ https://www.htfmarketreport.com/sample-report/3356619-2021-2030-report-on-global-life-insurance-software-market?utm_source=Ganesh_EINnews&utm_id=Ganesh\n\nAccording to HTF Market Intelligence, the Global Life Insurance Software Market is expected to grow from 4.5 billion USD in 2023 to 12 billion USD by 2030, with a CAGR of 10% from 2024 to 2030.\n\nLife Insurance Software Market Overview:\n\nThe study provides a detailed outlook vital to keep market knowledge up to date segmented by Term Life, Annuity, Whole Life, Group Life & Unit-linked, , On-premises & Cloud-based, and 18+ countries across the globe along with insights on emerging & major players. If you want to analyze different companies involved in the Life Insurance Software industry according to your targeted objective or geography we offer customization according to your requirements.\n\nLife Insurance Software Market: Demand Analysis & Opportunity Outlook 2032\n\nLife Insurance Software research study defines the market size of various segments & countries by historical years and forecasts the values for the next 6 years. The report is assembled to comprise qualitative and quantitative elements of Life Insurance Software industry including market share, market size (value and volume 2019-2024, and forecast to 2032) that admires each country concerned in the competitive marketplace. Further, the study also caters to and provides in-depth statistics about the crucial elements of Life Insurance Software which includes drivers & restraining factors that help estimate the future growth outlook of the market.\n\nThe segments and sub-section of Life Insurance Software market is shown below:\n\nThe Study is segmented by the following Product/Service Type: On-premises & Cloud-based\n\nMajor applications/end-users industry are as follows: Term Life, Annuity, Whole Life, Group Life & Unit-linked\n\nSome of the key players involved in the Market are: Salesforce, Microsoft, SAP, Vertafore , IBM , Applied Systems Inc. , Oracle, Sapiens International Corporation , Adobe, Vertafore , IBM , ACI, Sinosoft, Hyland Software , Aptitude Software , EIS Group & HawkSoft\n\nImportant years considered in the Life Insurance Software study:\n\nHistorical year \u2013 2019-2023; Base year \u2013 2023; Forecast period** \u2013 2024 to 2032 [** unless otherwise stated]\n\nBuy Life Insurance Software research report @ https://www.htfmarketreport.com/buy-now?format=1&report=3356619\n\nIf opting for the Global version of Life Insurance Software Market; then the below country analysis would be included:\n\n\u2022 North America (the USA , Canada , and Mexico )\n\n\u2022 Europe ( Germany , France , the United Kingdom , Netherlands , Italy , Nordic Nations, Spain , Switzerland , and the Rest of Europe )\n\n\u2022 Asia-Pacific ( China , Japan , Australia , New Zealand , South Korea , India , Southeast Asia , and the Rest of APAC)\n\n\u2022 South America ( Brazil , Argentina , Chile , Colombia , the Rest of the countries, etc.)\n\n\u2022 the Middle East and Africa ( Saudi Arabia , United Arab Emirates , Israel , Egypt , Turkey , Nigeria , South Africa , Rest of MEA)\n\nKey Questions Answered with this Study\n\n1) What makes Life Insurance Software Market feasible for long-term investment?\n\n2) Know value chain areas where players can create value.\n\n3) Teritorry that may see a steep rise in CAGR & Y-O-Y growth?\n\n4) What geographic region would have better demand for products/services?\n\n5) What opportunity emerging territory would offer to established and new entrants in Life Insurance Software market?\n\n6) Risk side analysis connected with service providers?\n\n7) How influencing are factors driving the demand of Life Insurance Software in the next few years?\n\n8) What is the impact analysis of various factors in the Global Life Insurance Software market growth?\n\n9) What strategies of big players help them acquire a share in a mature market?\n\n10) How Technology and Customer-Centric Innovation is bringing big Change in Life Insurance Software Market?\n\nThere are 15 Chapters to display the Global Life Insurance Software Market\n\nChapter 1, Overview to describe Definition, Specifications, and Classification of Global Life Insurance Software market, Applications [Term Life, Annuity, Whole Life, Group Life & Unit-linked], Market Segment by Types , On-premises & Cloud-based;\n\nChapter 2, the objective of the study.\n\nChapter 3, Research methodology, measures, assumptions, and analytical tools\n\nChapters 4 and 5, Global Life Insurance Software Market Trend Analysis, Drivers, Challenges by Consumer Behavior, Marketing Channels, Value Chain Analysis\n\nChapters 6 and 7, show the Life Insurance Software Market Analysis, segmentation analysis, characteristics;\n\nChapters 8 and 9, show Five forces (bargaining power of buyers/suppliers), Threats to new entrants, and market conditions;\n\nChapters 10 and 11, show analysis by regional segmentation [ North America , Europe , Asia-Pacific etc], comparison, leading countries, and opportunities; Customer Behaviour\n\nChapter 12, identifies the major decision framework accumulated through Industry experts and strategic decision-makers;\n\nChapters 13 and 14, are about the competitive landscape (classification and Market Ranking)\n\nChapter 15, deals with Global Life Insurance Software Market sales channel, research findings, conclusion, appendix, and data source.\n\nGet Details about the Scope; Before Procuring Global Life Insurance Software Market Research Study @ https://www.htfmarketreport.com/enquiry-before-buy/3356619-2021-2030-report-on-global-life-insurance-software-market?utm_source=Ganesh_EINnews&utm_id=Ganesh\n\nThanks for showing interest in Life Insurance Software Industry Research Publication; you can also get individual chapter-wise sections or region-wise report versions like North America , LATAM, United States , GCC, Southeast Asia , Europe , APAC, Japan , United Kingdom , India or China , etc\n\nLegal Disclaimer:\n\nEIN Presswire provides this news content \"as is\" without warranty of any kind. We do not accept any responsibility or liability\n\nfor the accuracy, content, images, videos, licenses, completeness, legality, or reliability of the information contained in this\n\narticle. If you have any complaints or copyright issues related to this article, kindly contact the author above."
    }
]